{
  "filename": "GLI-NER.txt",
  "length": 44161,
  "context": "GLiNER: Generalist Model for Named Entity Recognition using\nBidirectional Transformer\nUrchade Zaratiana1,2, Nadi Tomeh2, Pierre Holat1,2, Thierry Charnois2\n1FI Group,2LIPN, CNRS UMR 7030, France\nzaratiana@lipn.fr\nhttps://github.com/urchade/GLiNER\nAbstract\nNamed Entity Recognition (NER) is essential\nin various Natural Language Processing (NLP)\napplications. Traditional NER models are ef-\nfective but limited to a set of predefined entity\ntypes. In contrast, Large Language Models\n(LLMs) can extract arbitrary entities through\nnatural language instructions, offering greater\nflexibility. However, their size and cost, particu-\nlarly for those accessed via APIs like ChatGPT,\nmake them impractical in resource-limited sce-\nnarios. In this paper, we introduce a compact\nNER model trained to identify any type of en-\ntity. Leveraging a bidirectional transformer en-\ncoder, our model, GLiNER, facilitates parallel\nentity extraction, an advantage over the slow\nsequential token generation of LLMs. Through\ncomprehensive testing, GLiNER demonstrate\nstrong performance, outperforming both Chat-\nGPT and fine-tuned LLMs in zero-shot evalua-\ntions on various NER benchmarks.\n1 Introduction\nNamed Entity Recognition plays a crucial role in\nvarious real-world applications, such as construct-\ning knowledge graphs. Traditional NER models are\nlimited to a predefined set of entity types. Expand-\ning the number of entity types can be beneficial for\nmany applications but may involve labeling addi-\ntional datasets. The emergence of Large Language\nModels, like GPT-3 (Brown et al., 2020), has intro-\nduced a new era for open-type NER by enabling\nthe identification of any types of entity types only\nby natural language instruction. This shift signi-\nfies a significant departure from the inflexibility\nobserved in traditional models. However, powerful\nLLMs typically consist of billions of parameters\nand thus require substantial computing resources.\nAlthough it is possible to access some LLMs via\nAPIs (OpenAI, 2023), using them at scale can incur\nhigh costs.\nRecently, researchers have explored the fine-\ntuning of open source language models such as\nHuman: [Instruction]  \\n Text: Alain Farley works at McGill University Assistant: I\u2019ve read the text Human: What describes person in the text ? Assistant: [\u2018Alain Farley\u2019] Human: What describes location in the text ? Assistant: [] Human: What describes organization in the text ? Assistant: [\u2018Mcgill University\u2019]\nBidirectional LMs (BERT, DeBERTa)(0,1, person)(4,5, organization)[ENT] person [ENT] location [ENT]  organization [SEP] +  Alain Farley works at McGill Universitya) UniNER (prev) : Prompting LLM for Open NER. \nb) GLiNER (Ours): Prompting BiLM for Open NER.Figure 1: BiLM for Open NER. Previous models, such\nas UniNER (Zhou et al., 2023) (Fig. a), approach the\ntask of open type NER by prompting LLMs with natural\nlanguage instructions (using a multi-turn dialogue style).\nOur proposed GLiNER utilizes small bidirectional LMs\nand treats the NER task as matching entity types with\ntextual spans in a latent space.\nLLaMa (Touvron et al., 2023) for named entity\nrecognition tasks. Wang et al. (2023), for example,\nintroduced InstructUIE, a fine-tuned FlanT5-11B\n(Raffel et al., 2019; Chung et al., 2022) model on\nexisting information extraction datasets, achieving\nexcellent performance in zero-shot settings. Ad-\nditionally, GoLLIE (Sainz et al., 2023) was intro-\nduced as an extension of InstructUIE work by by\nfinetuning a CodeLLaMa (Rozi\u00e8re et al., 2023)\nusing detailed annotation guidelines, resulting in\nsignificant performance improvements. Another\nrecent proposal by Zhou et al. (2023), called Uni-\nversalNER, involves the fine-tuning of LLMs us-\ning diverse data from various domains annotated\nwith ChatGPT instead of relying on standard NERarXiv:2311.08526v1  [cs.CL]  14 Nov 2023\nPerson[ENT]Organization[ENT]Location[SEP]AlainFarleyworksatMcGillUniversity3\n01245\n0.10.30.20.10.0.30.40.2\n0.30.20.10.20.30.10.80.4\n0.10.90.30.00.10.20.30.1\u2026.\u2026.\u2026.Entity types promptInput sentenceBidirectional Transformer Language Model (BERT, DeBERTa, \u2026)Span representation layer[ENT]\nLocationOrganizationPersonFFN layer\n(0,0)(0,1)(1,1)(1,2)(2,2)(4,4)(4,5)(5,5)(Dot product + Sigmoid activation)Entity type/Span similarity matrix Token/word  representationEntity type  EmbeddingsSpan EmbeddingsFigure 2: Model architecture . GLiNER employs a BiLM and takes as input entity type prompts and a sentence/text.\nEach entity is separated by a learned token [ENT] . The BiLM outputs representations for each token. Entity\nembeddings are passed into a FeedForward Network, while input word representations are passed into a span\nrepresentation layer to compute embeddings for each span. Finally, we compute a matching score between entity\nrepresentations and span representations (using dot product and sigmoid activation). For instance, in the figure, the\nspan representation of (0, 1), corresponding to \"Alain Farley,\" has a high matching score with the entity embeddings\nof \"Person\".\ndatasets. Their approach enables the replication\nand even surpassing of the original capability of\nChatGPT when evaluated in zero-shot on several\nNER datasets. While these works have achieved\nremarkable results, they present certain limitations\nwe seek to address: They use autoregressive lan-\nguage models, which can be slow due to token-\nby-token generation; Moreover, they employ large\nmodels with several billion parameters, limiting\ntheir deployment in compute-limited scenarios.\nFurthurmore, as NER is treated as a text gener-\nation problem, the generation of entities is done\nin several decoding steps, and there is no way to\nperform the prediction of multiple entity types in\nparallel.\nIn our work, we propose a model that addresses\nthe above-mentioned problems. Instead of relying\non large autoregressive models, we utilize smaller-\nscale Bidirectional Language Models (BiLM), such\nas BERT (Devlin et al., 2019) or deBERTa (He\net al., 2021). The core concept of our model in-\nvolves treating the task of Open NER as matching\nentity type embeddings to textual span represen-\ntations in latent space, rather than as a generationtask. This approach naturally solves the scalability\nissues of autoregressive models and allows for bidi-\nrectional context processing, which enables richer\nrepresentations. When trained on the dataset re-\nleased by (Zhou et al., 2023), which comprises\ntexts from numerous domains and thousands of\nentity types, our model demonstrates impressive\nzero-shot performance. More specifilcally, it out-\nperforms both ChatGPT and fine-tuned LLMs on\nzero-shot NER datasets (Table 1). Our model\u2019s\nrobustness is further evident in its ability to han-\ndle languages not even encountered during training.\nSpecifically, our model surpasses ChatGPT in 8 of\n10 languages (Table 3) that were not included in its\ntraining data.\n2 Method\nThis section presents our model, GLiNER, which\nis train to extract any types of entity using a Bidi-\nrectional Language Models. Our model has three\nmain components: i) a pre-trained textual encoder\n(a BiLM such as BERT), ii) a span representation\nmodule which computes span embeddings from to-\nken embeddings, iii) an entity representation mod-\nule which computes entity embeddings that the\nmodel seeks to extract. The goal is to have en-\ntity and span embeddings in the same latent space\nto assess their compatibility (degree of matching).\nThe overall architecture of our model is depicted in\nFigure 2.\n2.1 Architecture\nInput format The input to our model comprises a\nunified sequence combining entity types (expressed\nin natural language) and the input text from which\nentities are to be extracted. The input format is as\nfollows:\nHuman: [Instruction]  \\n Text: Alain Farley works at McGill University Assistant: I\u2019ve read the text Human: What describes person in the text ? Assistant: [\u2018Alain Farley\u2019] Human: What describes location in the text ? Assistant: [] Human: What describes organization in the text ? Assistant: [\u2018Mcgill University\u2019]\nBidirectional LMs (BERT, DeBERTa)(0,1, person)(4,5, organization)[ENT] person [ENT] location [ENT]  organization [SEP] +  Alain Farley works at McGill Universitya) UniNER (prev) : Prompting LLM for Open NER. \nb) GLiNER (Ours): Prompting BiLM for Open NER.\n[ENT]  [ENT]  \u2026 [ENT]  [SEP]   \u2026 t0t1tM\u22121x0x2xN\u22121\n[ENT] token represents a special token placed\nbefore each entity type and the [SEP] token func-\ntions as a delimiter, separating the sequence of en-\ntity types from the input text. They are initialized\nrandomly at the start of training.\nToken representation The token encoder pro-\ncesses the unified input to compute interactions\nbetween all tokens (both entity types and input\ntext), producing contextualized representations.\nLetp={pi}M\u22121\n0\u2208RM\u00d7Drepresent the en-\ncoder\u2019s output for each entity type, corresponding\nto all the [ENT] token representations. Similarly,\nh={hi}N\u22121\n0\u2208RN\u00d7Ddenotes the representation\nof each word in the input text. For words tokenized\ninto multiple subwords, we use the representation\nof the first subword, which is a standard choice in\nthe NER literature (Zaratiana et al., 2022).\nEntity and Span Representation In our model,\nwe aim to encode entity types and span embeddings\ninto a unified latent space. The entity representa-\ntion is computed by refining the initial represen-\ntation pusing a two-layer feedforward network,\nresulting in q={qi}M\u22121\n0\u2208RM\u00d7D. The repre-\nsentation of a span starting at position iand ending\nat position jin the input text, Sij\u2208RD, is com-\nputed as:\nSij=FFN(hi\u2297hj) (1)\nHere, FFNdenotes a two-layer feedforward net-\nwork, and \u2297represents the concatenation operation.\nIn practice, The computation of all span represen-\ntations can be easily parallelized. Moreover, we set\nan upper bound to the length (K=12) of the span in\norder to keep linear complexity, without harming\nrecall.Entity Type and Span Matching To evaluate\nwhether a span (i, j)corresponds to entity type t,\nwe calculate the following matching score:\n\u03d5(i, j, t) =\u03c3(ST\nijqt)\u2208R (2)\nIn this equation, \u03c3denotes a sigmoid activation\nfunction. As we train with binary cross-entropy\nloss (see next sec. 2.2), \u03d5(i, j, t)can be interpreted\nas the probability of the span (i, j)being of type t.\n2.2 Training\nDuring training, our objective is to optimize model\nparameters to enhance the matching score for cor-\nrect span-type pairs (positive pairs) and reduce it\nfor incorrect pairs (negative pairs). A span (i, j)\npaired with an entity type tforms a positive pair\n(s\u2208 P) if the span is labeled with type tin the train-\ning data. Otherwise, it is a negative pair ( s\u2208 N ).\nThe training loss for an individual example, com-\nprising spans Sand entity types T, is defined as:\nLBCE=\u2212X\ns\u2208S\u00d7TIs\u2208Plog\u03d5(s)+\nIs\u2208Nlog (1\u2212\u03d5(s))(3)\nThe variable srepresents a pair of span/entity\ntype and Iis an indicator function, which returns\n1 when the specified condition is true and 0 oth-\nerwise. This loss function corresponds to binary\ncross-entropy.\n2.3 Decoding algorithm\nIn the decoding phase, we employ a greedy span\nsection (Zaratiana et al., 2022) that selects en-\ntity spans based on matching scores, to ensure\ntask/dataset specific constraints. This strategy is ap-\nplied independently to each sentence. Only, spans\n(i, j)with matching scores \u03d5(i, j, c )>0.5are con-\nsidered for selection.\nFlat NER: The algorithm chooses the highest-\nscoring non-overlapping span and continues this\nprocess until all spans are evaluated.\nNested NER: Similar to Flat NER, but the algo-\nrithm allows selection of fully nested spans within\nother entities while still avoiding partial overlaps.\nAlgorithm Efficiency: The decoding is imple-\nmented using a priority queue for spans, ensuring\nanO(nlogn)complexity, with nbeing the number\nof candidate spans.\nModel Params Movie Restaurant AI Literature Music Politics Science Average\nVicuna-7B 7B 6.0 5.3 12.8 16.1 17.0 20.5 13.0 13.0\nVicuna-13B 13B 0.9 0.4 22.7 22.7 26.6 27.0 22.0 17.5\nUSM 0.3B 37.7 17.7 28.2 56.0 44.9 36.1 44.0 37.8\nChatGPT \u2013 5.3 32.8 52.4 39.8 66.6 68.5 67.0 47.5\nInstructUIE 11B 63.0 21.0 49.0 47.2 53.2 48.1 49.2 47.2\nUniNER-7B 7B 42.4 31.7 53.6 59.3 67.0 60.9 61.1 53.7\nUniNER-13B 13B 48.7 36.2 54.2 60.9 64.5 61.4 63.5 55.6\nGoLLIE 7B 63.0 43.4 59.1 62.7 67.8 57.2 55.5 58.0\nGLiNER-S 50M 46.9 33.3 50.7 60.0 60.9 61.5 55.6 52.7\nGLiNER-M 90M 42.9 37.3 51.8 59.7 69.4 68.6 58.1 55.4\nGLiNER-L 0.3B 57.2 42.9 57.2 64.4 69.6 72.6 62.6 60.9\nTable 1: Zero-Shot Scores on Out-of-Domain NER Benchmark. We report the performance of GLiNER with\nvarious DeBERTa-v3 (He et al., 2021) model sizes. Results for Vicuna, ChatGPT, and UniNER are from Zhou et al.\n(2023); USM and InstructUIE are from Wang et al. (2023); and GoLLIE is from Sainz et al. (2023).\n3 Experimental Setting\n3.1 Training data\nOur objective is to construct a versatile NER model\ncapable of accurately identifying a wide array of\nentity types across different textual domains. To\nachieve this, it is essential that our training dataset\nencompasses a diverse range of entity types. For\nthis, we utilize the training data released by Zhou\net al. (2023), known as Pile-NER1. This dataset\nis derived from the Pile corpus (Gao et al., 2020),\ncommonly used for pretraining large language mod-\nels, and comprises text from diverse sources. More\nspecifically, Zhou et al. (2023) sampled 50,000\ntexts from the Pile data and employed ChatGPT\nto extract their associated entity types. Notably,\nthey did not specify the entity types to the LLMs,\naiming to extract a diverse range of entity types.\nThey used the following prompt:\n[ENT]  [ENT]  \u2026 [ENT]  [SEP]   \u2026 t0t1tM\u22121x0x2xN\u22121System Message: You are a helpful information extraction system. Prompt: Given a passage, your task is to extract all entities and identify their entity types. The output should be in a list of tuples of the following format: [(\"entity 1\", \"type of entity 1\"), ... ].Passage: {input_passage}\nFigure 3: Prompting ChatGPT for entity extraction .\nThis prompt was used Zhou et al. (2023) to construct\nthe Pile-NER dataset.\nFinally, after filtering bad outputs their datasets\nresults in 44889 passages containing in total 240k\nentity spans and 13k distinct entity types.\n1https://huggingface.co/datasets/Universal-NER/Pile-\nNER-type3.2 Hyperparameters\nOur model, GLiNER, is trained on the Pile-NER\ndataset, which we described in the previous section.\nWe use the deBERTa-v3 (He et al., 2021) as our\nbackbone due to its proven empirical performance.\nAll non-pretrained layers have a width dimension\nof 768 and a dropout rate of 0.4. Regarding the\ntraining process, we employ the AdamW optimizer\n(Loshchilov and Hutter, 2017), setting a base learn-\ning rate of 1e-5 for pretrained layers (the trans-\nformer backbone) and 5e-5 for non-pretrained lay-\ners (FFN layers, span representation). We trained\nour models for a maximum of 30k steps, starting\nwith a 10% warmup phase, followed by a decay\nphase using a cosine scheduler. The Pile-NER\ndataset natively contains only positive entities (i.e.,\nentities that are present in the sentence), and we\nfound it useful to include negative entity types dur-\ning training. This is achieved by sampling random\nentities from other examples in the same batch. In\naddition, we follow the strategies outlined in Sainz\net al. (2023) as a form of regularization, which\nincludes shuffling entity order andrandomly drop-\nping entities . Furthermore, we limit the number\nof entity types to 25 per sentence during training.\nThe larger variant of our model, GLiNER-L, takes\n5 hours to train on an A100 GPU.\n3.3 Baselines\nIn our evaluation, we compare our model, GLiNER,\nwith several recent models designed for open-type\nNER. First, we examine chat models like Chat-\nGPT andVicuna (Chiang et al., 2023), which\nutilize the prompting from Ye et al. (2023); we\nreport their results reported by Zhou et al. (2023).\nNext, we focus on three recent Large Language\nModels (LLMs) that have been fine-tuned for NER:\nInstructUIE (Wang et al., 2023), based on the\nFlanT5 11B model and fine-tuned on various NER\ndatasets; UniNER (Zhou et al., 2023), which em-\nploys a LLaMa model fine-tuned on a dataset gen-\nerated by ChatGPT; GoLLIE (Sainz et al., 2023),\nfine-tuned to adhere to detailed annotation guide-\nlines for enhanced performance in unseen IE tasks,\nutilizing CodeLLama as its base model. Finally,\nwe include USM (Lou et al., 2023) in our compari-\nson, which is similar in size to ours but features a\ndifferent architecture.\n3.4 Evaluation\nDatasets We primarily evaluate our model in a\nzero-shot context on common NER benchmarks,\nfollowing previous works (Wang et al., 2023; Zhou\net al., 2023). The first is the OOD NER Benchmark\n(Table 1), which comprises seven diverse NER\ndatasets from CrossNER and MIT. This benchmark\nis typically used for evaluating out-of-domain gen-\neralization capabilities of NER models. The second\nbenchmark consists of 20 NER datasets (Table 2)\nfrom a wide range of domains, including biomedi-\ncal, news articles, and tweets. These datasets are\ncommonly used for training supervised NER mod-\nels. Additionally, we evaluate our model on multi-\nlingual NER datasets (Table 3) for further investiga-\ntion. For this purpose, we use the recently released\nMulticoner (Multilingual Complex NER) (Malmasi\net al., 2022), which contains data in 11 languages\nacross various domains.\nMetric We adopt the standard NER evaluation\nmethodology, calculating F1-score based on the\nexact match between predicted and actual entities.\n4 Results\n4.1 Zero-shot on English datasets\nIn this section, we discuss the performance of our\nmodel in a zero-shot context, i.e., by only training\non the Pile-NER dataset without further fine-tuning\non target datasets.\nOOD NER Benchmark We first evaluate our\nmodel on the OOD benchmark as reported in Table\n1. We compare three different sizes of our model\n(small, medium, and large) against the baselines.\nThe results demonstrate our model\u2019s impressive ca-\npability, irrespective of its size. For example, evenDataset ChatGPT UniNER-7B GLiNER-L\nACE05 26.6 36.9 27.3\nAnatEM 30.7 25.1 33.3\nbc2gm 40.2 46.2 47.9\nbc4chemd 35.5 47.9 43.1\nbc5cdr 52.4 68.0 66.4\nBroad Tweeter 61.8 67.9 61.2\nCoNLL03 52.5 72.2 64.6\nFabNER 15.3 24.8 23.6\nFindVehicle 10.5 22.2 41.9\nGENIA 41.6 54.1 55.5\nHarveyNER 11.6 18.2 22.7\nMIT Movie 5.3 42.4 57.2\nMIT Restaurant 32.8 31.7 42.9\nMultiNERD 58.1 59.3 59.7\nncbi 42.1 60.4 61.9\nOntoNotes 29.7 27.8 32.2\nPolyglotNER 33.6 41.8 42.9\nTweetNER7 40.1 42.7 41.4\nWikiANN 52.0 55.4 58.9\nWikiNeural 57.7 69.2 71.8\nAverage 36.5 45.7 47.8\nTable 2: Z ero-shot performance on 20 NER datasets.\nResults of ChatGPT and UniNER are reported from\n(Zhou et al., 2023).\nour smallest model, with only 50M parameters, out-\nperforms general-purpose models such as ChatGPT\nand Vicuna. It also shows better performance than\nthe 11B InstructUIE, which has been instruction-\ntuned for the NER task. Furthermore, when com-\npared to UniNER, which used the same training\ndata as GLiNER, our medium-sized model (90M)\nachieves comparable results to UniNER-13B (55\nF1 for both), despite being 140 times smaller, while\nour largest version outperforms it by an average\nof 5 points. Our most best competitor, GoLLIE,\nwhich leads among the LLMs, achieves better per-\nformance than most of our models but is still less\neffective than GLiNER-L. Against USM, which\nhas a comparable number of parameters to ours,\nthe performance is significantly lower, highlighting\nthe superiority of our architecture.\n20 NER Benchmark Table 2 presents a compar-\nison of our model against ChatGPT and UniNER\nacross 20 diverse NER datasets. First, similar to\nthe OOD benchmark, ChatGPT significantly lags\nbehind fine-tuned models for NER, trailing behind\nUniNER. Furthermore, GLiNER achieves the high-\nest performance on 13 of these datasets, surpassing\nUniNER by an average of 2 points. This supe-\nrior performance underscores GLiNER\u2019s robust-\nness and adaptability across a broad spectrum of\ndomains. However, a notable observation is that\nGLiNER underperforms compared to UniNER on\nLanguage Sup. ChatGPTGLiNER\nEn MultiLatinGerman 64.6 37.1 35.6 39.5\nEnglish 62.7 37.2 42.4 41.7\nSpanish 58.7 34.7 38.7 42.1\nDutch 62.6 35.7 35.6 38.9Non-LatinBengali 39.7 23.3 0.89 25.9\nPersian 52.3 25.9 14.9 30.2\nHindi 47.8 27.3 11.3 27.8\nKorean 55.8 30.0 20.5 28.7\nRussian 59.7 27.4 30.3 33.3\nTurkish 46.8 31.9 22.0 30.0\nChinese 53.1 18.8 6.59 24.3\nAverage 54.9 29.9 23.6 32.9\nTable 3: Zero-Shot Scores on Different Languages.\nThe baseline, Sup. , is an XLM-R (Conneau et al.,\n2019) model fine-tuned on the training set of each lan-\nguage separately, as reported by Malmasi et al. (2022).\nChatGPT evaluation is taken from Lai et al. (2023).\nGLiNER-En employs deBERTa-v3-Large, and Multi\nuses mdeBERTa-v3-base.\ntweet-based NER datasets. This highlights poten-\ntial areas for improvement in GLiNER\u2019s ability to\nprocess informal, colloquial, or noisy data, typical\nof social media content.\n4.2 Zero-Shot Multilingual Evaluation\nIn this section, we evaluate the performance of our\nmodel in a zero-shot context on unseen languages\nto assess its generalizability. This evaluation uses\nthe Multiconel dataset, with results detailed in Ta-\nble 3. Our model, GLiNER, is presented in two\nvariants: En, which employs deBERTa-v3-Large\nas its backbone, and Multi , which utilizes a mul-\ntilingual version of deBERTa-v3 (mdeBERTa-v3).\nBoth versions were fine-tuned on the Pile-NER\ndataset. For comparative purposes, we include re-\nsults from ChatGPT and a supervised baseline, the\nlatter being fine-tuned on the training set of each\ndataset using separate models.\nResults As expected, the supervised baseline\ndemonstrated superior performance, significantly\noutperforming the zero-shot models. Among these,\nGLiNER-Multi showed the most promising results,\nsurpassing ChatGPT in most languages, which is\nnoteworthy considering that the fine-tuning dataset,\nPile-NER, consists exclusively of English exam-\nples. Interestingly, its performance on Spanish data\nslightly exceeded that in English. While GLiNER-\nEn generally underperformed compared to Chat-\nGPT on average, it achieved competitive, and at\ntimes superior, results in languages using the LatinDatasetInstructUIE UniNER-7B GLiNER-L\nw/o w/ w/ w/o\nACE05 79.9 86.7 82.8 81.3\nAnatEM 88.5 88.5 88.9 88.4\nbc2gm 80.7 82.4 83.7 82.0\nbc4chemd 87.6 89.2 87.9 86.7\nbc5cdr 89.0 89.3 88.7 88.7\nBroad Twitter 80.3 81.2 82.5 82.7\nCoNLL03 91.5 93.3 92.6 92.5\nFabNER 78.4 81.9 77.8 74.8\nFindVehicle 87.6 98.3 95.7 95.2\nGENIA 75.7 77.5 78.9 77.4\nHarveyNER 74.7 74.2 68.6 67.4\nMIT Movie 89.6 90.2 87.9 87.5\nMIT Restaurant 82.6 82.3 83.6 83.3\nMultiNERD 90.3 93.7 93.8 93.3\nncbi 86.2 87.0 87.8 87.1\nOntoNotes 88.6 89.9 89.0 88.1\nPolyglotNER 53.3 65.7 61.5 60.6\nTweetNER7 65.9 65.8 51.4 50.3\nWikiANN 64.5 84.9 83.7 82.8\nwikiNeural 88.3 93.3 91.3 91.4\nAverage 81.2 84.8 82.9 82.1\nTable 4: In-domain Supervised Finetuning. All the\nmodels are fine-tuned on the mix of all training data of\nthe benchmark. w/indicates that the model was trained\non the Pile-NER dataset before finetuning.\nscript, such as Spanish and German. However, its\nperformance was markedly less competitive in non-\nLatin languages, particularly in Bengali, where it\nscored only 0.89 in the F1 score.\n4.3 In-domain Supervised tuning\nIn our work, we also perform in-domain supervised\nfine-tuning (on 20 NER datasets) of our model\nto compare its capabilities against LLMs under\nthis setup. Specifically, we compare our model\nagainst InstructUIE and UniNER, both of which\nhave also been fine-tuned. The main difference is\nthat UniNER has been pre-trained on the Pile-NER\ndataset before fine-tuning.\nTraining Setup For the supervised setting, we\nprimarily adhere to the same experimental setup as\ndescribed in the main experiment (using deBERTa-\nv3 large), except for the training dataset. Regarding\nthe training data, we follow the approach of Instruc-\ntUIE: we randomly sample 10,000 data points for\neach dataset in the 20 NER benchmark. If a dataset\ndoes not contain 10,000 samples, we include all\navailable data. We implement two variants of our\nmodel: the first one initializes the weights from\nour zero-shot model, which is a pretrained on the\nPile-NER dataset. The second variant is trained\nwithout the Pile-NER dataset, same as InstructUIE.\n50 51 52 53 54 55\nAvg. zero-shot F1 on OOD NER Benchmark42.042.543.043.544.044.545.0Avg. zero-shot F1 on 20 NER DatasetsBERT\nRoBERTaalBERTELECTRADeBERTaFigure 4: Zero-shot performance for different back-\nbones. It reports the avg. results on 20 NER and OOD\nNER datasets\nResults The results of our experiment are re-\nported in Table 3. Firstly, we observe that for the\nin-domain fine-tuning, our GLiNER model, pre-\ntrained on Pile-NER, achieves slightly better re-\nsults than the non-pretrained variant, with an av-\nerage difference of 0.8. Moreover, our pretrained\nGLiNER model outperforms InstructUIE (with an\naverage difference of 0.9) despite being fine-tuned\non the same dataset, whereas InstructUIE is signif-\nicantly larger (approximately 30 times so). This\ndemonstrates that our proposed architecture is in-\ndeed competitive. However, our model falls behind\nUniNER by almost 3 points. Nevertheless, our\nmodel still manages to achieve the best score in 7\nout of 20 datasets.\n5 Further analysis and ablations\nHere we conduct different set of experiments to\nbetter investigate our model.\n5.1 Effect of Different Backbones\nIn our work, we primarily utilize the deBERTa-v3\nmodel as our backbone due to its strong empirical\nperformance. However, we demonstrate here that\nour method is adaptable to a wide range of BiLMs.\nSetup Specifically, we investigate the perfor-\nmance of our model using other popular BiLMs,\nincluding BERT (Devlin et al., 2019), RoBERTa\n(Liu et al., 2019), AlBERT (Lan et al., 2019), and\nELECTRA (Clark et al., 2020). We also conducted\nexperiments with XLNet (Yang et al., 2019) but did\nnot achieve acceptable performance (achieving at\nmost 3 F1 on the OOD benchmark) despite exten-\nsive hyperparameter tuning. For a fair comparison,\nwe employed the base size (GLiNER-M) and tuned\nthe learning rate for each model. We report the\n100 500 1000 5000 10000\nDataset Size65707580Avg. F1 ||=5.6\n||=1.6\n||=1.3\n||=1.2\n||=0.6\nGLiNER-L w/o pretraining\nGLiNER-LFigure 5: Supervised performance across different\ndataset sizes. The evaluation is conducted on the 20\nNER datasets (in table 4).\nzero-shot results on both the OOD benchmark and\nthe 20 NER benchmark in Figure 4.\nResult The results of our experiment, as shown\nin the Figure 4, clearly demonstrate the superiority\nof deBERTa-v3 over other pretrained BiLMs. It\nachieves the highest performance on both bench-\nmarks by a clear margin. ELECTRA and AlBERT\nalso show notable performance, albeit slightly\nlower, while BERT and RoBERTa lag behind with\nsimilar scores. However, it should be noted that\nall of the backbones we tested demonstrate strong\nperformance compared to existing models. More\nspecifically, even BERT-base, which ranks among\nthe lower performers, achieves around 49 F1 on\nthe OOD benchmark. This score is still 2 F1 points\nhigher than the average for models like ChatGPT\nand InstructUIE.\n5.2 Effect of Pretraining on In-domain\nPerformance\nIn this section, we investigate the impact of pre-\ntraining on the Pile-NER dataset for supervised\nin-domain training on the 20 NER datasets, across\nvarious data sizes. The experiments range from\n100 samples per dataset to 10,000 (full training\nsetup). We use the same hyperparameters for all\nconfigurations. The results are reported in Figure\n5.\nResults As shown in the figure, models pre-\ntrained on Pile-NER consistently outperform their\ncounterparts that are only trained on supervised\ndata, indicating successful positive transfer. We\nfurther observe that the gain is larger when super-\nvised data is limited. For instance, the difference in\nperformance is 5.6 when employing 100 samples\nper dataset, and the gap becomes smaller as the\nsize of the dataset increases.\nNegative Samples Prec Rec F1\n0% 49.3 58.1 53.3\n50% 62.3 59.7 60.9\n75% 61.1 56.5 58.6\nTable 5: Effect of negative entity types sampling.\n5.3 Ablations\nNegative Entity Sampling The original Pile-\nNER dataset, curated by Zhou et al. (2023), fea-\ntures passages with positive entity instances, i.e.,\nentities that are directly present in the text. To bet-\nter align training with real-world scenarios, where\nsome entity types might be absent, we implemented\nnegative entity sampling as mentioned in Section\n3.2. In this study, we evaluate different sampling\nratios: 0% (only positive entities), 50%, and 75%\nnegative entities. Table 5 shows that training with\nonly positive entities results in lower precision but\nhigher recall, indicating that the model often makes\nfalse positive errors. Conversely, using 75% nega-\ntive entities increases precision but decreases recall,\nas the abundance of negatives makes the model\nmore cautious, leading to missed correct entities.\nA 50% negative entity ratio proves to be the most\neffective, providing a balanced approach.\nEntity type dropping In the experiment, we em-\nployed a strategy of randomly varying the number\nof entity prompts during training. This approach\naimed to expose the model to different quantities\nof entity types in each training instance, thereby\nincreasing its adaptability to handle scenarios with\nvarying numbers of entities. The usage of this tech-\nnique results in an average improvement of over\n1.4 points in out-of-domain evaluation, as shown\nin the Figure 5.\n6 Related Works\nNamed Entity Recognition NER is a well-\nestablished task in the field of NLP, with numerous\napplications. Initially, NER models relied on rule-\nbased system (Weischedel et al., 1996) that were\nbuilt using handcrafted algorithms and gazetteers\n(Mikheev et al., 1999; Nadeau et al., 2006; Zamin\nand Oxley, 2011). However, these models had\nlimitations in terms of scalability and adaptabil-\nity to new domains or languages. To overcome\nthese issues, machine learning approaches have\nbeen proposed (Lafferty et al., 2001). In the early\nstages, NER tasks were designed as sequence la-\n50 52 54 56 58 60 62\nAvg. F1Full\nw/o drop\nw/o Neg\nw/o both60.90\n59.50\n53.30\n52.30Figure 6: Randomly dropping entity types. We report\nthe results with and without negative entity sampling.\nbeling (Huang et al., 2015; Lample et al., 2016;\nAkbik et al., 2018) where the objective was to pre-\ndict tagged sequences (e.g., BILOU tags (Ratinov\nand Roth, 2009)). Since then, several paradigm\nshifts have occurred: span-based approaches treat-\ning NER as span classification (Sarawagi and Co-\nhen, 2004; Fu et al., 2021; Li et al., 2021; Zaratiana\net al., 2023); NER being treated as a question an-\nswering problem (Li et al., 2019); and even as a\ngeneration task (Yan et al., 2021).\nZero-shot learning for NER The advent of\nlarge-scale autoregressive models has recently\ntransformed many paradigms in NLP through nat-\nural language prompting (Min et al., 2022; Wei\net al., 2022; Qin et al., 2023). This is also the case\nfor NER (Li et al., 2022; Ashok and Lipton, 2023;\nAgrawal et al., 2022). Others have fine-tuned these\nmodels for tasks to better align their capabilities\nwith the requirements of entity recognition (Cui\net al., 2021; Zhou et al., 2023) or information ex-\ntraction in general (Lou et al., 2023; Wang et al.,\n2023; Sainz et al., 2023; Lu et al., 2022). This\nis done through-instruction tuning (Mishra et al.,\n2021; Wang et al., 2022; Longpre et al., 2023).\n7 Conclusion\nIn this paper, we introduced GLiNER, a new\nmethod for identifying various types of entities\nin text using bidirectional language models. Our\nmodel not only outperforms state-of-the-art Large\nLanguage Models like ChatGPT in zero-shot sce-\nnarios but also offers a more resource-efficient al-\nternative, crucial for environments with limited\ncomputing power. GLiNER is versatile, perform-\ning well in multiple languages, including those\nit wasn\u2019t trained on. In future work, we aim to\nfurther improve GLiNER\u2019s design for enhanced\nperformance and to better adapt it for low-resource\nlanguages.\nReferences\nMonica Agrawal, Stefan Hegselmann, Hunter Lang,\nYoon Kim, and David A. Sontag. 2022. Large lan-\nguage models are few-shot clinical information ex-\ntractors. In Conference on Empirical Methods in\nNatural Language Processing .\nAlan Akbik, Duncan Blythe, and Roland V ollgraf. 2018.\nContextual string embeddings for sequence label-\ning. In Proceedings of the 27th International Con-\nference on Computational Linguistics , pages 1638\u2013\n1649, Santa Fe, New Mexico, USA. Association for\nComputational Linguistics.\nDhananjay Ashok and Zachary Chase Lipton. 2023.\nPromptner: Prompting for named entity recognition.\nArXiv , abs/2305.15444.\nTom B. Brown, Benjamin Mann, Nick Ryder, Melanie\nSubbiah, Jared Kaplan, Prafulla Dhariwal, Arvind\nNeelakantan, Pranav Shyam, Girish Sastry, Amanda\nAskell, Sandhini Agarwal, Ariel Herbert-V oss,\nGretchen Krueger, T. J. Henighan, Rewon Child,\nAditya Ramesh, Daniel M. Ziegler, Jeff Wu, Clemens\nWinter, Christopher Hesse, Mark Chen, Eric Sigler,\nMateusz Litwin, Scott Gray, Benjamin Chess, Jack\nClark, Christopher Berner, Sam McCandlish, Alec\nRadford, Ilya Sutskever, and Dario Amodei. 2020.\nLanguage models are few-shot learners. ArXiv ,\nabs/2005.14165.\nWei-Lin Chiang, Zhuohan Li, Zi Lin, Ying Sheng,\nZhanghao Wu, Hao Zhang, Lianmin Zheng, Siyuan\nZhuang, Yonghao Zhuang, Joseph E. Gonzalez, Ion\nStoica, and Eric P. Xing. 2023. Vicuna: An open-\nsource chatbot impressing gpt-4 with 90%* chatgpt\nquality.\nHyung Won Chung, Le Hou, Shayne Longpre, Barret\nZoph, Yi Tay, William Fedus, Yunxuan Li, Xuezhi\nWang, Mostafa Dehghani, Siddhartha Brahma, Al-\nbert Webson, Shixiang Shane Gu, Zhuyun Dai,\nMirac Suzgun, Xinyun Chen, Aakanksha Chowdh-\nery, Alex Castro-Ros, Marie Pellat, Kevin Robinson,\nDasha Valter, Sharan Narang, Gaurav Mishra, Adams\nYu, Vincent Zhao, Yanping Huang, Andrew Dai,\nHongkun Yu, Slav Petrov, Ed H. Chi, Jeff Dean, Ja-\ncob Devlin, Adam Roberts, Denny Zhou, Quoc V . Le,\nand Jason Wei. 2022. Scaling instruction-finetuned\nlanguage models.\nKevin Clark, Minh-Thang Luong, Quoc V . Le, and\nChristopher D. Manning. 2020. Electra: Pre-training\ntext encoders as discriminators rather than genera-\ntors.\nAlexis Conneau, Kartikay Khandelwal, Naman Goyal,\nVishrav Chaudhary, Guillaume Wenzek, Francisco\nGuzm\u00e1n, Edouard Grave, Myle Ott, Luke Zettle-\nmoyer, and Veselin Stoyanov. 2019. Unsupervised\ncross-lingual representation learning at scale. In An-\nnual Meeting of the Association for Computational\nLinguistics .Leyang Cui, Yu Wu, Jian Liu, Sen Yang, and Yue Zhang.\n2021. Template-based named entity recognition us-\ning bart. In Findings .\nJacob Devlin, Ming-Wei Chang, Kenton Lee, and\nKristina Toutanova. 2019. Bert: Pre-training of deep\nbidirectional transformers for language understand-\ning. In North American Chapter of the Association\nfor Computational Linguistics .\nJinlan Fu, Xuanjing Huang, and Pengfei Liu. 2021.\nSpanNER: Named entity re-/recognition as span pre-\ndiction. In Proceedings of the 59th Annual Meet-\ning of the Association for Computational Linguistics\nand the 11th International Joint Conference on Natu-\nral Language Processing (Volume 1: Long Papers) ,\npages 7183\u20137195, Online. Association for Computa-\ntional Linguistics.\nLeo Gao, Stella Rose Biderman, Sid Black, Laurence\nGolding, Travis Hoppe, Charles Foster, Jason Phang,\nHorace He, Anish Thite, Noa Nabeshima, Shawn\nPresser, and Connor Leahy. 2020. The pile: An\n800gb dataset of diverse text for language modeling.\nArXiv , abs/2101.00027.\nPengcheng He, Jianfeng Gao, and Weizhu Chen. 2021.\nDebertav3: Improving deberta using electra-style pre-\ntraining with gradient-disentangled embedding shar-\ning. ArXiv , abs/2111.09543.\nZhiheng Huang, Wei Xu, and Kai Yu. 2015. Bidirec-\ntional lstm-crf models for sequence tagging.\nJohn D. Lafferty, Andrew McCallum, and Fernando\nPereira. 2001. Conditional random fields: Probabilis-\ntic models for segmenting and labeling sequence data.\nInInternational Conference on Machine Learning .\nViet Dac Lai, Nghia Trung Ngo, Amir Pouran Ben\nVeyseh, Hieu Man, Franck Dernoncourt, Trung Bui,\nand Thien Huu Nguyen. 2023. Chatgpt beyond en-\nglish: Towards a comprehensive evaluation of large\nlanguage models in multilingual learning. ArXiv ,\nabs/2304.05613.\nGuillaume Lample, Miguel Ballesteros, Sandeep Sub-\nramanian, Kazuya Kawakami, and Chris Dyer. 2016.\nNeural architectures for named entity recognition.\nInNorth American Chapter of the Association for\nComputational Linguistics .\nZhenzhong Lan, Mingda Chen, Sebastian Goodman,\nKevin Gimpel, Piyush Sharma, and Radu Soricut.\n2019. Albert: A lite bert for self-supervised learning\nof language representations. ArXiv , abs/1909.11942.\nDongfang Li, Baotian Hu, and Qingcai Chen. 2022.\nPrompt-based text entailment for low-resource\nnamed entity recognition. ArXiv , abs/2211.03039.\nXiaoya Li, Jingrong Feng, Yuxian Meng, Qinghong\nHan, Fei Wu, and Jiwei Li. 2019. A unified mrc\nframework for named entity recognition. ArXiv ,\nabs/1910.11476.\nYangming Li, lemao liu, and Shuming Shi. 2021. Em-\npirical analysis of unlabeled entity problem in named\nentity recognition. In International Conference on\nLearning Representations .\nYinhan Liu, Myle Ott, Naman Goyal, Jingfei Du, Man-\ndar Joshi, Danqi Chen, Omer Levy, Mike Lewis,\nLuke Zettlemoyer, and Veselin Stoyanov. 2019.\nRoberta: A robustly optimized bert pretraining ap-\nproach. ArXiv , abs/1907.11692.\nS. Longpre, Le Hou, Tu Vu, Albert Webson, Hyung Won\nChung, Yi Tay, Denny Zhou, Quoc V . Le, Barret\nZoph, Jason Wei, and Adam Roberts. 2023. The flan\ncollection: Designing data and methods for effective\ninstruction tuning. In International Conference on\nMachine Learning .\nIlya Loshchilov and Frank Hutter. 2017. Decoupled\nweight decay regularization. In International Confer-\nence on Learning Representations .\nJie Lou, Yaojie Lu, Dai Dai, Wei Jia, Hongyu Lin, Xi-\nanpei Han, Le Sun, and Hua Wu. 2023. Universal\ninformation extraction as unified semantic matching.\nInAAAI Conference on Artificial Intelligence .\nYaojie Lu, Qing Liu, Dai Dai, Xinyan Xiao, Hongyu\nLin, Xianpei Han, Le Sun, and Hua Wu. 2022. Uni-\nfied structure generation for universal information\nextraction. In Annual Meeting of the Association for\nComputational Linguistics .\nShervin Malmasi, Anjie Fang, Besnik Fetahu, Sudipta\nKar, and Oleg Rokhlenko. 2022. Multiconer: A large-\nscale multilingual dataset for complex named entity\nrecognition. In International Conference on Compu-\ntational Linguistics .\nAndrei Mikheev, Marc Moens, and Claire Grover. 1999.\nNamed entity recognition without gazetteers. In Con-\nference of the European Chapter of the Association\nfor Computational Linguistics .\nSewon Min, Xinxi Lyu, Ari Holtzman, Mikel Artetxe,\nMike Lewis, Hannaneh Hajishirzi, and Luke Zettle-\nmoyer. 2022. Rethinking the role of demonstra-\ntions: What makes in-context learning work? ArXiv ,\nabs/2202.12837.\nSwaroop Mishra, Daniel Khashabi, Chitta Baral, and\nHannaneh Hajishirzi. 2021. Cross-task generaliza-\ntion via natural language crowdsourcing instructions.\nInAnnual Meeting of the Association for Computa-\ntional Linguistics .\nDavid Nadeau, Peter D. Turney, and Stan Matwin. 2006.\nUnsupervised named-entity recognition: Generating\ngazetteers and resolving ambiguity. In Canadian\nConference on AI .\nOpenAI. 2023. Gpt-4 technical report.\nChengwei Qin, Aston Zhang, Zhuosheng Zhang, Jiaao\nChen, Michihiro Yasunaga, and Diyi Yang. 2023. Is\nchatgpt a general-purpose natural language process-\ning task solver? ArXiv , abs/2302.06476.Colin Raffel, Noam M. Shazeer, Adam Roberts, Kather-\nine Lee, Sharan Narang, Michael Matena, Yanqi\nZhou, Wei Li, and Peter J. Liu. 2019. Exploring the\nlimits of transfer learning with a unified text-to-text\ntransformer. J. Mach. Learn. Res. , 21:140:1\u2013140:67.\nLev-Arie Ratinov and Dan Roth. 2009. Design chal-\nlenges and misconceptions in named entity recog-\nnition. In Conference on Computational Natural\nLanguage Learning .\nBaptiste Rozi\u00e8re, Jonas Gehring, Fabian Gloeckle,\nSten Sootla, Itai Gat, Xiaoqing Tan, Yossi Adi,\nJingyu Liu, Tal Remez, J\u00e9r\u00e9my Rapin, Artyom\nKozhevnikov, I. Evtimov, Joanna Bitton, Manish P\nBhatt, Cristian Cant\u00f3n Ferrer, Aaron Grattafiori, Wen-\nhan Xiong, Alexandre D\u2019efossez, Jade Copet, Faisal\nAzhar, Hugo Touvron, Louis Martin, Nicolas Usunier,\nThomas Scialom, and Gabriel Synnaeve. 2023. Code\nllama: Open foundation models for code. ArXiv ,\nabs/2308.12950.\nOscar Sainz, Iker Garc\u00eda-Ferrero, Rodrigo Agerri,\nOier Lopez de Lacalle, German Rigau, and Eneko\nAgirre. 2023. Gollie: Annotation guidelines im-\nprove zero-shot information-extraction. ArXiv ,\nabs/2310.03668.\nSunita Sarawagi and William W. Cohen. 2004. Semi-\nmarkov conditional random fields for information\nextraction. In Neural Information Processing Sys-\ntems.\nHugo Touvron, Thibaut Lavril, Gautier Izacard, Xavier\nMartinet, Marie-Anne Lachaux, Timoth\u00e9e Lacroix,\nBaptiste Rozi\u00e8re, Naman Goyal, Eric Hambro, Faisal\nAzhar, Aurelien Rodriguez, Armand Joulin, Edouard\nGrave, and Guillaume Lample. 2023. Llama: Open\nand efficient foundation language models. ArXiv ,\nabs/2302.13971.\nXiao Wang, Wei Zhou, Can Zu, Han Xia, Tianze Chen,\nYuan Zhang, Rui Zheng, Junjie Ye, Qi Zhang, Tao\nGui, Jihua Kang, J. Yang, Siyuan Li, and Chun-\nsai Du. 2023. Instructuie: Multi-task instruction\ntuning for unified information extraction. ArXiv ,\nabs/2304.08085.\nYizhong Wang, Swaroop Mishra, Pegah Alipoor-\nmolabashi, Yeganeh Kordi, Amirreza Mirzaei,\nAnjana Arunkumar, Arjun Ashok, Arut Selvan\nDhanasekaran, Atharva Naik, David Stap, Eshaan\nPathak, Giannis Karamanolakis, Haizhi Gary Lai, Is-\nhan Purohit, Ishani Mondal, Jacob Anderson, Kirby\nKuznia, Krima Doshi, Maitreya Patel, Kuntal Kumar\nPal, M. Moradshahi, Mihir Parmar, Mirali Purohit,\nNeeraj Varshney, Phani Rohitha Kaza, Pulkit Verma,\nRavsehaj Singh Puri, Rushang Karia, Shailaja Keyur\nSampat, Savan Doshi, Siddharth Deepak Mishra, Su-\njan Reddy, Sumanta Patro, Tanay Dixit, Xudong\nShen, Chitta Baral, Yejin Choi, Noah A. Smith, Han-\nnaneh Hajishirzi, and Daniel Khashabi. 2022. Super-\nnaturalinstructions: Generalization via declarative\ninstructions on 1600+ nlp tasks. In Conference on\nEmpirical Methods in Natural Language Processing .\nJason Wei, Xuezhi Wang, Dale Schuurmans, Maarten\nBosma, Ed Huai hsin Chi, F. Xia, Quoc Le, and\nDenny Zhou. 2022. Chain of thought prompting\nelicits reasoning in large language models. ArXiv ,\nabs/2201.11903.\nRalph Weischedel, Sean Boisen, Daniel Bikel, Robert\nBobrow, Michael Crystal, William Ferguson, Allan\nWechsler, and The PLUM Research Group. 1996.\nProgress in information extraction. In TIPSTER\nTEXT PROGRAM PHASE II: Proceedings of a Work-\nshop held at Vienna, Virginia, May 6-8, 1996 , pages\n127\u2013138, Vienna, Virginia, USA. Association for\nComputational Linguistics.\nHang Yan, Tao Gui, Junqi Dai, Qipeng Guo, Zheng\nZhang, and Xipeng Qiu. 2021. A unified generative\nframework for various ner subtasks.\nZhilin Yang, Zihang Dai, Yiming Yang, Jaime G. Car-\nbonell, Ruslan Salakhutdinov, and Quoc V . Le. 2019.\nXlnet: Generalized autoregressive pretraining for lan-\nguage understanding. In Neural Information Process-\ning Systems .\nJunjie Ye, Xuanting Chen, Nuo Xu, Can Zu, Zekai\nShao, Shichun Liu, Yuhan Cui, Zeyang Zhou, Chao\nGong, Yang Shen, Jie Zhou, Siming Chen, Tao Gui,\nQi Zhang, and Xuanjing Huang. 2023. A comprehen-\nsive capability analysis of gpt-3 and gpt-3.5 series\nmodels. ArXiv , abs/2303.10420.\nNorshuhani Zamin and Alan Oxley. 2011. Building a\ncorpus-derived gazetteer for named entity recogni-\ntion. In International Conference on Software Engi-\nneering and Computer Systems .\nUrchade Zaratiana, Nadi Tomeh, Niama Elkhbir, Pierre\nHolat, and Thierry Charnois. 2023. Filtered semi-\nmarkov CRF.\nUrchade Zaratiana, Nadi Tomeh, Pierre Holat, and\nThierry Charnois. 2022. Named entity recognition\nas structured span prediction. In Proceedings of the\nWorkshop on Unimodal and Multimodal Induction\nof Linguistic Structures (UM-IoS) , pages 1\u201310, Abu\nDhabi, United Arab Emirates (Hybrid). Association\nfor Computational Linguistics.\nWenxuan Zhou, Sheng Zhang, Yu Gu, Muhao Chen,\nand Hoifung Poon. 2023. Universalner: Targeted dis-\ntillation from large language models for open named\nentity recognition.",
  "keywords": [
    "entities",
    "entity",
    "encoder",
    "ner1",
    "ner",
    "encoders",
    "corpus",
    "encode",
    "tokenized",
    "nlp"
  ],
  "intent_category": "named_entity_recognition",
  "named_entities": [
    {
      "text": "Generalist Model",
      "label": "PERSON"
    },
    {
      "text": "Bidirectional Transformer\nUrchade Zaratiana1,2",
      "label": "ORG"
    },
    {
      "text": "Nadi",
      "label": "GPE"
    },
    {
      "text": "Pierre Holat1,2",
      "label": "PERSON"
    },
    {
      "text": "Thierry",
      "label": "PERSON"
    },
    {
      "text": "1FI",
      "label": "CARDINAL"
    },
    {
      "text": "UMR 7030",
      "label": "PRODUCT"
    },
    {
      "text": "France",
      "label": "GPE"
    },
    {
      "text": "NER",
      "label": "ORG"
    },
    {
      "text": "Natural Language Processing",
      "label": "ORG"
    },
    {
      "text": "NLP",
      "label": "ORG"
    },
    {
      "text": "NER",
      "label": "ORG"
    },
    {
      "text": "Large Language Models",
      "label": "PERSON"
    },
    {
      "text": "NER",
      "label": "ORG"
    },
    {
      "text": "GPT",
      "label": "ORG"
    },
    {
      "text": "zero",
      "label": "CARDINAL"
    },
    {
      "text": "NER",
      "label": "ORG"
    },
    {
      "text": "1",
      "label": "CARDINAL"
    },
    {
      "text": "Recognition",
      "label": "ORG"
    },
    {
      "text": "NER",
      "label": "ORG"
    },
    {
      "text": "Large Language\nModels",
      "label": "PERSON"
    },
    {
      "text": "GPT-3",
      "label": "ORG"
    },
    {
      "text": "Brown et al.",
      "label": "PERSON"
    },
    {
      "text": "2020",
      "label": "DATE"
    },
    {
      "text": "NER",
      "label": "ORG"
    },
    {
      "text": "billions",
      "label": "CARDINAL"
    },
    {
      "text": "OpenAI",
      "label": "GPE"
    },
    {
      "text": "2023",
      "label": "DATE"
    },
    {
      "text": "\\n Text: Alain Farley",
      "label": "WORK_OF_ART"
    },
    {
      "text": "McGill University",
      "label": "ORG"
    },
    {
      "text": "BERT",
      "label": "ORG"
    },
    {
      "text": "ENT",
      "label": "ORG"
    },
    {
      "text": "ENT",
      "label": "ORG"
    },
    {
      "text": "SEP",
      "label": "ORG"
    },
    {
      "text": "Alain Farley",
      "label": "ORG"
    },
    {
      "text": "McGill Universitya",
      "label": "PERSON"
    },
    {
      "text": "Zhou",
      "label": "PERSON"
    },
    {
      "text": "2023",
      "label": "DATE"
    },
    {
      "text": "Fig",
      "label": "PERSON"
    },
    {
      "text": "NER",
      "label": "ORG"
    },
    {
      "text": "NER",
      "label": "ORG"
    },
    {
      "text": "LLaMa",
      "label": "PRODUCT"
    },
    {
      "text": "Touvron",
      "label": "ORG"
    },
    {
      "text": "2023",
      "label": "DATE"
    },
    {
      "text": "Wang et al.",
      "label": "PERSON"
    },
    {
      "text": "2023",
      "label": "DATE"
    },
    {
      "text": "InstructUIE",
      "label": "ORG"
    },
    {
      "text": "Raffel et al.",
      "label": "PERSON"
    },
    {
      "text": "2019",
      "label": "DATE"
    },
    {
      "text": "Chung",
      "label": "PERSON"
    },
    {
      "text": "al.",
      "label": "GPE"
    },
    {
      "text": "2022",
      "label": "DATE"
    },
    {
      "text": "zero",
      "label": "CARDINAL"
    },
    {
      "text": "GoLLIE",
      "label": "PERSON"
    },
    {
      "text": "Sainz",
      "label": "ORG"
    },
    {
      "text": "2023",
      "label": "DATE"
    },
    {
      "text": "InstructUIE",
      "label": "ORG"
    },
    {
      "text": "2023",
      "label": "DATE"
    },
    {
      "text": "Zhou",
      "label": "PERSON"
    },
    {
      "text": "2023",
      "label": "DATE"
    },
    {
      "text": "Uni-\nversalNER",
      "label": "ORG"
    },
    {
      "text": "14",
      "label": "CARDINAL"
    },
    {
      "text": "01245",
      "label": "CARDINAL"
    },
    {
      "text": "0.30.20.10.20.30.10.80.4",
      "label": "CARDINAL"
    },
    {
      "text": "BERT",
      "label": "ORG"
    },
    {
      "text": "0,0)(0,1)(1,1)(1,2)(2,2)(4,4)(4,5)(5,5)(Dot",
      "label": "CARDINAL"
    },
    {
      "text": "Token",
      "label": "ORG"
    },
    {
      "text": "EmbeddingsSpan",
      "label": "ORG"
    },
    {
      "text": "2",
      "label": "CARDINAL"
    },
    {
      "text": "BiLM",
      "label": "PRODUCT"
    },
    {
      "text": "ENT",
      "label": "ORG"
    },
    {
      "text": "BiLM",
      "label": "PERSON"
    },
    {
      "text": "0",
      "label": "CARDINAL"
    },
    {
      "text": "1",
      "label": "CARDINAL"
    },
    {
      "text": "Alain Farley",
      "label": "WORK_OF_ART"
    },
    {
      "text": "zero",
      "label": "CARDINAL"
    },
    {
      "text": "NER",
      "label": "ORG"
    },
    {
      "text": "several billion",
      "label": "CARDINAL"
    },
    {
      "text": "NER",
      "label": "ORG"
    },
    {
      "text": "Bidirectional Language Models",
      "label": "ORG"
    },
    {
      "text": "BiLM",
      "label": "PERSON"
    },
    {
      "text": "BERT",
      "label": "ORG"
    },
    {
      "text": "Devlin et al.",
      "label": "PERSON"
    },
    {
      "text": "2019",
      "label": "DATE"
    },
    {
      "text": "al.",
      "label": "PERSON"
    },
    {
      "text": "2021",
      "label": "DATE"
    },
    {
      "text": "Zhou",
      "label": "PERSON"
    },
    {
      "text": "2023",
      "label": "DATE"
    },
    {
      "text": "thousands",
      "label": "CARDINAL"
    },
    {
      "text": "zero",
      "label": "CARDINAL"
    },
    {
      "text": "zero",
      "label": "CARDINAL"
    },
    {
      "text": "NER",
      "label": "ORG"
    },
    {
      "text": "1",
      "label": "CARDINAL"
    },
    {
      "text": "8",
      "label": "CARDINAL"
    },
    {
      "text": "10",
      "label": "CARDINAL"
    },
    {
      "text": "3",
      "label": "CARDINAL"
    },
    {
      "text": "2",
      "label": "CARDINAL"
    },
    {
      "text": "Method",
      "label": "PRODUCT"
    },
    {
      "text": "Language Models",
      "label": "ORG"
    },
    {
      "text": "three",
      "label": "CARDINAL"
    },
    {
      "text": "BiLM",
      "label": "NORP"
    },
    {
      "text": "BERT",
      "label": "ORG"
    },
    {
      "text": "ken embeddings",
      "label": "PERSON"
    },
    {
      "text": "2",
      "label": "CARDINAL"
    },
    {
      "text": "2.1",
      "label": "CARDINAL"
    },
    {
      "text": "\\n Text: Alain Farley",
      "label": "WORK_OF_ART"
    },
    {
      "text": "McGill University",
      "label": "ORG"
    },
    {
      "text": "BERT",
      "label": "ORG"
    },
    {
      "text": "ENT",
      "label": "ORG"
    },
    {
      "text": "ENT",
      "label": "ORG"
    },
    {
      "text": "SEP",
      "label": "ORG"
    },
    {
      "text": "Alain Farley",
      "label": "ORG"
    },
    {
      "text": "McGill Universitya",
      "label": "PERSON"
    },
    {
      "text": "ENT",
      "label": "ORG"
    },
    {
      "text": "ENT",
      "label": "ORG"
    },
    {
      "text": "ENT",
      "label": "ORG"
    },
    {
      "text": "SEP",
      "label": "ORG"
    },
    {
      "text": "ENT",
      "label": "ORG"
    },
    {
      "text": "SEP",
      "label": "ORG"
    },
    {
      "text": "Letp={pi}M\u22121",
      "label": "GPE"
    },
    {
      "text": "ENT",
      "label": "ORG"
    },
    {
      "text": "first",
      "label": "ORDINAL"
    },
    {
      "text": "NER",
      "label": "ORG"
    },
    {
      "text": "Zaratiana",
      "label": "GPE"
    },
    {
      "text": "al.",
      "label": "GPE"
    },
    {
      "text": "2022",
      "label": "DATE"
    },
    {
      "text": "Entity and Span Representation",
      "label": "ORG"
    },
    {
      "text": "two",
      "label": "CARDINAL"
    },
    {
      "text": "0\u2208RM\u00d7D.",
      "label": "CARDINAL"
    },
    {
      "text": "1",
      "label": "CARDINAL"
    },
    {
      "text": "FFNdenotes",
      "label": "ORG"
    },
    {
      "text": "two",
      "label": "CARDINAL"
    },
    {
      "text": "\u03d5(i",
      "label": "PERSON"
    },
    {
      "text": "2",
      "label": "CARDINAL"
    },
    {
      "text": "sec",
      "label": "ORG"
    },
    {
      "text": "2.2",
      "label": "CARDINAL"
    },
    {
      "text": "\u03d5(i",
      "label": "PERSON"
    },
    {
      "text": "type t.\n",
      "label": "PERSON"
    },
    {
      "text": "2.2",
      "label": "CARDINAL"
    },
    {
      "text": "Sand",
      "label": "GPE"
    },
    {
      "text": "1",
      "label": "CARDINAL"
    },
    {
      "text": "0",
      "label": "CARDINAL"
    },
    {
      "text": "2.3",
      "label": "CARDINAL"
    },
    {
      "text": "Zaratiana",
      "label": "GPE"
    },
    {
      "text": "al.",
      "label": "GPE"
    },
    {
      "text": "2022",
      "label": "DATE"
    },
    {
      "text": "\u03d5(i",
      "label": "DATE"
    },
    {
      "text": "Algorithm Efficiency",
      "label": "ORG"
    },
    {
      "text": "Model Params Movie",
      "label": "PERSON"
    },
    {
      "text": "20.5",
      "label": "CARDINAL"
    },
    {
      "text": "13.0 13.0",
      "label": "TIME"
    },
    {
      "text": "13B",
      "label": "CARDINAL"
    },
    {
      "text": "0.9",
      "label": "PRODUCT"
    },
    {
      "text": "27.0",
      "label": "CARDINAL"
    },
    {
      "text": "22.0 17.5",
      "label": "CARDINAL"
    },
    {
      "text": "37.7",
      "label": "CARDINAL"
    },
    {
      "text": "17.7 28.2",
      "label": "CARDINAL"
    },
    {
      "text": "56.0",
      "label": "CARDINAL"
    },
    {
      "text": "36.1 44.0 37.8",
      "label": "CARDINAL"
    },
    {
      "text": "5.3",
      "label": "CARDINAL"
    },
    {
      "text": "52.4 39.8",
      "label": "QUANTITY"
    },
    {
      "text": "66.6",
      "label": "CARDINAL"
    },
    {
      "text": "68.5 67.0",
      "label": "CARDINAL"
    },
    {
      "text": "63.0 21.0",
      "label": "CARDINAL"
    },
    {
      "text": "49.0 47.2",
      "label": "CARDINAL"
    },
    {
      "text": "53.2",
      "label": "CARDINAL"
    },
    {
      "text": "48.1",
      "label": "CARDINAL"
    },
    {
      "text": "49.2 47.2",
      "label": "CARDINAL"
    },
    {
      "text": "42.4",
      "label": "CARDINAL"
    },
    {
      "text": "31.7",
      "label": "CARDINAL"
    },
    {
      "text": "53.6",
      "label": "CARDINAL"
    },
    {
      "text": "59.3 67.0",
      "label": "QUANTITY"
    },
    {
      "text": "60.9",
      "label": "CARDINAL"
    },
    {
      "text": "61.1 53.7",
      "label": "CARDINAL"
    },
    {
      "text": "48.7 36.2 54.2 60.9 64.5 61.4 63.5 55.6\nGoLLIE",
      "label": "QUANTITY"
    },
    {
      "text": "7B",
      "label": "CARDINAL"
    },
    {
      "text": "63.0 43.4",
      "label": "CARDINAL"
    },
    {
      "text": "62.7",
      "label": "CARDINAL"
    },
    {
      "text": "67.8",
      "label": "CARDINAL"
    },
    {
      "text": "57.2",
      "label": "CARDINAL"
    },
    {
      "text": "55.5 58.0",
      "label": "PERCENT"
    },
    {
      "text": "50",
      "label": "CARDINAL"
    },
    {
      "text": "60.9",
      "label": "CARDINAL"
    },
    {
      "text": "55.6 52.7",
      "label": "CARDINAL"
    },
    {
      "text": "51.8 59.7",
      "label": "PRODUCT"
    },
    {
      "text": "69.4",
      "label": "CARDINAL"
    },
    {
      "text": "68.6",
      "label": "CARDINAL"
    },
    {
      "text": "58.1 55.4",
      "label": "CARDINAL"
    },
    {
      "text": "57.2",
      "label": "CARDINAL"
    },
    {
      "text": "62.6 60.9",
      "label": "CARDINAL"
    },
    {
      "text": "Table 1: Zero-Shot Scores",
      "label": "PRODUCT"
    },
    {
      "text": "2021",
      "label": "DATE"
    },
    {
      "text": "Zhou",
      "label": "PERSON"
    },
    {
      "text": "2023",
      "label": "DATE"
    },
    {
      "text": "USM",
      "label": "ORG"
    },
    {
      "text": "InstructUIE",
      "label": "ORG"
    },
    {
      "text": "Wang",
      "label": "ORG"
    },
    {
      "text": "2023",
      "label": "DATE"
    },
    {
      "text": "GoLLIE",
      "label": "PERSON"
    },
    {
      "text": "Sainz",
      "label": "ORG"
    },
    {
      "text": "2023",
      "label": "DATE"
    },
    {
      "text": "3",
      "label": "CARDINAL"
    },
    {
      "text": "Experimental Setting",
      "label": "ORG"
    },
    {
      "text": "3.1",
      "label": "CARDINAL"
    },
    {
      "text": "NER",
      "label": "ORG"
    },
    {
      "text": "Zhou",
      "label": "PERSON"
    },
    {
      "text": "al",
      "label": "PERSON"
    },
    {
      "text": "2023",
      "label": "DATE"
    },
    {
      "text": "Pile-NER1",
      "label": "ORG"
    },
    {
      "text": "Pile",
      "label": "ORG"
    },
    {
      "text": "Gao et al.",
      "label": "PERSON"
    },
    {
      "text": "2020",
      "label": "DATE"
    },
    {
      "text": "Zhou",
      "label": "PERSON"
    },
    {
      "text": "2023",
      "label": "DATE"
    },
    {
      "text": "50,000",
      "label": "CARDINAL"
    },
    {
      "text": "Pile",
      "label": "ORG"
    },
    {
      "text": "ENT",
      "label": "ORG"
    },
    {
      "text": "ENT",
      "label": "ORG"
    },
    {
      "text": "ENT",
      "label": "ORG"
    },
    {
      "text": "SEP",
      "label": "ORG"
    },
    {
      "text": "1",
      "label": "CARDINAL"
    },
    {
      "text": "1",
      "label": "CARDINAL"
    },
    {
      "text": "3",
      "label": "CARDINAL"
    },
    {
      "text": "Zhou",
      "label": "PERSON"
    },
    {
      "text": "2023",
      "label": "DATE"
    },
    {
      "text": "Pile",
      "label": "ORG"
    },
    {
      "text": "44889",
      "label": "DATE"
    },
    {
      "text": "240k",
      "label": "CARDINAL"
    },
    {
      "text": "13k",
      "label": "DATE"
    },
    {
      "text": "1https://huggingface.co/datasets/Universal-NER/Pile-",
      "label": "CARDINAL"
    },
    {
      "text": "Pile",
      "label": "ORG"
    },
    {
      "text": "2021",
      "label": "DATE"
    },
    {
      "text": "768",
      "label": "CARDINAL"
    },
    {
      "text": "0.4",
      "label": "CARDINAL"
    },
    {
      "text": "Loshchilov",
      "label": "PERSON"
    },
    {
      "text": "Hutter",
      "label": "GPE"
    },
    {
      "text": "2017",
      "label": "DATE"
    },
    {
      "text": "1e-5",
      "label": "CARDINAL"
    },
    {
      "text": "FFN",
      "label": "ORG"
    },
    {
      "text": "30k",
      "label": "CARDINAL"
    },
    {
      "text": "10%",
      "label": "PERCENT"
    },
    {
      "text": "Sainz",
      "label": "ORG"
    },
    {
      "text": "al",
      "label": "PERSON"
    },
    {
      "text": "2023",
      "label": "DATE"
    },
    {
      "text": "25",
      "label": "CARDINAL"
    },
    {
      "text": "5 hours",
      "label": "TIME"
    },
    {
      "text": "3.3",
      "label": "CARDINAL"
    },
    {
      "text": "NER",
      "label": "ORG"
    },
    {
      "text": "First",
      "label": "ORDINAL"
    },
    {
      "text": "GPT andVicuna",
      "label": "PERSON"
    },
    {
      "text": "2023",
      "label": "DATE"
    },
    {
      "text": "Ye et al",
      "label": "PERSON"
    },
    {
      "text": "2023",
      "label": "DATE"
    },
    {
      "text": "Zhou",
      "label": "PERSON"
    },
    {
      "text": "2023",
      "label": "DATE"
    },
    {
      "text": "three",
      "label": "CARDINAL"
    },
    {
      "text": "Large Language\nModels",
      "label": "PERSON"
    },
    {
      "text": "NER",
      "label": "ORG"
    },
    {
      "text": "Wang",
      "label": "ORG"
    },
    {
      "text": "2023",
      "label": "DATE"
    },
    {
      "text": "11B",
      "label": "CARDINAL"
    },
    {
      "text": "NER",
      "label": "ORG"
    },
    {
      "text": "Zhou",
      "label": "PERSON"
    },
    {
      "text": "2023",
      "label": "DATE"
    },
    {
      "text": "LLaMa",
      "label": "PRODUCT"
    },
    {
      "text": "GoLLIE",
      "label": "PERSON"
    },
    {
      "text": "Sainz",
      "label": "ORG"
    },
    {
      "text": "2023",
      "label": "DATE"
    },
    {
      "text": "USM",
      "label": "PERSON"
    },
    {
      "text": "Lou et al.",
      "label": "PERSON"
    },
    {
      "text": "2023",
      "label": "DATE"
    },
    {
      "text": "3.4",
      "label": "CARDINAL"
    },
    {
      "text": "zero",
      "label": "CARDINAL"
    },
    {
      "text": "NER",
      "label": "ORG"
    },
    {
      "text": "Wang et al.",
      "label": "PERSON"
    },
    {
      "text": "2023",
      "label": "DATE"
    },
    {
      "text": "Zhou",
      "label": "PERSON"
    },
    {
      "text": "al.",
      "label": "PERSON"
    },
    {
      "text": "2023",
      "label": "DATE"
    },
    {
      "text": "first",
      "label": "ORDINAL"
    },
    {
      "text": "1",
      "label": "CARDINAL"
    },
    {
      "text": "seven",
      "label": "CARDINAL"
    },
    {
      "text": "NER",
      "label": "ORG"
    },
    {
      "text": "CrossNER",
      "label": "ORG"
    },
    {
      "text": "MIT",
      "label": "ORG"
    },
    {
      "text": "NER",
      "label": "ORG"
    },
    {
      "text": "second",
      "label": "ORDINAL"
    },
    {
      "text": "20",
      "label": "CARDINAL"
    },
    {
      "text": "NER",
      "label": "ORG"
    },
    {
      "text": "2",
      "label": "CARDINAL"
    },
    {
      "text": "NER",
      "label": "ORG"
    },
    {
      "text": "NER",
      "label": "ORG"
    },
    {
      "text": "3",
      "label": "CARDINAL"
    },
    {
      "text": "Malmasi",
      "label": "ORG"
    },
    {
      "text": "al.",
      "label": "PERSON"
    },
    {
      "text": "2022",
      "label": "DATE"
    },
    {
      "text": "11",
      "label": "CARDINAL"
    },
    {
      "text": "NER",
      "label": "ORG"
    },
    {
      "text": "F1",
      "label": "GPE"
    },
    {
      "text": "4",
      "label": "CARDINAL"
    },
    {
      "text": "4.1 Zero",
      "label": "CARDINAL"
    },
    {
      "text": "English",
      "label": "LANGUAGE"
    },
    {
      "text": "zero",
      "label": "CARDINAL"
    },
    {
      "text": "Pile",
      "label": "ORG"
    },
    {
      "text": "first",
      "label": "ORDINAL"
    },
    {
      "text": "Table",
      "label": "ORG"
    },
    {
      "text": "1",
      "label": "CARDINAL"
    },
    {
      "text": "three",
      "label": "CARDINAL"
    },
    {
      "text": "26.6",
      "label": "CARDINAL"
    },
    {
      "text": "27.3",
      "label": "CARDINAL"
    },
    {
      "text": "30.7",
      "label": "CARDINAL"
    },
    {
      "text": "33.3",
      "label": "CARDINAL"
    },
    {
      "text": "40.2",
      "label": "CARDINAL"
    },
    {
      "text": "46.2 47.9\nbc4chemd",
      "label": "QUANTITY"
    },
    {
      "text": "35.5",
      "label": "CARDINAL"
    },
    {
      "text": "47.9 43.1",
      "label": "QUANTITY"
    },
    {
      "text": "52.4",
      "label": "CARDINAL"
    },
    {
      "text": "68.0 66.4",
      "label": "PRODUCT"
    },
    {
      "text": "Broad Tweeter",
      "label": "ORG"
    },
    {
      "text": "61.8 67.9",
      "label": "CARDINAL"
    },
    {
      "text": "52.5",
      "label": "CARDINAL"
    },
    {
      "text": "64.6",
      "label": "CARDINAL"
    },
    {
      "text": "15.3",
      "label": "CARDINAL"
    },
    {
      "text": "24.8 23.6",
      "label": "CARDINAL"
    },
    {
      "text": "FindVehicle",
      "label": "ORG"
    },
    {
      "text": "22.2 41.9",
      "label": "CARDINAL"
    },
    {
      "text": "41.6",
      "label": "CARDINAL"
    },
    {
      "text": "54.1",
      "label": "CARDINAL"
    },
    {
      "text": "11.6 18.2",
      "label": "CARDINAL"
    },
    {
      "text": "MIT",
      "label": "ORG"
    },
    {
      "text": "5.3",
      "label": "CARDINAL"
    },
    {
      "text": "42.4 57.2",
      "label": "CARDINAL"
    },
    {
      "text": "MIT",
      "label": "ORG"
    },
    {
      "text": "31.7 42.9",
      "label": "CARDINAL"
    },
    {
      "text": "MultiNERD",
      "label": "GPE"
    },
    {
      "text": "58.1",
      "label": "CARDINAL"
    },
    {
      "text": "59.3 59.7",
      "label": "CARDINAL"
    },
    {
      "text": "OntoNotes",
      "label": "ORG"
    },
    {
      "text": "29.7",
      "label": "PRODUCT"
    },
    {
      "text": "40.1",
      "label": "CARDINAL"
    },
    {
      "text": "52.0",
      "label": "CARDINAL"
    },
    {
      "text": "55.4 58.9",
      "label": "CARDINAL"
    },
    {
      "text": "57.7",
      "label": "CARDINAL"
    },
    {
      "text": "69.2 71.8",
      "label": "CARDINAL"
    },
    {
      "text": "45.7 47.8",
      "label": "CARDINAL"
    },
    {
      "text": "2",
      "label": "CARDINAL"
    },
    {
      "text": "20",
      "label": "CARDINAL"
    },
    {
      "text": "NER",
      "label": "ORG"
    },
    {
      "text": "Zhou et al.",
      "label": "PERSON"
    },
    {
      "text": "2023",
      "label": "DATE"
    },
    {
      "text": "only 50",
      "label": "CARDINAL"
    },
    {
      "text": "Vicuna",
      "label": "PERSON"
    },
    {
      "text": "NER",
      "label": "ORG"
    },
    {
      "text": "UniNER",
      "label": "ORG"
    },
    {
      "text": "UniNER-13B",
      "label": "GPE"
    },
    {
      "text": "55",
      "label": "CARDINAL"
    },
    {
      "text": "140",
      "label": "CARDINAL"
    },
    {
      "text": "5",
      "label": "CARDINAL"
    },
    {
      "text": "GoLLIE",
      "label": "PERSON"
    },
    {
      "text": "20",
      "label": "CARDINAL"
    },
    {
      "text": "NER",
      "label": "ORG"
    },
    {
      "text": "2",
      "label": "CARDINAL"
    },
    {
      "text": "20",
      "label": "CARDINAL"
    },
    {
      "text": "NER",
      "label": "ORG"
    },
    {
      "text": "First",
      "label": "ORDINAL"
    },
    {
      "text": "NER",
      "label": "ORG"
    },
    {
      "text": "13",
      "label": "CARDINAL"
    },
    {
      "text": "2",
      "label": "CARDINAL"
    },
    {
      "text": "Language Sup",
      "label": "ORG"
    },
    {
      "text": "64.6",
      "label": "CARDINAL"
    },
    {
      "text": "35.6 39.5",
      "label": "QUANTITY"
    },
    {
      "text": "62.7",
      "label": "CARDINAL"
    },
    {
      "text": "42.4 41.7",
      "label": "CARDINAL"
    },
    {
      "text": "58.7 34.7",
      "label": "MONEY"
    },
    {
      "text": "38.7 42.1",
      "label": "PRODUCT"
    },
    {
      "text": "62.6 35.7",
      "label": "CARDINAL"
    },
    {
      "text": "35.6",
      "label": "CARDINAL"
    },
    {
      "text": "23.3",
      "label": "CARDINAL"
    },
    {
      "text": "0.89 25.9",
      "label": "CARDINAL"
    },
    {
      "text": "Persian",
      "label": "NORP"
    },
    {
      "text": "25.9",
      "label": "CARDINAL"
    },
    {
      "text": "14.9",
      "label": "CARDINAL"
    },
    {
      "text": "47.8",
      "label": "CARDINAL"
    },
    {
      "text": "11.3 27.8",
      "label": "CARDINAL"
    },
    {
      "text": "Korean",
      "label": "NORP"
    },
    {
      "text": "55.8 30.0",
      "label": "CARDINAL"
    },
    {
      "text": "20.5 28.7",
      "label": "CARDINAL"
    },
    {
      "text": "Russian",
      "label": "NORP"
    },
    {
      "text": "33.3",
      "label": "CARDINAL"
    },
    {
      "text": "46.8",
      "label": "CARDINAL"
    },
    {
      "text": "22.0 30.0",
      "label": "CARDINAL"
    },
    {
      "text": "Chinese",
      "label": "NORP"
    },
    {
      "text": "53.1",
      "label": "CARDINAL"
    },
    {
      "text": "18.8",
      "label": "CARDINAL"
    },
    {
      "text": "6.59 24.3",
      "label": "EVENT"
    },
    {
      "text": "54.9",
      "label": "CARDINAL"
    },
    {
      "text": "23.6 32.9",
      "label": "CARDINAL"
    },
    {
      "text": "3",
      "label": "CARDINAL"
    },
    {
      "text": "Sup",
      "label": "PERSON"
    },
    {
      "text": "2019",
      "label": "DATE"
    },
    {
      "text": "Malmasi",
      "label": "ORG"
    },
    {
      "text": "2022",
      "label": "DATE"
    },
    {
      "text": "Lai et al.",
      "label": "PERSON"
    },
    {
      "text": "2023",
      "label": "DATE"
    },
    {
      "text": "Multi",
      "label": "ORG"
    },
    {
      "text": "mdeBERTa",
      "label": "CARDINAL"
    },
    {
      "text": "NER",
      "label": "ORG"
    },
    {
      "text": "4.2 Zero",
      "label": "CARDINAL"
    },
    {
      "text": "zero",
      "label": "CARDINAL"
    },
    {
      "text": "Multiconel",
      "label": "PERSON"
    },
    {
      "text": "3",
      "label": "CARDINAL"
    },
    {
      "text": "two",
      "label": "CARDINAL"
    },
    {
      "text": "Multi",
      "label": "GPE"
    },
    {
      "text": "mdeBERTa-v3",
      "label": "QUANTITY"
    },
    {
      "text": "Pile",
      "label": "ORG"
    },
    {
      "text": "zero",
      "label": "CARDINAL"
    },
    {
      "text": "Pile-NER",
      "label": "ORG"
    },
    {
      "text": "English",
      "label": "LANGUAGE"
    },
    {
      "text": "Spanish",
      "label": "NORP"
    },
    {
      "text": "English",
      "label": "LANGUAGE"
    },
    {
      "text": "LatinDatasetInstructUIE",
      "label": "GPE"
    },
    {
      "text": "79.9",
      "label": "CARDINAL"
    },
    {
      "text": "86.7",
      "label": "CARDINAL"
    },
    {
      "text": "82.8",
      "label": "DATE"
    },
    {
      "text": "81.3",
      "label": "DATE"
    },
    {
      "text": "88.5",
      "label": "CARDINAL"
    },
    {
      "text": "80.7",
      "label": "CARDINAL"
    },
    {
      "text": "82.4",
      "label": "CARDINAL"
    },
    {
      "text": "83.7 82.0\nbc4chemd 87.6 89.2 87.9 86.7",
      "label": "QUANTITY"
    },
    {
      "text": "89.0 89.3 88.7 88.7",
      "label": "QUANTITY"
    },
    {
      "text": "80.3 81.2 82.5 82.7",
      "label": "QUANTITY"
    },
    {
      "text": "91.5",
      "label": "CARDINAL"
    },
    {
      "text": "92.6 92.5",
      "label": "CARDINAL"
    },
    {
      "text": "78.4",
      "label": "CARDINAL"
    },
    {
      "text": "77.8 74.8",
      "label": "CARDINAL"
    },
    {
      "text": "FindVehicle",
      "label": "ORG"
    },
    {
      "text": "98.3",
      "label": "CARDINAL"
    },
    {
      "text": "95.7 95.2",
      "label": "CARDINAL"
    },
    {
      "text": "75.7 77.5 78.9 77.4",
      "label": "QUANTITY"
    },
    {
      "text": "68.6 67.4",
      "label": "CARDINAL"
    },
    {
      "text": "MIT",
      "label": "ORG"
    },
    {
      "text": "89.6",
      "label": "CARDINAL"
    },
    {
      "text": "90.2",
      "label": "CARDINAL"
    },
    {
      "text": "87.5",
      "label": "CARDINAL"
    },
    {
      "text": "MIT",
      "label": "ORG"
    },
    {
      "text": "83.6 83.3",
      "label": "CARDINAL"
    },
    {
      "text": "MultiNERD",
      "label": "GPE"
    },
    {
      "text": "90.3",
      "label": "CARDINAL"
    },
    {
      "text": "93.7",
      "label": "CARDINAL"
    },
    {
      "text": "93.8 93.3",
      "label": "CARDINAL"
    },
    {
      "text": "87.0",
      "label": "PRODUCT"
    },
    {
      "text": "87.8",
      "label": "CARDINAL"
    },
    {
      "text": "87.1",
      "label": "CARDINAL"
    },
    {
      "text": "OntoNotes",
      "label": "ORG"
    },
    {
      "text": "88.6 89.9",
      "label": "PRODUCT"
    },
    {
      "text": "89.0 88.1",
      "label": "CARDINAL"
    },
    {
      "text": "PolyglotNER",
      "label": "ORG"
    },
    {
      "text": "65.7 61.5 60.6",
      "label": "CARDINAL"
    },
    {
      "text": "65.9",
      "label": "CARDINAL"
    },
    {
      "text": "51.4 50.3",
      "label": "CARDINAL"
    },
    {
      "text": "64.5",
      "label": "CARDINAL"
    },
    {
      "text": "84.9",
      "label": "PRODUCT"
    },
    {
      "text": "83.7 82.8",
      "label": "EVENT"
    },
    {
      "text": "88.3",
      "label": "CARDINAL"
    },
    {
      "text": "91.3 91.4",
      "label": "CARDINAL"
    },
    {
      "text": "81.2",
      "label": "CARDINAL"
    },
    {
      "text": "82.1",
      "label": "CARDINAL"
    },
    {
      "text": "4",
      "label": "CARDINAL"
    },
    {
      "text": "Pile",
      "label": "ORG"
    },
    {
      "text": "Spanish",
      "label": "NORP"
    },
    {
      "text": "German",
      "label": "NORP"
    },
    {
      "text": "Latin",
      "label": "NORP"
    },
    {
      "text": "Bengali",
      "label": "NORP"
    },
    {
      "text": "only 0.89",
      "label": "CARDINAL"
    },
    {
      "text": "F1",
      "label": "GPE"
    },
    {
      "text": "4.3",
      "label": "CARDINAL"
    },
    {
      "text": "20",
      "label": "CARDINAL"
    },
    {
      "text": "NER",
      "label": "ORG"
    },
    {
      "text": "InstructUIE",
      "label": "ORG"
    },
    {
      "text": "UniNER",
      "label": "ORG"
    },
    {
      "text": "Pile",
      "label": "ORG"
    },
    {
      "text": "10,000",
      "label": "CARDINAL"
    },
    {
      "text": "20",
      "label": "CARDINAL"
    },
    {
      "text": "NER",
      "label": "ORG"
    },
    {
      "text": "10,000",
      "label": "CARDINAL"
    },
    {
      "text": "two",
      "label": "CARDINAL"
    },
    {
      "text": "first",
      "label": "ORDINAL"
    },
    {
      "text": "zero",
      "label": "CARDINAL"
    },
    {
      "text": "second",
      "label": "ORDINAL"
    },
    {
      "text": "Pile",
      "label": "ORG"
    },
    {
      "text": "InstructUIE",
      "label": "ORG"
    },
    {
      "text": "50",
      "label": "CARDINAL"
    },
    {
      "text": "54 55",
      "label": "DATE"
    },
    {
      "text": "Avg",
      "label": "PERSON"
    },
    {
      "text": "zero",
      "label": "CARDINAL"
    },
    {
      "text": "F1",
      "label": "GPE"
    },
    {
      "text": "NER",
      "label": "ORG"
    },
    {
      "text": "zero",
      "label": "CARDINAL"
    },
    {
      "text": "F1",
      "label": "GPE"
    },
    {
      "text": "20",
      "label": "CARDINAL"
    },
    {
      "text": "NER",
      "label": "ORG"
    },
    {
      "text": "4",
      "label": "CARDINAL"
    },
    {
      "text": "Zero",
      "label": "CARDINAL"
    },
    {
      "text": "20",
      "label": "CARDINAL"
    },
    {
      "text": "NER",
      "label": "ORG"
    },
    {
      "text": "NER",
      "label": "ORG"
    },
    {
      "text": "Table 3",
      "label": "LAW"
    },
    {
      "text": "Firstly",
      "label": "ORDINAL"
    },
    {
      "text": "Pile-NER",
      "label": "ORG"
    },
    {
      "text": "0.8",
      "label": "CARDINAL"
    },
    {
      "text": "InstructUIE",
      "label": "PERSON"
    },
    {
      "text": "0.9",
      "label": "CARDINAL"
    },
    {
      "text": "InstructUIE",
      "label": "ORG"
    },
    {
      "text": "approximately 30",
      "label": "CARDINAL"
    },
    {
      "text": "almost 3",
      "label": "CARDINAL"
    },
    {
      "text": "7",
      "label": "CARDINAL"
    },
    {
      "text": "20",
      "label": "CARDINAL"
    },
    {
      "text": "5",
      "label": "CARDINAL"
    },
    {
      "text": "5.1",
      "label": "CARDINAL"
    },
    {
      "text": "Setup Specifically",
      "label": "PERSON"
    },
    {
      "text": "BERT",
      "label": "ORG"
    },
    {
      "text": "Devlin et al.",
      "label": "PERSON"
    },
    {
      "text": "2019",
      "label": "DATE"
    },
    {
      "text": "Liu et al.",
      "label": "PERSON"
    },
    {
      "text": "2019",
      "label": "DATE"
    },
    {
      "text": "AlBERT",
      "label": "PERSON"
    },
    {
      "text": "Lan et al.",
      "label": "PERSON"
    },
    {
      "text": "2019",
      "label": "DATE"
    },
    {
      "text": "Clark et al.",
      "label": "PERSON"
    },
    {
      "text": "2020",
      "label": "DATE"
    },
    {
      "text": "XLNet",
      "label": "ORG"
    },
    {
      "text": "2019",
      "label": "DATE"
    },
    {
      "text": "Dataset",
      "label": "ORG"
    },
    {
      "text": "5",
      "label": "CARDINAL"
    },
    {
      "text": "20",
      "label": "CARDINAL"
    },
    {
      "text": "NER",
      "label": "ORG"
    },
    {
      "text": "4",
      "label": "CARDINAL"
    },
    {
      "text": "zero",
      "label": "CARDINAL"
    },
    {
      "text": "20",
      "label": "CARDINAL"
    },
    {
      "text": "NER",
      "label": "ORG"
    },
    {
      "text": "4",
      "label": "CARDINAL"
    },
    {
      "text": "4",
      "label": "CARDINAL"
    },
    {
      "text": "AlBERT",
      "label": "PERSON"
    },
    {
      "text": "BERT",
      "label": "ORG"
    },
    {
      "text": "BERT",
      "label": "ORG"
    },
    {
      "text": "49",
      "label": "DATE"
    },
    {
      "text": "2 F1",
      "label": "CARDINAL"
    },
    {
      "text": "InstructUIE",
      "label": "ORG"
    },
    {
      "text": "5.2",
      "label": "CARDINAL"
    },
    {
      "text": "Pile",
      "label": "ORG"
    },
    {
      "text": "20",
      "label": "CARDINAL"
    },
    {
      "text": "NER",
      "label": "ORG"
    },
    {
      "text": "100",
      "label": "CARDINAL"
    },
    {
      "text": "10,000",
      "label": "CARDINAL"
    },
    {
      "text": "5",
      "label": "CARDINAL"
    },
    {
      "text": "Pile-NER",
      "label": "ORG"
    },
    {
      "text": "5.6",
      "label": "CARDINAL"
    },
    {
      "text": "100",
      "label": "CARDINAL"
    },
    {
      "text": "0%",
      "label": "PERCENT"
    },
    {
      "text": "49.3 58.1 53.3",
      "label": "CARDINAL"
    },
    {
      "text": "50%",
      "label": "PERCENT"
    },
    {
      "text": "62.3 59.7 60.9",
      "label": "QUANTITY"
    },
    {
      "text": "75%",
      "label": "PERCENT"
    },
    {
      "text": "61.1 56.5 58.6",
      "label": "CARDINAL"
    },
    {
      "text": "5",
      "label": "CARDINAL"
    },
    {
      "text": "5.3",
      "label": "CARDINAL"
    },
    {
      "text": "Ablations\nNegative Entity Sampling",
      "label": "ORG"
    },
    {
      "text": "NER",
      "label": "ORG"
    },
    {
      "text": "Zhou",
      "label": "PERSON"
    },
    {
      "text": "2023",
      "label": "DATE"
    },
    {
      "text": "3.2",
      "label": "CARDINAL"
    },
    {
      "text": "0%",
      "label": "PERCENT"
    },
    {
      "text": "50%",
      "label": "PERCENT"
    },
    {
      "text": "75%",
      "label": "PERCENT"
    },
    {
      "text": "75%",
      "label": "PERCENT"
    },
    {
      "text": "50%",
      "label": "PERCENT"
    },
    {
      "text": "1.4",
      "label": "CARDINAL"
    },
    {
      "text": "5",
      "label": "CARDINAL"
    },
    {
      "text": "NLP",
      "label": "ORG"
    },
    {
      "text": "NER",
      "label": "ORG"
    },
    {
      "text": "Weischedel et al.",
      "label": "PERSON"
    },
    {
      "text": "1996",
      "label": "DATE"
    },
    {
      "text": "Mikheev",
      "label": "PRODUCT"
    },
    {
      "text": "1999",
      "label": "DATE"
    },
    {
      "text": "Nadeau",
      "label": "PERSON"
    },
    {
      "text": "2006",
      "label": "DATE"
    },
    {
      "text": "Zamin",
      "label": "ORG"
    },
    {
      "text": "Oxley",
      "label": "PERSON"
    },
    {
      "text": "2011",
      "label": "DATE"
    },
    {
      "text": "Lafferty et al.",
      "label": "LOC"
    },
    {
      "text": "2001",
      "label": "DATE"
    },
    {
      "text": "NER",
      "label": "ORG"
    },
    {
      "text": "50",
      "label": "CARDINAL"
    },
    {
      "text": "54",
      "label": "DATE"
    },
    {
      "text": "56",
      "label": "DATE"
    },
    {
      "text": "58",
      "label": "DATE"
    },
    {
      "text": "60 62",
      "label": "DATE"
    },
    {
      "text": "Avg",
      "label": "PERSON"
    },
    {
      "text": "Neg",
      "label": "PERSON"
    },
    {
      "text": "59.50",
      "label": "CARDINAL"
    },
    {
      "text": "53.30",
      "label": "CARDINAL"
    },
    {
      "text": "6",
      "label": "CARDINAL"
    },
    {
      "text": "Huang et al.",
      "label": "PERSON"
    },
    {
      "text": "2015",
      "label": "DATE"
    },
    {
      "text": "Lample et al.",
      "label": "ORG"
    },
    {
      "text": "2016",
      "label": "DATE"
    },
    {
      "text": "Akbik",
      "label": "PERSON"
    },
    {
      "text": "2018",
      "label": "DATE"
    },
    {
      "text": "Ratinov",
      "label": "PERSON"
    },
    {
      "text": "Roth",
      "label": "PERSON"
    },
    {
      "text": "2009",
      "label": "DATE"
    },
    {
      "text": "NER",
      "label": "ORG"
    },
    {
      "text": "Sarawagi",
      "label": "NORP"
    },
    {
      "text": "2004",
      "label": "DATE"
    },
    {
      "text": "Fu et al.",
      "label": "PERSON"
    },
    {
      "text": "2021",
      "label": "DATE"
    },
    {
      "text": "Li et al.",
      "label": "PERSON"
    },
    {
      "text": "2021",
      "label": "DATE"
    },
    {
      "text": "Zaratiana",
      "label": "GPE"
    },
    {
      "text": "al.",
      "label": "GPE"
    },
    {
      "text": "2023",
      "label": "DATE"
    },
    {
      "text": "NER",
      "label": "ORG"
    },
    {
      "text": "Li et al.",
      "label": "PERSON"
    },
    {
      "text": "2019",
      "label": "DATE"
    },
    {
      "text": "Yan et al.",
      "label": "PERSON"
    },
    {
      "text": "2021",
      "label": "DATE"
    },
    {
      "text": "Zero",
      "label": "CARDINAL"
    },
    {
      "text": "NER",
      "label": "ORG"
    },
    {
      "text": "NLP",
      "label": "ORG"
    },
    {
      "text": "2022",
      "label": "DATE"
    },
    {
      "text": "Wei",
      "label": "PERSON"
    },
    {
      "text": "al.",
      "label": "PERSON"
    },
    {
      "text": "2022",
      "label": "DATE"
    },
    {
      "text": "Qin",
      "label": "PERSON"
    },
    {
      "text": "2023",
      "label": "DATE"
    },
    {
      "text": "NER",
      "label": "ORG"
    },
    {
      "text": "Li et al.",
      "label": "PERSON"
    },
    {
      "text": "2022",
      "label": "DATE"
    },
    {
      "text": "Ashok",
      "label": "ORG"
    },
    {
      "text": "Lipton",
      "label": "ORG"
    },
    {
      "text": "2023",
      "label": "DATE"
    },
    {
      "text": "Agrawal et al.",
      "label": "PERSON"
    },
    {
      "text": "2022",
      "label": "DATE"
    },
    {
      "text": "al.",
      "label": "PERSON"
    },
    {
      "text": "2021",
      "label": "DATE"
    },
    {
      "text": "Zhou",
      "label": "PERSON"
    },
    {
      "text": "2023",
      "label": "DATE"
    },
    {
      "text": "Lou et al.",
      "label": "PERSON"
    },
    {
      "text": "2023",
      "label": "DATE"
    },
    {
      "text": "Wang",
      "label": "ORG"
    },
    {
      "text": "2023",
      "label": "DATE"
    },
    {
      "text": "Sainz",
      "label": "ORG"
    },
    {
      "text": "2023",
      "label": "DATE"
    },
    {
      "text": "Lu",
      "label": "PERSON"
    },
    {
      "text": "2022",
      "label": "DATE"
    },
    {
      "text": "Mishra et al.",
      "label": "PERSON"
    },
    {
      "text": "2021",
      "label": "DATE"
    },
    {
      "text": "Wang",
      "label": "ORG"
    },
    {
      "text": "2022",
      "label": "DATE"
    },
    {
      "text": "Longpre et al.",
      "label": "ORG"
    },
    {
      "text": "2023",
      "label": "DATE"
    },
    {
      "text": "zero",
      "label": "CARDINAL"
    },
    {
      "text": "Monica Agrawal",
      "label": "PERSON"
    },
    {
      "text": "Stefan Hegselmann",
      "label": "PERSON"
    },
    {
      "text": "Hunter Lang",
      "label": "PERSON"
    },
    {
      "text": "Yoon Kim",
      "label": "PERSON"
    },
    {
      "text": "David A. Sontag",
      "label": "PERSON"
    },
    {
      "text": "2022",
      "label": "DATE"
    },
    {
      "text": "Natural Language Processing",
      "label": "WORK_OF_ART"
    },
    {
      "text": "Alan Akbik",
      "label": "PERSON"
    },
    {
      "text": "Duncan Blythe",
      "label": "PERSON"
    },
    {
      "text": "Roland",
      "label": "GPE"
    },
    {
      "text": "2018",
      "label": "DATE"
    },
    {
      "text": "Computational Linguistics",
      "label": "PERSON"
    },
    {
      "text": "1638",
      "label": "DATE"
    },
    {
      "text": "1649",
      "label": "DATE"
    },
    {
      "text": "Santa Fe",
      "label": "ORG"
    },
    {
      "text": "New Mexico",
      "label": "GPE"
    },
    {
      "text": "USA",
      "label": "GPE"
    },
    {
      "text": "Computational Linguistics",
      "label": "PERSON"
    },
    {
      "text": "Dhananjay Ashok",
      "label": "ORG"
    },
    {
      "text": "Zachary Chase Lipton",
      "label": "ORG"
    },
    {
      "text": "2023",
      "label": "DATE"
    },
    {
      "text": "ArXiv",
      "label": "PRODUCT"
    },
    {
      "text": "Tom B. Brown",
      "label": "PERSON"
    },
    {
      "text": "Benjamin Mann",
      "label": "PERSON"
    },
    {
      "text": "Nick Ryder",
      "label": "PERSON"
    },
    {
      "text": "Melanie",
      "label": "PERSON"
    },
    {
      "text": "Subbiah",
      "label": "GPE"
    },
    {
      "text": "Jared Kaplan",
      "label": "PERSON"
    },
    {
      "text": "Pranav Shyam",
      "label": "PERSON"
    },
    {
      "text": "Girish Sastry",
      "label": "PERSON"
    },
    {
      "text": "Amanda",
      "label": "ORG"
    },
    {
      "text": "Askell, Sandhini Agarwal",
      "label": "ORG"
    },
    {
      "text": "Ariel Herbert-V",
      "label": "PERSON"
    },
    {
      "text": "Gretchen Krueger",
      "label": "PERSON"
    },
    {
      "text": "T. J. Henighan",
      "label": "PERSON"
    },
    {
      "text": "Rewon Child",
      "label": "PERSON"
    },
    {
      "text": "Aditya Ramesh",
      "label": "PERSON"
    },
    {
      "text": "Daniel M. Ziegler",
      "label": "PERSON"
    },
    {
      "text": "Jeff Wu",
      "label": "PERSON"
    },
    {
      "text": "Clemens\nWinter",
      "label": "DATE"
    },
    {
      "text": "Christopher Hesse",
      "label": "PERSON"
    },
    {
      "text": "Mark Chen",
      "label": "PERSON"
    },
    {
      "text": "Eric Sigler",
      "label": "PERSON"
    },
    {
      "text": "Mateusz Litwin",
      "label": "PERSON"
    },
    {
      "text": "Scott Gray",
      "label": "PERSON"
    },
    {
      "text": "Benjamin Chess",
      "label": "PERSON"
    },
    {
      "text": "Jack\nClark",
      "label": "PERSON"
    },
    {
      "text": "Christopher Berner",
      "label": "PERSON"
    },
    {
      "text": "Sam McCandlish",
      "label": "PERSON"
    },
    {
      "text": "Alec\nRadford",
      "label": "PERSON"
    },
    {
      "text": "Dario Amodei",
      "label": "PERSON"
    },
    {
      "text": "2020",
      "label": "DATE"
    },
    {
      "text": "Wei-Lin Chiang",
      "label": "PERSON"
    },
    {
      "text": "Zhuohan Li",
      "label": "PERSON"
    },
    {
      "text": "Zi Lin",
      "label": "PERSON"
    },
    {
      "text": "Ying Sheng",
      "label": "PERSON"
    },
    {
      "text": "Zhanghao Wu",
      "label": "PERSON"
    },
    {
      "text": "Hao Zhang",
      "label": "PERSON"
    },
    {
      "text": "Lianmin Zheng",
      "label": "PERSON"
    },
    {
      "text": "Siyuan\nZhuang",
      "label": "PERSON"
    },
    {
      "text": "Yonghao Zhuang",
      "label": "PERSON"
    },
    {
      "text": "Joseph E. Gonzalez",
      "label": "PERSON"
    },
    {
      "text": "Ion\nStoica",
      "label": "PERSON"
    },
    {
      "text": "Eric P. Xing",
      "label": "PERSON"
    },
    {
      "text": "2023",
      "label": "DATE"
    },
    {
      "text": "90%",
      "label": "PERCENT"
    },
    {
      "text": "Hyung Won Chung",
      "label": "PERSON"
    },
    {
      "text": "Le Hou",
      "label": "ORG"
    },
    {
      "text": "Shayne Longpre",
      "label": "PERSON"
    },
    {
      "text": "Barret\nZoph",
      "label": "PERSON"
    },
    {
      "text": "Yi Tay",
      "label": "PERSON"
    },
    {
      "text": "William Fedus",
      "label": "PERSON"
    },
    {
      "text": "Yunxuan Li",
      "label": "PERSON"
    },
    {
      "text": "Xuezhi\nWang",
      "label": "PERSON"
    },
    {
      "text": "Mostafa Dehghani",
      "label": "PERSON"
    },
    {
      "text": "Siddhartha Brahma",
      "label": "PERSON"
    },
    {
      "text": "bert Webson",
      "label": "PERSON"
    },
    {
      "text": "Shixiang Shane Gu",
      "label": "PERSON"
    },
    {
      "text": "Zhuyun Dai",
      "label": "PERSON"
    },
    {
      "text": "Mirac Suzgun",
      "label": "PERSON"
    },
    {
      "text": "Xinyun Chen",
      "label": "PERSON"
    },
    {
      "text": "Aakanksha Chowdh-",
      "label": "PERSON"
    },
    {
      "text": "Alex Castro-Ros",
      "label": "PERSON"
    },
    {
      "text": "Marie Pellat",
      "label": "PERSON"
    },
    {
      "text": "Kevin Robinson",
      "label": "PERSON"
    },
    {
      "text": "Dasha Valter",
      "label": "PERSON"
    },
    {
      "text": "Sharan Narang",
      "label": "PERSON"
    },
    {
      "text": "Gaurav Mishra",
      "label": "PERSON"
    },
    {
      "text": "Adams\nYu",
      "label": "PERSON"
    },
    {
      "text": "Vincent Zhao",
      "label": "PERSON"
    },
    {
      "text": "Yanping Huang",
      "label": "PERSON"
    },
    {
      "text": "Andrew Dai",
      "label": "PERSON"
    },
    {
      "text": "Hongkun Yu",
      "label": "PERSON"
    },
    {
      "text": "Slav Petrov",
      "label": "PERSON"
    },
    {
      "text": "Ed H. Chi",
      "label": "PERSON"
    },
    {
      "text": "Jeff Dean",
      "label": "PERSON"
    },
    {
      "text": "Devlin",
      "label": "ORG"
    },
    {
      "text": "Adam Roberts",
      "label": "PERSON"
    },
    {
      "text": "Denny Zhou",
      "label": "PERSON"
    },
    {
      "text": "Quoc V .",
      "label": "PERSON"
    },
    {
      "text": "Jason Wei",
      "label": "PERSON"
    },
    {
      "text": "2022",
      "label": "DATE"
    },
    {
      "text": "Kevin Clark",
      "label": "PERSON"
    },
    {
      "text": "Thang Luong",
      "label": "PERSON"
    },
    {
      "text": "Quoc V .",
      "label": "ORG"
    },
    {
      "text": "Christopher D. Manning",
      "label": "PERSON"
    },
    {
      "text": "2020",
      "label": "DATE"
    },
    {
      "text": "Alexis Conneau",
      "label": "PERSON"
    },
    {
      "text": "Kartikay Khandelwal",
      "label": "PERSON"
    },
    {
      "text": "Naman Goyal",
      "label": "ORG"
    },
    {
      "text": "Vishrav Chaudhary",
      "label": "PERSON"
    },
    {
      "text": "Guillaume Wenzek",
      "label": "PERSON"
    },
    {
      "text": "Francisco\nGuzm\u00e1n",
      "label": "PERSON"
    },
    {
      "text": "Edouard Grave",
      "label": "PERSON"
    },
    {
      "text": "Myle Ott",
      "label": "PERSON"
    },
    {
      "text": "Luke Zettle-",
      "label": "PERSON"
    },
    {
      "text": "Veselin Stoyanov",
      "label": "PERSON"
    },
    {
      "text": "2019",
      "label": "DATE"
    },
    {
      "text": "the Association for Computational\nLinguistics .Leyang",
      "label": "ORG"
    },
    {
      "text": "Yu Wu",
      "label": "PERSON"
    },
    {
      "text": "Jian Liu",
      "label": "PERSON"
    },
    {
      "text": "Sen Yang",
      "label": "PERSON"
    },
    {
      "text": "Yue Zhang",
      "label": "PERSON"
    },
    {
      "text": "2021",
      "label": "DATE"
    },
    {
      "text": "bart",
      "label": "ORG"
    },
    {
      "text": "Findings",
      "label": "GPE"
    },
    {
      "text": "Jacob Devlin",
      "label": "PERSON"
    },
    {
      "text": "Ming-Wei Chang",
      "label": "PERSON"
    },
    {
      "text": "Kenton Lee",
      "label": "PERSON"
    },
    {
      "text": "Kristina Toutanova",
      "label": "PERSON"
    },
    {
      "text": "2019",
      "label": "DATE"
    },
    {
      "text": "Bert",
      "label": "PERSON"
    },
    {
      "text": "North American",
      "label": "NORP"
    },
    {
      "text": "Association",
      "label": "ORG"
    },
    {
      "text": "Jinlan Fu",
      "label": "PERSON"
    },
    {
      "text": "Xuanjing Huang",
      "label": "PERSON"
    },
    {
      "text": "Pengfei Liu",
      "label": "PERSON"
    },
    {
      "text": "2021",
      "label": "DATE"
    },
    {
      "text": "59th",
      "label": "ORDINAL"
    },
    {
      "text": "Annual",
      "label": "DATE"
    },
    {
      "text": "the Association for Computational Linguistics",
      "label": "ORG"
    },
    {
      "text": "1",
      "label": "CARDINAL"
    },
    {
      "text": "7183\u20137195",
      "label": "CARDINAL"
    },
    {
      "text": "Computa-",
      "label": "PERSON"
    },
    {
      "text": "Linguistics",
      "label": "PERSON"
    },
    {
      "text": "Leo Gao",
      "label": "PERSON"
    },
    {
      "text": "Stella Rose Biderman",
      "label": "PERSON"
    },
    {
      "text": "Sid Black",
      "label": "PERSON"
    },
    {
      "text": "Travis Hoppe",
      "label": "PERSON"
    },
    {
      "text": "Charles Foster",
      "label": "PERSON"
    },
    {
      "text": "Jason Phang",
      "label": "PERSON"
    },
    {
      "text": "Horace",
      "label": "PERSON"
    },
    {
      "text": "Anish Thite",
      "label": "PERSON"
    },
    {
      "text": "Noa Nabeshima",
      "label": "PERSON"
    },
    {
      "text": "Shawn\nPresser",
      "label": "PERSON"
    },
    {
      "text": "Connor Leahy",
      "label": "PERSON"
    },
    {
      "text": "2020",
      "label": "DATE"
    },
    {
      "text": "Pengcheng He",
      "label": "PERSON"
    },
    {
      "text": "Jianfeng Gao",
      "label": "PERSON"
    },
    {
      "text": "Weizhu Chen",
      "label": "PERSON"
    },
    {
      "text": "2021",
      "label": "DATE"
    },
    {
      "text": "Zhiheng Huang",
      "label": "PERSON"
    },
    {
      "text": "Wei Xu",
      "label": "PERSON"
    },
    {
      "text": "Kai Yu",
      "label": "PERSON"
    },
    {
      "text": "2015",
      "label": "DATE"
    },
    {
      "text": "John D. Lafferty",
      "label": "PERSON"
    },
    {
      "text": "Andrew McCallum",
      "label": "PERSON"
    },
    {
      "text": "Fernando\nPereira",
      "label": "PERSON"
    },
    {
      "text": "2001",
      "label": "DATE"
    },
    {
      "text": "InInternational Conference on Machine Learning",
      "label": "ORG"
    },
    {
      "text": "Viet Dac Lai",
      "label": "PERSON"
    },
    {
      "text": "Amir Pouran Ben\nVeyseh",
      "label": "PERSON"
    },
    {
      "text": "Hieu Man",
      "label": "PERSON"
    },
    {
      "text": "Franck Dernoncourt",
      "label": "ORG"
    },
    {
      "text": "Trung Bui",
      "label": "GPE"
    },
    {
      "text": "Thien Huu Nguyen",
      "label": "PERSON"
    },
    {
      "text": "2023",
      "label": "DATE"
    },
    {
      "text": "Chatgpt",
      "label": "ORG"
    },
    {
      "text": "abs/2304.05613",
      "label": "GPE"
    },
    {
      "text": "Guillaume Lample",
      "label": "PERSON"
    },
    {
      "text": "Miguel Ballesteros",
      "label": "PERSON"
    },
    {
      "text": "Kazuya Kawakami",
      "label": "PERSON"
    },
    {
      "text": "Chris Dyer",
      "label": "PERSON"
    },
    {
      "text": "2016",
      "label": "DATE"
    },
    {
      "text": "InNorth American",
      "label": "NORP"
    },
    {
      "text": "Computational Linguistics",
      "label": "PERSON"
    },
    {
      "text": "Zhenzhong Lan",
      "label": "PERSON"
    },
    {
      "text": "Mingda Chen",
      "label": "PERSON"
    },
    {
      "text": "Sebastian Goodman",
      "label": "PERSON"
    },
    {
      "text": "Kevin Gimpel",
      "label": "PERSON"
    },
    {
      "text": "Radu Soricut",
      "label": "PERSON"
    },
    {
      "text": "2019",
      "label": "DATE"
    },
    {
      "text": "Albert",
      "label": "PERSON"
    },
    {
      "text": "Dongfang Li",
      "label": "PERSON"
    },
    {
      "text": "Baotian Hu",
      "label": "PERSON"
    },
    {
      "text": "Qingcai Chen",
      "label": "PERSON"
    },
    {
      "text": "2022",
      "label": "DATE"
    },
    {
      "text": "Xiaoya Li",
      "label": "PERSON"
    },
    {
      "text": "Jingrong Feng",
      "label": "PERSON"
    },
    {
      "text": "Yuxian Meng",
      "label": "PERSON"
    },
    {
      "text": "Qinghong",
      "label": "GPE"
    },
    {
      "text": "Han",
      "label": "NORP"
    },
    {
      "text": "Fei Wu",
      "label": "PERSON"
    },
    {
      "text": "Jiwei Li",
      "label": "PERSON"
    },
    {
      "text": "2019",
      "label": "DATE"
    },
    {
      "text": "Yangming Li",
      "label": "PERSON"
    },
    {
      "text": "lemao liu",
      "label": "PERSON"
    },
    {
      "text": "Shuming Shi",
      "label": "PERSON"
    },
    {
      "text": "2021",
      "label": "DATE"
    },
    {
      "text": "Learning Representations",
      "label": "WORK_OF_ART"
    },
    {
      "text": "Yinhan Liu",
      "label": "PERSON"
    },
    {
      "text": "Myle Ott",
      "label": "PERSON"
    },
    {
      "text": "Naman Goyal",
      "label": "PERSON"
    },
    {
      "text": "Jingfei Du",
      "label": "PERSON"
    },
    {
      "text": "Joshi",
      "label": "PERSON"
    },
    {
      "text": "Danqi Chen",
      "label": "PERSON"
    },
    {
      "text": "Omer Levy",
      "label": "PERSON"
    },
    {
      "text": "Mike Lewis",
      "label": "PERSON"
    },
    {
      "text": "Luke Zettlemoyer",
      "label": "PERSON"
    },
    {
      "text": "Veselin Stoyanov",
      "label": "PERSON"
    },
    {
      "text": "2019",
      "label": "DATE"
    },
    {
      "text": "Roberta",
      "label": "PERSON"
    },
    {
      "text": "abs/1907.11692",
      "label": "GPE"
    },
    {
      "text": "S. Longpre",
      "label": "PERSON"
    },
    {
      "text": "Le Hou",
      "label": "PERSON"
    },
    {
      "text": "Albert Webson",
      "label": "PERSON"
    },
    {
      "text": "Hyung Won\nChung",
      "label": "PERSON"
    },
    {
      "text": "Yi Tay",
      "label": "PERSON"
    },
    {
      "text": "Denny Zhou",
      "label": "PERSON"
    },
    {
      "text": "Quoc V .",
      "label": "PERSON"
    },
    {
      "text": "Barret\nZoph",
      "label": "PERSON"
    },
    {
      "text": "Jason Wei",
      "label": "PERSON"
    },
    {
      "text": "Adam Roberts",
      "label": "PERSON"
    },
    {
      "text": "2023",
      "label": "DATE"
    },
    {
      "text": "Machine Learning",
      "label": "PERSON"
    },
    {
      "text": "Ilya Loshchilov",
      "label": "PERSON"
    },
    {
      "text": "Frank Hutter",
      "label": "PERSON"
    },
    {
      "text": "2017",
      "label": "DATE"
    },
    {
      "text": "Learning Representations",
      "label": "WORK_OF_ART"
    },
    {
      "text": "Jie Lou",
      "label": "PERSON"
    },
    {
      "text": "Yaojie Lu",
      "label": "PERSON"
    },
    {
      "text": "Dai Dai",
      "label": "PERSON"
    },
    {
      "text": "Wei Jia",
      "label": "PERSON"
    },
    {
      "text": "Hongyu Lin",
      "label": "PERSON"
    },
    {
      "text": "Xi-",
      "label": "PERSON"
    },
    {
      "text": "Han",
      "label": "NORP"
    },
    {
      "text": "Le Sun",
      "label": "ORG"
    },
    {
      "text": "Hua Wu",
      "label": "PERSON"
    },
    {
      "text": "2023",
      "label": "DATE"
    },
    {
      "text": "Yaojie Lu",
      "label": "PERSON"
    },
    {
      "text": "Qing Liu",
      "label": "PERSON"
    },
    {
      "text": "Dai Dai",
      "label": "PERSON"
    },
    {
      "text": "Xinyan Xiao",
      "label": "PERSON"
    },
    {
      "text": "Lin",
      "label": "PERSON"
    },
    {
      "text": "Xianpei Han",
      "label": "PERSON"
    },
    {
      "text": "Le Sun",
      "label": "ORG"
    },
    {
      "text": "Hua Wu",
      "label": "PERSON"
    },
    {
      "text": "2022",
      "label": "DATE"
    },
    {
      "text": "Annual",
      "label": "DATE"
    },
    {
      "text": "Computational Linguistics",
      "label": "PERSON"
    },
    {
      "text": "Shervin Malmasi",
      "label": "PERSON"
    },
    {
      "text": "Anjie Fang",
      "label": "PERSON"
    },
    {
      "text": "Besnik Fetahu",
      "label": "PERSON"
    },
    {
      "text": "Sudipta\nKar",
      "label": "PERSON"
    },
    {
      "text": "Oleg Rokhlenko",
      "label": "PERSON"
    },
    {
      "text": "2022",
      "label": "DATE"
    },
    {
      "text": "Linguistics",
      "label": "PERSON"
    },
    {
      "text": "Andrei Mikheev",
      "label": "PERSON"
    },
    {
      "text": "Marc Moens",
      "label": "PERSON"
    },
    {
      "text": "Claire Grover",
      "label": "PERSON"
    },
    {
      "text": "1999",
      "label": "DATE"
    },
    {
      "text": "the European Chapter of the Association",
      "label": "ORG"
    },
    {
      "text": "Xinxi Lyu",
      "label": "PERSON"
    },
    {
      "text": "Ari Holtzman",
      "label": "PERSON"
    },
    {
      "text": "Mikel Artetxe",
      "label": "PERSON"
    },
    {
      "text": "Mike Lewis",
      "label": "PERSON"
    },
    {
      "text": "Hannaneh",
      "label": "GPE"
    },
    {
      "text": "Luke Zettle-",
      "label": "PERSON"
    },
    {
      "text": "2022",
      "label": "DATE"
    },
    {
      "text": "Swaroop Mishra",
      "label": "PERSON"
    },
    {
      "text": "Daniel Khashabi",
      "label": "PERSON"
    },
    {
      "text": "Chitta Baral",
      "label": "PERSON"
    },
    {
      "text": "Hannaneh Hajishirzi",
      "label": "ORG"
    },
    {
      "text": "2021",
      "label": "DATE"
    },
    {
      "text": "Linguistics",
      "label": "PERSON"
    },
    {
      "text": "David Nadeau",
      "label": "PERSON"
    },
    {
      "text": "Peter D. Turney",
      "label": "PERSON"
    },
    {
      "text": "Stan Matwin",
      "label": "PERSON"
    },
    {
      "text": "2006",
      "label": "DATE"
    },
    {
      "text": "Canadian",
      "label": "NORP"
    },
    {
      "text": "OpenAI",
      "label": "GPE"
    },
    {
      "text": "2023",
      "label": "DATE"
    },
    {
      "text": "Chengwei Qin",
      "label": "PERSON"
    },
    {
      "text": "Aston Zhang",
      "label": "PERSON"
    },
    {
      "text": "Zhuosheng Zhang",
      "label": "PERSON"
    },
    {
      "text": "Jiaao\nChen",
      "label": "PERSON"
    },
    {
      "text": "Michihiro Yasunaga",
      "label": "PERSON"
    },
    {
      "text": "Diyi Yang",
      "label": "PERSON"
    },
    {
      "text": "2023",
      "label": "DATE"
    },
    {
      "text": "abs/2302.06476.Colin Raffel",
      "label": "PERSON"
    },
    {
      "text": "Noam M. Shazeer",
      "label": "PERSON"
    },
    {
      "text": "Adam Roberts",
      "label": "PERSON"
    },
    {
      "text": "Kather-",
      "label": "PERSON"
    },
    {
      "text": "ine Lee",
      "label": "PERSON"
    },
    {
      "text": "Sharan Narang",
      "label": "PERSON"
    },
    {
      "text": "Michael Matena",
      "label": "PERSON"
    },
    {
      "text": "Yanqi",
      "label": "GPE"
    },
    {
      "text": "Zhou",
      "label": "PERSON"
    },
    {
      "text": "Wei Li",
      "label": "PERSON"
    },
    {
      "text": "Peter J. Liu",
      "label": "PERSON"
    },
    {
      "text": "2019",
      "label": "DATE"
    },
    {
      "text": "J. Mach",
      "label": "PERSON"
    },
    {
      "text": "Learn",
      "label": "PERSON"
    },
    {
      "text": "Res",
      "label": "PERSON"
    },
    {
      "text": "21:140:1\u2013140:67",
      "label": "CARDINAL"
    },
    {
      "text": "Lev-Arie Ratinov",
      "label": "ORG"
    },
    {
      "text": "Dan Roth",
      "label": "PERSON"
    },
    {
      "text": "2009",
      "label": "DATE"
    },
    {
      "text": "Baptiste Rozi\u00e8re",
      "label": "PERSON"
    },
    {
      "text": "Jonas Gehring",
      "label": "PERSON"
    },
    {
      "text": "Fabian Gloeckle",
      "label": "PERSON"
    },
    {
      "text": "Sten Sootla",
      "label": "PERSON"
    },
    {
      "text": "Itai Gat",
      "label": "PERSON"
    },
    {
      "text": "Xiaoqing Tan",
      "label": "PERSON"
    },
    {
      "text": "Yossi Adi",
      "label": "PERSON"
    },
    {
      "text": "Jingyu Liu",
      "label": "PERSON"
    },
    {
      "text": "Tal Remez",
      "label": "GPE"
    },
    {
      "text": "J\u00e9r\u00e9my Rapin",
      "label": "PERSON"
    },
    {
      "text": "Artyom",
      "label": "PERSON"
    },
    {
      "text": "I. Evtimov",
      "label": "PERSON"
    },
    {
      "text": "Joanna Bitton",
      "label": "PERSON"
    },
    {
      "text": "Manish P\nBhatt",
      "label": "PERSON"
    },
    {
      "text": "Cant\u00f3n Ferrer",
      "label": "PERSON"
    },
    {
      "text": "Aaron Grattafiori",
      "label": "PERSON"
    },
    {
      "text": "Alexandre",
      "label": "PERSON"
    },
    {
      "text": "Jade Copet",
      "label": "PERSON"
    },
    {
      "text": "Faisal\nAzhar",
      "label": "PERSON"
    },
    {
      "text": "Hugo Touvron",
      "label": "PERSON"
    },
    {
      "text": "Louis Martin",
      "label": "PERSON"
    },
    {
      "text": "Nicolas Usunier",
      "label": "PERSON"
    },
    {
      "text": "Thomas Scialom",
      "label": "PERSON"
    },
    {
      "text": "Gabriel Synnaeve",
      "label": "PERSON"
    },
    {
      "text": "2023",
      "label": "DATE"
    },
    {
      "text": "Oscar Sainz",
      "label": "PERSON"
    },
    {
      "text": "Iker Garc\u00eda-Ferrero",
      "label": "PERSON"
    },
    {
      "text": "Rodrigo Agerri",
      "label": "PERSON"
    },
    {
      "text": "Oier Lopez de Lacalle",
      "label": "ORG"
    },
    {
      "text": "German",
      "label": "NORP"
    },
    {
      "text": "Eneko\nAgirre",
      "label": "PRODUCT"
    },
    {
      "text": "2023",
      "label": "DATE"
    },
    {
      "text": "Gollie",
      "label": "PERSON"
    },
    {
      "text": "zero",
      "label": "CARDINAL"
    },
    {
      "text": "abs/2310.03668",
      "label": "GPE"
    },
    {
      "text": "Sunita Sarawagi",
      "label": "PERSON"
    },
    {
      "text": "William W. Cohen",
      "label": "PERSON"
    },
    {
      "text": "2004",
      "label": "DATE"
    },
    {
      "text": "Neural Information Processing",
      "label": "ORG"
    },
    {
      "text": "Hugo Touvron",
      "label": "PERSON"
    },
    {
      "text": "Thibaut Lavril",
      "label": "PERSON"
    },
    {
      "text": "Gautier Izacard",
      "label": "PERSON"
    },
    {
      "text": "Xavier",
      "label": "GPE"
    },
    {
      "text": "Marie-Anne Lachaux",
      "label": "PERSON"
    },
    {
      "text": "Timoth\u00e9e Lacroix",
      "label": "PERSON"
    },
    {
      "text": "Baptiste Rozi\u00e8re",
      "label": "PERSON"
    },
    {
      "text": "Naman Goyal",
      "label": "PERSON"
    },
    {
      "text": "Eric Hambro",
      "label": "PERSON"
    },
    {
      "text": "Faisal\nAzhar",
      "label": "PERSON"
    },
    {
      "text": "Armand Joulin",
      "label": "PERSON"
    },
    {
      "text": "Guillaume Lample",
      "label": "PERSON"
    },
    {
      "text": "2023",
      "label": "DATE"
    },
    {
      "text": "Xiao Wang",
      "label": "PERSON"
    },
    {
      "text": "Wei Zhou",
      "label": "PERSON"
    },
    {
      "text": "Han Xia",
      "label": "PERSON"
    },
    {
      "text": "Tianze Chen",
      "label": "PERSON"
    },
    {
      "text": "Yuan Zhang",
      "label": "PERSON"
    },
    {
      "text": "Rui Zheng",
      "label": "PERSON"
    },
    {
      "text": "Junjie Ye",
      "label": "PERSON"
    },
    {
      "text": "Qi Zhang",
      "label": "PERSON"
    },
    {
      "text": "Tao\nGui",
      "label": "PERSON"
    },
    {
      "text": "Jihua Kang",
      "label": "PERSON"
    },
    {
      "text": "J. Yang",
      "label": "PERSON"
    },
    {
      "text": "Siyuan Li",
      "label": "PERSON"
    },
    {
      "text": "Du",
      "label": "ORG"
    },
    {
      "text": "2023",
      "label": "DATE"
    },
    {
      "text": "abs/2304.08085",
      "label": "CARDINAL"
    },
    {
      "text": "Yizhong Wang",
      "label": "PERSON"
    },
    {
      "text": "Swaroop Mishra",
      "label": "PERSON"
    },
    {
      "text": "Pegah",
      "label": "ORG"
    },
    {
      "text": "Yeganeh Kordi",
      "label": "PERSON"
    },
    {
      "text": "Amirreza Mirzaei",
      "label": "PERSON"
    },
    {
      "text": "Anjana Arunkumar",
      "label": "PERSON"
    },
    {
      "text": "Arjun Ashok",
      "label": "PERSON"
    },
    {
      "text": "Arut Selvan",
      "label": "PERSON"
    },
    {
      "text": "Atharva Naik",
      "label": "PERSON"
    },
    {
      "text": "David Stap",
      "label": "PERSON"
    },
    {
      "text": "Eshaan\nPathak",
      "label": "PERSON"
    },
    {
      "text": "Giannis Karamanolakis",
      "label": "PERSON"
    },
    {
      "text": "Gary Lai",
      "label": "PERSON"
    },
    {
      "text": "han Purohit",
      "label": "ORG"
    },
    {
      "text": "Ishani Mondal",
      "label": "PERSON"
    },
    {
      "text": "Jacob Anderson",
      "label": "PERSON"
    },
    {
      "text": "Kirby\nKuznia",
      "label": "PERSON"
    },
    {
      "text": "Krima Doshi",
      "label": "PERSON"
    },
    {
      "text": "Maitreya Patel",
      "label": "PERSON"
    },
    {
      "text": "M. Moradshahi",
      "label": "PERSON"
    },
    {
      "text": "Mirali Purohit",
      "label": "PERSON"
    },
    {
      "text": "Neeraj Varshney",
      "label": "PERSON"
    },
    {
      "text": "Phani",
      "label": "NORP"
    },
    {
      "text": "Rohitha Kaza",
      "label": "PERSON"
    },
    {
      "text": "Pulkit Verma",
      "label": "PERSON"
    },
    {
      "text": "Ravsehaj Singh Puri",
      "label": "PERSON"
    },
    {
      "text": "Rushang Karia",
      "label": "PERSON"
    },
    {
      "text": "Shailaja Keyur\nSampat",
      "label": "PERSON"
    },
    {
      "text": "Savan Doshi",
      "label": "PERSON"
    },
    {
      "text": "Siddharth Deepak Mishra",
      "label": "PERSON"
    },
    {
      "text": "Tanay Dixit",
      "label": "PERSON"
    },
    {
      "text": "Xudong",
      "label": "GPE"
    },
    {
      "text": "Chitta Baral",
      "label": "PERSON"
    },
    {
      "text": "Yejin Choi",
      "label": "ORG"
    },
    {
      "text": "Noah A. Smith",
      "label": "PERSON"
    },
    {
      "text": "Daniel Khashabi",
      "label": "PERSON"
    },
    {
      "text": "2022",
      "label": "DATE"
    },
    {
      "text": "1600+",
      "label": "DATE"
    },
    {
      "text": "Empirical Methods in Natural Language Processing",
      "label": "WORK_OF_ART"
    },
    {
      "text": "Jason Wei",
      "label": "PERSON"
    },
    {
      "text": "Xuezhi Wang",
      "label": "PERSON"
    },
    {
      "text": "Dale Schuurmans",
      "label": "PERSON"
    },
    {
      "text": "Ed Huai",
      "label": "PERSON"
    },
    {
      "text": "Chi",
      "label": "PERSON"
    },
    {
      "text": "F. Xia",
      "label": "PERSON"
    },
    {
      "text": "Quoc Le",
      "label": "PERSON"
    },
    {
      "text": "Denny Zhou",
      "label": "PERSON"
    },
    {
      "text": "2022",
      "label": "DATE"
    },
    {
      "text": "Ralph Weischedel",
      "label": "PERSON"
    },
    {
      "text": "Sean Boisen",
      "label": "PERSON"
    },
    {
      "text": "Daniel Bikel",
      "label": "PERSON"
    },
    {
      "text": "Robert\nBobrow",
      "label": "PERSON"
    },
    {
      "text": "Michael Crystal",
      "label": "PERSON"
    },
    {
      "text": "William Ferguson",
      "label": "PERSON"
    },
    {
      "text": "Allan\nWechsler",
      "label": "PERSON"
    },
    {
      "text": "The PLUM Research Group",
      "label": "ORG"
    },
    {
      "text": "1996",
      "label": "DATE"
    },
    {
      "text": "Vienna",
      "label": "GPE"
    },
    {
      "text": "Virginia",
      "label": "GPE"
    },
    {
      "text": "May 6-8, 1996",
      "label": "DATE"
    },
    {
      "text": "127\u2013138",
      "label": "GPE"
    },
    {
      "text": "Vienna",
      "label": "GPE"
    },
    {
      "text": "Virginia",
      "label": "GPE"
    },
    {
      "text": "USA",
      "label": "GPE"
    },
    {
      "text": "Computational Linguistics",
      "label": "PERSON"
    },
    {
      "text": "Hang Yan",
      "label": "PERSON"
    },
    {
      "text": "Tao Gui",
      "label": "PERSON"
    },
    {
      "text": "Junqi Dai",
      "label": "PERSON"
    },
    {
      "text": "Qipeng Guo",
      "label": "PERSON"
    },
    {
      "text": "Zheng\nZhang",
      "label": "PERSON"
    },
    {
      "text": "Xipeng Qiu",
      "label": "PERSON"
    },
    {
      "text": "2021",
      "label": "DATE"
    },
    {
      "text": "Zhilin Yang",
      "label": "PERSON"
    },
    {
      "text": "Zihang Dai",
      "label": "PERSON"
    },
    {
      "text": "Yiming Yang",
      "label": "PERSON"
    },
    {
      "text": "Jaime G.",
      "label": "PERSON"
    },
    {
      "text": "Ruslan Salakhutdinov",
      "label": "PERSON"
    },
    {
      "text": "Quoc V .",
      "label": "ORG"
    },
    {
      "text": "2019",
      "label": "DATE"
    },
    {
      "text": "Neural Information",
      "label": "ORG"
    },
    {
      "text": "Junjie Ye",
      "label": "PERSON"
    },
    {
      "text": "Xuanting Chen",
      "label": "PERSON"
    },
    {
      "text": "Nuo Xu",
      "label": "PERSON"
    },
    {
      "text": "Shichun Liu",
      "label": "PERSON"
    },
    {
      "text": "Yuhan Cui",
      "label": "GPE"
    },
    {
      "text": "Zeyang Zhou",
      "label": "PERSON"
    },
    {
      "text": "Chao\nGong",
      "label": "PERSON"
    },
    {
      "text": "Yang Shen",
      "label": "PERSON"
    },
    {
      "text": "Jie Zhou",
      "label": "PERSON"
    },
    {
      "text": "Siming Chen",
      "label": "PERSON"
    },
    {
      "text": "Tao Gui",
      "label": "PERSON"
    },
    {
      "text": "Qi Zhang",
      "label": "PERSON"
    },
    {
      "text": "Xuanjing Huang",
      "label": "PERSON"
    },
    {
      "text": "2023",
      "label": "DATE"
    },
    {
      "text": "abs/2303.10420",
      "label": "PERSON"
    },
    {
      "text": "Norshuhani Zamin",
      "label": "ORG"
    },
    {
      "text": "Alan Oxley",
      "label": "PERSON"
    },
    {
      "text": "2011",
      "label": "DATE"
    },
    {
      "text": "Computer Systems",
      "label": "ORG"
    },
    {
      "text": "Urchade Zaratiana",
      "label": "PERSON"
    },
    {
      "text": "Nadi Tomeh",
      "label": "PERSON"
    },
    {
      "text": "Niama Elkhbir",
      "label": "PERSON"
    },
    {
      "text": "Pierre\nHolat",
      "label": "PERSON"
    },
    {
      "text": "Thierry Charnois",
      "label": "PERSON"
    },
    {
      "text": "2023",
      "label": "DATE"
    },
    {
      "text": "Urchade Zaratiana",
      "label": "PERSON"
    },
    {
      "text": "Nadi Tomeh",
      "label": "PERSON"
    },
    {
      "text": "Pierre Holat",
      "label": "PERSON"
    },
    {
      "text": "Thierry Charnois",
      "label": "PERSON"
    },
    {
      "text": "2022",
      "label": "DATE"
    },
    {
      "text": "Workshop on Unimodal and Multimodal Induction",
      "label": "WORK_OF_ART"
    },
    {
      "text": "Linguistic Structures",
      "label": "ORG"
    },
    {
      "text": "UM-IoS",
      "label": "ORG"
    },
    {
      "text": "1\u201310",
      "label": "DATE"
    },
    {
      "text": "Abu\nDhabi",
      "label": "ORG"
    },
    {
      "text": "United Arab Emirates",
      "label": "GPE"
    },
    {
      "text": "Wenxuan Zhou",
      "label": "PERSON"
    },
    {
      "text": "Sheng Zhang",
      "label": "PERSON"
    },
    {
      "text": "Yu Gu",
      "label": "PERSON"
    },
    {
      "text": "Muhao Chen",
      "label": "PERSON"
    },
    {
      "text": "Hoifung Poon",
      "label": "PERSON"
    },
    {
      "text": "2023",
      "label": "DATE"
    }
  ],
  "summary": "GLiNER is a compact Named Entity Recognition (NER) model leveraging bidirectional transformers to extract entities of any type, offering faster parallel processing compared to Large Language Models (LLMs). It outperforms LLMs like ChatGPT in zero-shot evaluations, providing an efficient alternative for resource-limited scenarios.",
  "embedding": [
    0.049831490963697433,
    0.038660090416669846,
    0.02824360877275467,
    0.05080600455403328,
    -0.011601443402469158,
    0.061390411108732224,
    -0.02129632793366909,
    0.007969117723405361,
    0.02879626490175724,
    -0.07534170150756836,
    -0.030701523646712303,
    -0.021791702136397362,
    -0.023875605314970016,
    0.010175884701311588,
    0.05153615400195122,
    -0.012086700648069382,
    0.03317660838365555,
    -0.014341494999825954,
    0.03381899371743202,
    0.028408922255039215,
    -0.014406909234821796,
    0.02538258396089077,
    -0.0020811886060982943,
    0.018026459962129593,
    0.01541165355592966,
    0.009715520776808262,
    -0.013781016692519188,
    0.01029901672154665,
    0.013735801912844181,
    -0.050763897597789764,
    0.019520243629813194,
    0.0460619293153286,
    -0.021306999027729034,
    0.030198657885193825,
    2.1417977222881746e-06,
    -0.025977661833167076,
    -0.06943019479513168,
    0.017554275691509247,
    -0.030166301876306534,
    -0.035534244030714035,
    0.0010685489978641272,
    -0.03028646856546402,
    -0.017113467678427696,
    0.009970983490347862,
    -0.021902453154325485,
    -0.079666867852211,
    0.025893719866871834,
    0.07596009224653244,
    0.017165979370474815,
    0.09214834868907928,
    -0.021105218678712845,
    -0.047987159341573715,
    0.048135578632354736,
    -0.013098586350679398,
    -0.03308279812335968,
    -0.03095802664756775,
    0.03077888861298561,
    -0.02081219106912613,
    -0.024639099836349487,
    0.04700956866145134,
    0.016025006771087646,
    0.008649305440485477,
    -0.01746555045247078,
    0.029950212687253952,
    0.02725408785045147,
    0.03643754869699478,
    -0.03406999260187149,
    0.004859298001974821,
    -0.026675812900066376,
    0.0860619768500328,
    -0.03307677060365677,
    0.005074155516922474,
    0.06612217426300049,
    0.003884729230776429,
    -0.015836099162697792,
    -0.016937175765633583,
    -0.013145921751856804,
    0.013101883232593536,
    -0.0539519339799881,
    -0.00034250778844580054,
    0.03147429972887039,
    0.0021311098244041204,
    0.023491578176617622,
    -0.024437937885522842,
    0.008734108880162239,
    -0.0058324881829321384,
    0.027928072959184647,
    -0.03542473539710045,
    0.02235635183751583,
    -0.008304956369102001,
    -0.03687683865427971,
    -0.07080159336328506,
    0.03042897954583168,
    0.042484384030103683,
    0.03319951146841049,
    0.02556420862674713,
    0.012592867948114872,
    -0.0181479062885046,
    0.01180263888090849,
    -0.04299771413207054,
    -0.013526390306651592,
    0.023453721776604652,
    0.01567946746945381,
    0.05252653732895851,
    -0.06885932385921478,
    0.0396650955080986,
    -0.0070020658895373344,
    0.015003600157797337,
    0.023619776591658592,
    -0.048358459025621414,
    -0.04971824213862419,
    -0.010898354463279247,
    -0.04979122802615166,
    0.07029058039188385,
    -0.03347042575478554,
    -0.00533308507874608,
    -0.025889892131090164,
    0.01851091906428337,
    0.008553065359592438,
    0.020469462499022484,
    0.06387537717819214,
    -0.008785178884863853,
    0.010292175225913525,
    -0.012232252396643162,
    -0.02041558548808098,
    0.029710475355386734,
    -0.009414945729076862,
    -0.016087934374809265,
    -0.03553399071097374,
    -0.05303628370165825,
    0.007860423065721989,
    -0.014668903313577175,
    0.04126168414950371,
    -0.04058351740241051,
    0.035208407789468765,
    0.09813393652439117,
    0.023354537785053253,
    -0.09624865651130676,
    -0.06887046992778778,
    -0.004367906600236893,
    0.01837010681629181,
    -0.0430602952837944,
    0.0011932249180972576,
    -0.051498234272003174,
    0.04604727774858475,
    0.029984688386321068,
    0.016475867480039597,
    -0.06534630805253983,
    0.02127036824822426,
    0.003471559612080455,
    -0.05666390433907509,
    0.08281683176755905,
    -0.03626265749335289,
    -0.0014395336620509624,
    0.009468646720051765,
    -0.0027120988816022873,
    0.004130194894969463,
    0.035740453749895096,
    0.05676698684692383,
    0.0007945839897729456,
    0.04842124879360199,
    -0.03279821202158928,
    0.01402953453361988,
    0.04472258314490318,
    0.00022606503625866026,
    -0.02190030738711357,
    0.025432845577597618,
    0.009072206914424896,
    0.008593499660491943,
    0.0025277629029005766,
    0.015779580920934677,
    0.08744680881500244,
    -0.006280448753386736,
    -0.014450078830122948,
    0.027503151446580887,
    0.03825996816158295,
    0.006890613120049238,
    0.024972479790449142,
    0.05771550163626671,
    0.0027925490867346525,
    0.0023468947038054466,
    -0.036678895354270935,
    -0.02546900324523449,
    0.0051226238720119,
    -0.011141561903059483,
    0.007935376837849617,
    0.022677097469568253,
    0.060545556247234344,
    -0.023951511830091476,
    0.008455353789031506,
    -0.006973487325012684,
    -0.006746217142790556,
    0.011183114722371101,
    -0.01570383459329605,
    0.051515329629182816,
    0.025738868862390518,
    -0.09366285800933838,
    0.06987091898918152,
    0.031181445345282555,
    -0.025664424523711205,
    0.0018601709743961692,
    -0.04931950569152832,
    0.005372747778892517,
    0.01749221608042717,
    0.03424464911222458,
    -0.011255475692451,
    -0.054797422140836716,
    -0.03870544582605362,
    -0.05523121356964111,
    0.05222732573747635,
    0.00782314408570528,
    -0.02349727600812912,
    0.0033795894123613834,
    -0.0381607860326767,
    0.0113416388630867,
    0.033409904688596725,
    0.013753989711403847,
    0.033900633454322815,
    0.04978277534246445,
    0.04797150194644928,
    0.02029065415263176,
    -0.025569980964064598,
    -0.012919796630740166,
    0.046505387872457504,
    -0.042292360216379166,
    -0.03789800778031349,
    0.003542328253388405,
    0.009814389050006866,
    0.020648442208766937,
    0.03259865939617157,
    0.014309057965874672,
    -0.020574528723955154,
    0.02404744364321232,
    -0.02386075258255005,
    -0.04065435379743576,
    -0.01672542095184326,
    0.012188063003122807,
    -0.05715006962418556,
    0.013753047212958336,
    -0.0022216651123017073,
    -0.011329473927617073,
    0.0059539154171943665,
    -0.03557031601667404,
    -0.04805193468928337,
    -0.03508230671286583,
    0.01936275139451027,
    0.06388989835977554,
    -0.020682398229837418,
    0.03823769837617874,
    0.04501182585954666,
    0.017933223396539688,
    -0.010934512130916119,
    0.0620512031018734,
    -0.025235652923583984,
    0.02623629756271839,
    0.0062759085558354855,
    -0.022653203457593918,
    -0.006106697954237461,
    -0.023586364462971687,
    -0.05411788448691368,
    0.03776553273200989,
    -0.013387211598455906,
    -0.02352362684905529,
    0.0008697379962541163,
    0.004841355606913567,
    -0.0488998182117939,
    -0.033525023609399796,
    -0.12522663176059723,
    0.0464535653591156,
    -0.01453400868922472,
    0.06267204135656357,
    0.02453579008579254,
    0.03963351994752884,
    -0.02323891781270504,
    -0.0036940325517207384,
    0.004126181360334158,
    -0.0013748921919614077,
    -0.011009967885911465,
    0.0051711201667785645,
    0.031158972531557083,
    -0.008416999131441116,
    -0.03566085547208786,
    0.01328854076564312,
    0.010818296112120152,
    -0.04322736710309982,
    0.036290429532527924,
    0.028552720323204994,
    -0.04549067094922066,
    -0.053306832909584045,
    0.040176309645175934,
    -0.014502073638141155,
    0.014436225406825542,
    0.002267277566716075,
    -0.018454039469361305,
    -0.02663915418088436,
    0.025213008746504784,
    0.030667798593640327,
    0.028712589293718338,
    0.010223791934549809,
    0.01503463089466095,
    -0.059765953570604324,
    -0.020847687497735023,
    -0.03349446505308151,
    0.037484776228666306,
    -0.03690357506275177,
    0.015302082523703575,
    -0.004525902681052685,
    -0.0401325486600399,
    0.041001349687576294,
    0.09788703918457031,
    -0.015867458656430244,
    -0.0006639529019594193,
    -0.04133348539471626,
    -0.00010968765855068341,
    -0.0014573094667866826,
    0.021538671106100082,
    0.0169534832239151,
    0.027896372601389885,
    -0.011806591413915157,
    -0.03984319418668747,
    -0.018173636868596077,
    -0.005758379120379686,
    0.03432122617959976,
    -0.06599339842796326,
    -0.004045331850647926,
    0.001584875863045454,
    0.0011156740365549922,
    -0.0679643452167511,
    0.05327809974551201,
    0.04260486736893654,
    -0.002105346415191889,
    0.017723819240927696,
    -0.07407738268375397,
    0.014156917110085487,
    0.03895134478807449,
    -0.02988944575190544,
    -0.03098946064710617,
    0.04693536087870598,
    -0.0003416096733417362,
    0.027789989486336708,
    -0.031177926808595657,
    -0.028000105172395706,
    -0.04086872562766075,
    -0.02087675966322422,
    -0.04783065989613533,
    0.03533511236310005,
    0.023979615420103073,
    -0.02188594825565815,
    0.0048409514129161835,
    0.04813936725258827,
    -0.005013178568333387,
    0.06491168588399887,
    -0.0065352837555110455,
    -0.0067410278134047985,
    -0.04307204484939575,
    0.0440458245575428,
    0.03677814453840256,
    -0.009985969401896,
    0.012813410721719265,
    0.015883048996329308,
    0.00714221503585577,
    0.04244834929704666,
    -0.021051431074738503,
    -0.02770925872027874,
    -0.006966632325202227,
    -0.017628991976380348,
    0.007279505021870136,
    -0.09013283252716064,
    0.002296139020472765,
    -0.010898527689278126,
    0.04794403538107872,
    -0.029486116021871567,
    0.0026046806015074253,
    0.127459317445755,
    -0.013102549128234386,
    -0.037546902894973755,
    -0.02353236824274063,
    0.03913850337266922,
    -1.5818864994798787e-05,
    0.018218744546175003,
    0.01308247447013855,
    -0.07662064582109451,
    -0.06991777569055557,
    0.017945745959877968,
    -0.005836124997586012,
    -0.0060718064196407795,
    -0.08232861757278442,
    -0.013775793835520744,
    -0.12308792024850845,
    -0.00388570805080235,
    -0.035335712134838104,
    -0.07536766678094864,
    0.011616775766015053,
    -0.049619704484939575,
    0.0006291870959103107,
    -0.04244372621178627,
    -0.01822984404861927,
    -0.015347744338214397,
    -0.04318561777472496,
    -0.0024207255337387323,
    0.010846353136003017,
    -0.008800317533314228,
    -0.020821020007133484,
    0.03078065998852253,
    -0.06208314746618271,
    0.04418410360813141,
    -0.02486099675297737,
    0.03714367747306824,
    -0.013549556955695152,
    -0.007971091195940971,
    0.0332491509616375,
    -0.04390520602464676,
    -0.03751034662127495,
    -0.017992597073316574,
    0.033703457564115524,
    -0.06999393552541733,
    -0.0020267306827008724,
    -0.007836460135877132,
    0.008378865197300911,
    -0.05908586084842682,
    0.00434153014793992,
    0.0026784378569573164,
    0.07787598669528961,
    0.01537229772657156,
    0.004337681923061609,
    0.006237726658582687,
    -0.04884909838438034,
    0.015065108425915241,
    0.09171070903539658,
    -0.008426477201282978,
    -0.015330448746681213,
    -0.03331434354186058,
    -0.009824322536587715,
    -0.0006714551127515733,
    -0.022128840908408165,
    -0.028666257858276367,
    0.010403051972389221,
    -0.014498012140393257,
    -0.04816718026995659,
    -0.031577207148075104,
    -0.02121397666633129,
    0.04691532999277115,
    0.020537428557872772,
    0.01846890337765217,
    0.021706733852624893,
    0.04981127753853798,
    0.010674891993403435,
    -0.05975319817662239,
    0.031419940292835236,
    -0.03791641443967819,
    -0.011622926220297813,
    -0.10122773796319962,
    -0.030159611254930496,
    0.03887192904949188,
    0.010086193680763245,
    -0.05853678286075592,
    0.020319722592830658,
    -0.07801927626132965,
    -0.055378761142492294,
    -0.01728309504687786,
    0.029520219191908836,
    0.009995995089411736,
    0.024832554161548615,
    -0.0013416095171123743,
    0.012099983170628548,
    0.012741114012897015,
    0.06995876878499985,
    -0.05823149532079697,
    -0.028364237397909164,
    -0.0004553982289507985,
    0.03453194350004196,
    -0.015543635934591293,
    0.03266124427318573,
    -0.028558583930134773,
    0.012490742839872837,
    0.017016790807247162,
    0.053955186158418655,
    -0.0374007411301136,
    -0.03199246898293495,
    -0.007700991816818714,
    0.04451102018356323,
    0.04112832248210907,
    0.004291933495551348,
    0.004086188971996307,
    -0.06289646774530411,
    -0.001252362853847444,
    0.0036224587820470333,
    0.017701957374811172,
    -0.032261256128549576,
    -0.016819406300783157,
    0.008860930800437927,
    -0.01024133525788784,
    -0.025245506316423416,
    0.027905572205781937,
    -0.00814710184931755,
    0.01929144188761711,
    -0.030611472204327583,
    0.007976781576871872,
    -0.004496240522712469,
    0.009109278209507465,
    0.02556174248456955,
    -0.04933558776974678,
    0.005665759555995464,
    0.03696611896157265,
    0.051425181329250336,
    0.020919835194945335,
    -0.04463891685009003,
    0.027804087847471237,
    0.0016195278149098158,
    0.0088220639154315,
    -0.025674747303128242,
    0.025451956316828728,
    -0.016088660806417465,
    0.0004249509365763515,
    -0.03563913330435753,
    0.06348248571157455,
    0.0561581589281559,
    0.0033277433831244707,
    0.05822286754846573,
    0.0008145390311256051,
    -0.00855343695729971,
    0.004336671903729439,
    0.035622160881757736,
    -0.011647592298686504,
    -0.017306054010987282,
    0.04522531107068062,
    0.0181597787886858,
    -0.03797159716486931,
    -0.028813833370804787,
    0.07227253168821335,
    0.010067171417176723,
    0.04528572037816048,
    0.039397675544023514,
    -0.035686809569597244,
    -0.04900876432657242,
    -0.013270740397274494,
    0.03374141827225685,
    -0.03713873401284218,
    -0.006066242232918739,
    0.018035121262073517,
    -0.02175871469080448,
    -0.06162841618061066,
    0.03282046690583229,
    -0.04101887345314026,
    -0.00570008996874094,
    -0.02279837429523468,
    0.026496393606066704,
    0.01101772766560316,
    0.026132218539714813,
    -0.057467270642519,
    -0.05440292879939079,
    0.02632637321949005,
    -0.014929785393178463,
    -0.029548050835728645,
    -0.007170099299401045,
    -6.70672497858299e-33,
    -0.039844512939453125,
    -0.05155935138463974,
    0.03176278620958328,
    -0.0034432176034897566,
    -0.004844045266509056,
    0.029364870861172676,
    -0.015154886990785599,
    -0.016130533069372177,
    0.011081268079578876,
    -0.031521860510110855,
    -0.008465834893286228,
    0.0040616439655423164,
    0.026618631556630135,
    0.02619081921875477,
    -0.006285357754677534,
    -0.024189680814743042,
    0.043000154197216034,
    0.017861654981970787,
    0.00047354362322948873,
    0.03472553566098213,
    0.04934745281934738,
    0.05863712728023529,
    0.08940182626247406,
    -0.04370299354195595,
    0.009935647249221802,
    -0.019782813265919685,
    0.02260628715157509,
    -0.009438259527087212,
    0.06457508355379105,
    0.05071849003434181,
    -0.05669952556490898,
    -0.01948563940823078,
    0.029840875416994095,
    -0.0726504847407341,
    0.03157434239983559,
    0.02214624546468258,
    -0.15082986652851105,
    0.001358255511149764,
    -0.023212479427456856,
    0.030691029503941536,
    -0.02430589124560356,
    -0.028887109830975533,
    0.04987122863531113,
    -0.008505255915224552,
    0.011400819756090641,
    0.012045232579112053,
    0.01634526439011097,
    0.005525493528693914,
    0.0030576856806874275,
    -0.015613320283591747,
    -0.07037439942359924,
    0.052385296672582626,
    0.027193957939743996,
    0.031858865171670914,
    0.03090735338628292,
    -0.019681228324770927,
    0.019647836685180664,
    0.015373224392533302,
    -0.08700001984834671,
    -0.039443545043468475,
    0.0030151994433254004,
    -0.01370315346866846,
    0.011018680408596992,
    0.021752022206783295,
    0.005179135594516993,
    0.033789414912462234,
    -0.006466879975050688,
    -0.014479520730674267,
    -0.03935106098651886,
    0.012138031423091888,
    -0.017177661880850792,
    0.025205915793776512,
    -0.023394959047436714,
    0.025728849694132805,
    0.06496763229370117,
    -0.04216581583023071,
    -0.07063624262809753,
    0.02376570738852024,
    0.016559310257434845,
    0.01894555613398552,
    0.006498001981526613,
    -0.029114266857504845,
    -0.053212471306324005,
    0.012284921482205391,
    0.009008805267512798,
    -0.05226060375571251,
    -0.02482936531305313,
    -0.012178500182926655,
    0.03813426196575165,
    0.023207446560263634,
    -0.01613556407392025,
    0.026915449649095535,
    0.03420860692858696,
    -0.026953114196658134,
    -0.040372878313064575,
    0.03317729011178017,
    0.021439647302031517,
    0.01143654901534319,
    -0.011502155102789402,
    0.02551141567528248,
    -0.08049269765615463,
    -0.07405082136392593,
    0.0026820655912160873,
    -0.0005502915009856224,
    0.029711345210671425,
    0.011841348372399807,
    0.04732867330312729,
    -0.01007766928523779,
    -0.0750371441245079,
    0.002881701337173581,
    -0.021900320425629616,
    0.04978969320654869,
    -0.043861985206604004,
    0.04563579708337784,
    0.022271210327744484,
    0.01289938110858202,
    -0.0015960176242515445,
    0.036439429968595505,
    0.060052815824747086,
    -0.002903315704315901,
    -0.013066225685179234,
    0.03128720074892044,
    0.04257196933031082,
    0.017492657527327538,
    -0.009481718763709068,
    0.009901333600282669,
    -0.010883820243179798,
    0.0015860182465985417,
    -0.011164034716784954,
    -0.06682823598384857,
    0.0011373942252248526,
    0.005080210976302624,
    2.9390383815552923e-07,
    0.009958246722817421,
    0.011678005568683147,
    0.023271795362234116,
    0.007663351017981768,
    0.004734182730317116,
    0.016107937321066856,
    0.03181206062436104,
    0.04402027651667595,
    -0.005911045242100954,
    -0.0014378010528162122,
    -0.030057357624173164,
    -0.003835955634713173,
    0.002176268957555294,
    0.03221151605248451,
    -0.1262451410293579,
    -0.016496149823069572,
    -0.042548369616270065,
    -0.004148391541093588,
    -0.05887044593691826,
    0.054406069219112396,
    0.04572085291147232,
    0.06945057958364487,
    -0.006684753578156233,
    -0.0026758930180221796,
    -0.06280963867902756,
    -0.04305703938007355,
    0.05337299779057503,
    0.017471320927143097,
    0.012343169189989567,
    0.05781618878245354,
    0.02668619714677334,
    0.09768223017454147,
    -0.031179172918200493,
    0.03485197201371193,
    0.00729011557996273,
    0.04435728117823601,
    0.02010747417807579,
    0.06889792531728745,
    -0.015164201147854328,
    0.01385993417352438,
    0.01375727728009224,
    -0.04700818285346031,
    0.00355516467243433,
    -0.03660533204674721,
    0.1045728549361229,
    -0.047664184123277664,
    -0.026351816952228546,
    0.01122079137712717,
    -0.02367600053548813,
    -0.004836950916796923,
    -0.028986917808651924,
    0.004000450950115919,
    -0.015238070860505104,
    0.03395213931798935,
    0.03671875223517418,
    -0.04609120637178421,
    -0.024022208526730537,
    -0.07279419153928757,
    0.03770638629794121,
    0.023240093141794205,
    -0.0258882325142622,
    0.00034901953767985106,
    -0.015966039150953293,
    -0.012840315699577332,
    0.017396610230207443,
    -0.043144166469573975,
    0.007208512630313635,
    3.033433656040214e-34,
    -0.006100506987422705,
    0.012547050602734089,
    -0.02927408739924431,
    0.03564400598406792,
    0.04559646546840668,
    -0.022281525656580925,
    -0.02450975961983204,
    -0.01087332796305418,
    -0.03658200427889824,
    -0.06910799443721771,
    -0.0012057831045240164
  ]
}