{
  "filename": "T-NER.txt",
  "length": 37207,
  "context": "T-NER: An All-Round Python Library\nfor Transformer-based Named Entity Recognition\nAsahi Ushio and Jose Camacho-Collados\nSchool of Computer Science and Informatics\nCardiff University, United Kingdom\nfushioa,camachocolladosj g@cardiff.ac.uk\nAbstract\nLanguage model (LM) pretraining has led\nto consistent improvements in many NLP\ndownstream tasks, including named entity\nrecognition (NER). In this paper, we present\nT-NER1(Transformer-based Named Entity\nRecognition), a Python library for NER LM\n\ufb01netuning. In addition to its practical utility,\nT-NER facilitates the study and investigation\nof the cross-domain and cross-lingual general-\nization ability of LMs \ufb01netuned on NER. Our\nlibrary also provides a web app where users\ncan get model predictions interactively for ar-\nbitrary text, which facilitates qualitative model\nevaluation for non-expert programmers. We\nshow the potential of the library by compil-\ning nine public NER datasets into a uni\ufb01ed for-\nmat and evaluating the cross-domain and cross-\nlingual performance across the datasets. The\nresults from our initial experiments show that\nin-domain performance is generally competi-\ntive across datasets. However, cross-domain\ngeneralization is challenging even with a large\npretrained LM, which has nevertheless capac-\nity to learn domain-speci\ufb01c features if \ufb01ne-\ntuned on a combined dataset. To facilitate\nfuture research, we also release all our LM\ncheckpoints via the Hugging Face model hub2\n1 Introduction\nLanguage model (LM) pretraining has become one\nof the most common strategies within the natural\nlanguage processing (NLP) community to solve\ndownstream tasks (Peters et al., 2018; Howard and\nRuder, 2018; Radford et al., 2018, 2019; Devlin\net al., 2019). LMs trained over large textual data\nonly need to be \ufb01netuned on downstream tasks\nto outperform most of the task-speci\ufb01c designed\nmodels. Among the NLP tasks impacted by LM\n1https://github.com/asahi417/tner\n2https://huggingface.co/models?search=\nasahi417/tner .\nFigure 1: System overview of T-NER.\npretraining, named entity recognition (NER) is one\nof the most prevailing and practical applications.\nHowever, the availability of open-source NER li-\nbraries for LM training is limited.3\nIn this paper, we introduce T-NER , an open-\nsource Python library for cross-domain analysis\nfor NER with pretrained Transformer-based LMs.\nFigure 1 shows a brief overview of our library and\nits functionalities. The library facilitates NER ex-\nperimental design including easy-to-use features\nsuch as model training and evaluation. Most no-\ntably, it enables to organize cross-domain analyses\nsuch as training a NER model and testing it on a\ndifferent domain, with a small con\ufb01guration. We\nalso report initial experiment results, by which we\nshow that although cross-domain NER is challeng-\ning, if it has an access to new domains, LM can\nsuccessfully learn new domain knowledge. The\nresults give us an insight that LM is capable to\nlearn a variety of domain knowledge, but an or-\ndinary \ufb01netuning scheme on single dataset most\nlikely causes over\ufb01tting and results in poor domain\ngeneralization.\nAs a system design, T-NER is implemented in\n3Recently, spaCy ( https://spacy.io/ ) has released\na general NLP pipeline with pretrained models including a\nNER feature. Although it provides a very ef\ufb01cient pipeline\nfor processing text, it is not suitable for LM \ufb01netuning or\nevaluation on arbitrary NER data.arXiv:2209.12616v1  [cs.CL]  9 Sep 2022\nPytorch (Paszke et al., 2019) on top of the Trans-\nformers library (Wolf et al., 2019). Moreover, the\ninterfaces of our training and evaluation modules\nare highly inspired by Scikit-learn (Pedregosa et al.,\n2011), enabling an interoperability with recent\nmodels as well as integrating them in an intuitive\nway. In addition to the versatility of our toolkit for\nNER experimentation, we also include an online\ndemo and robust pre-trained models trained across\ndomains. In the following sections, we provide a\nbrief overview about NER in Section 2, explain\nthe system architecture of T-NER with a few ba-\nsic usages in Section 3 and describe experiment\nresults on cross-domain transfer with our library in\nSection 4.\n2 Named Entity Recognition\nGiven an arbitrary text, the task of NER consists\nof detecting named entities and identifying their\ntype. For example, given a sentence \u201dDante was\nborn in Florence. \u201d , a NER model are would iden-\ntify\u201dDante\u201d as a person and \u201dFlorence\u201d as a loca-\ntion. Traditionally, NER systems have relied on a\nclassi\ufb01cation model on top of hand-engineered fea-\nture sets extracted from corpora (Ratinov and Roth,\n2009; Collobert et al., 2011), which was improved\nby carefully designed neural network approaches\n(Lample et al., 2016; Chiu and Nichols, 2016; Ma\nand Hovy, 2016). This paradigm shift was mainly\ndue to its ef\ufb01cient access to contextual information\nand \ufb02exibility, as human-crafted feature sets were\nno longer required. Later, contextual representa-\ntions produced by pretrained LMs have improved\nthe generalization abilities of neural network archi-\ntectures in many NLP tasks, including NER (Peters\net al., 2018; Devlin et al., 2019).\nIn particular, LMs seemillions of plain texts dur-\ning pretraining, a knowledge that then can be lever-\naged in downstream NLP applications. This prop-\nerty has been studied in the recently literature by\nprobing their generalization capacity (Hendrycks\net al., 2020; Aharoni and Goldberg, 2020; Desai\nand Durrett, 2020; Gururangan et al., 2020). When\nit comes to LM generalization studies in NER, the\nliterature is more limited and mainly restricted to in-\ndomain (Agarwal et al., 2021) or multilingual set-\ntings (Pfeiffer et al., 2020a; Hu et al., 2020b). Our\nlibrary facilitates future research in cross-domain\nand cross-lingual generalization by providing a\nuni\ufb01ed benchmark for several languages and do-\nmain as well as a straightforward implementationof NER LM \ufb01netuning.\n3 T-NER: An Overview\nA key design goal was to create a self-contained\nuniversal system to train, evaluate, and utilize NER\nmodels in an easy way, not only for research pur-\npose but also practical use cases in industry. More-\nover, we provide a demo web app (Figure 2) where\nusers can get predictions from a trained model\ngiven a sentence interactively. This way, users\n(even those without programming experience) can\nconduct qualitative analyses on their own or exist-\ning pre-trained models.\nIn the following we provide details on the techni-\ncalities of the package provided, including details\non how to train and evaluate any LM-based archi-\ntecture. Our package, T-NER, allows practitioners\nin NLP to get started working on NER with a few\nlines of code while diving into the recent progress\nin LM \ufb01netuning. We employ Python as our core\nimplementation, as is one of the most prevailing\nlanguages in the machine learning and NLP com-\nmunities. Our library enables Python users to ac-\ncess its various kinds of features such as model\ntraining, in- and cross-domain model evaluation,\nand an interface to get predictions from trained\nmodels with minimum effort.\n3.1 Datasets\nFor model training and evaluation, we compiled\nnine public NER datasets from different domains,\nunifying them into same format: OntoNotes5\n(Hovy et al., 2006), CoNLL 2003 (Tjong Kim Sang\nand De Meulder, 2003), WNUT 2017 (Derczynski\net al., 2017), WikiAnn (Pan et al., 2017), FIN (Sali-\nnas Alvarado et al., 2015), BioNLP 2004 (Collier\nand Kim, 2004), BioCreative V CDR4(Wei et al.,\n2015), MIT movie review semantic corpus,5and\nMIT restaurant review.6These uni\ufb01ed datasets are\nalso made available as part of our T-NER library.\nExcept for WikiAnn that contains 282 languages,\nall the datasets are in English, and only the MIT\ncorpora are lowercased. As MIT corpora are com-\n4The original dataset consists of long documents which\ncannot be fed on LM because of the length, so we split them\ninto sentences to reduce their size.\n5The movie corpus includes two datasets ( eng and\ntrivia10k13 ) coming from different data sources. While both\nhave been integrated into our library, we only used the largest\ntrivia10k13 in our experiments.\n6The original MIT NER corpora can be downloaded\nfrom https://groups.csail.mit.edu/sls/\ndownloads/ .\nFigure 2: A screenshot from the demo web app. In this example, the NER transformer model is \ufb01ne-tuned on\nOntoNotes 5 and a sample sentence is fetched from Wikipedia ( en.wikipedia.org/wiki/Sergio_Mendes ).\nmonly used for slot \ufb01lling task in spoken language\nunderstanding (Liu and Lane, 2017), the charac-\nteristics of the entities and annotation guidelines\nare quite different from the other datasets, but we\nincluded them for completeness and to analyze the\ndifferences across datasets.\nTable 1 shows statistics of each dataset. In Sec-\ntion 4, we train models on each dataset, and assess\nthe in- and cross-domain accuracy over them.\nDataset format and customization. Users can\nutilize their own datasets for both model training\nand evaluation by formatting them into the IOB\nscheme (Tjong Kim Sang and De Meulder, 2003)\nwhich we used to unify all datasets. In the IOB\nformat, all data \ufb01les contain one word per line with\nempty lines representing sentence boundaries. At\nthe end of each line there is a tag which states\nwhether the current word is inside a named entity\nor not. The tag also encodes the type of named\nentity. Here is an example from CoNLL 2003:\nEU B-ORG\nrejects O\nGerman B-MISC\ncall O\nto O\nboycott O\nBritish B-MISC\nlamb O\n. O3.2 Model Training\nWe provide modules to facilitate LM \ufb01netuning on\nany given NER dataset. Following Devlin et al.\n(2019), we add a linear layer on top of the last em-\nbedding layer in each token, and train all weights\nwith cross-entropy loss. The model training compo-\nnent relies on the Huggingface transformers library\n(Wolf et al., 2019), one of the largest Python frame-\nworks for distributing pretrained LM checkpoint\n\ufb01les. Our library is therefore fully compatible with\nthe Transformers framework: once new model was\ndeployed on the Transformer hub, one can imme-\ndiately try those models out with our library as a\nNER model. To reduce computational complexity,\nin addition to enabling multi-GPU support, we im-\nplement mixture precision during model training\nby using the apex library7.\nThe instance of model training in a given\ndataset8can be used in an intuitive way as dis-\nplayed below:\nfrom tner import TrainTransformersNER\nmodel = TrainTransformersNER(\ndataset=\"ontonotes5\",\ntransformer=\"roberta-base\")\nmodel.train()\nWith this sample code, we would \ufb01netune\n7https://github.com/NVIDIA/apex\n8To use custom datasets, the path to a custom dataset folder\ncan simply be included in the dataset argument.\nName Domain Entity types Data size\nOntoNotes5 News, Blog, Dialogue 18 59,924/8,582/8,262\nCoNLL 2003 News 4 14,041/3,250/3,453\nWNUT 2017 SNS 6 1,000/1,008/1,287\nWikiAnn Wikipedia (282 languages) 3 20,000/10,000/10,000\nFIN Finance 4 1,164/-/303\nBioNLP 2004 Biochemical 5 18,546/-/3,856\nBioCreative V Biomedical 5 5,228/5,330/5,865\nMIT Restaurant Restaurant review 8 7,660/-/1,521\nMIT Movie Movie review 12 7,816/-/1,953\nTable 1: Overview of the NER datasets used in our evaluation and included in T-NER. Data size is the number of\nsentence in training/validation/test set.\nRoBERTa BASE (Liu et al., 2019) on the\nOntoNotes5 dataset. We also provide an easy ex-\ntension to train on multiple datasets at the same\ntime:\nTrainTransformersNER(\ndataset=[\n\"ontonotes5\", \"wnut2017\"\n],\ntransformer=\"roberta-base\")\nOnce training is completed, checkpoint \ufb01les with\nmodel weights and other statistics are generated.\nThese are automatically organized for each con\ufb01g-\nuration and can be easily uploaded to the Hugging\nFace model hub. Ready-to-use code samples can be\nfound in our Google Colab notebook9, and details\nfor additional options and arguments are included\nin the github repository. Finally, our library sup-\nports Tensorboard10to visualize learning curves.\n3.3 Model Evaluation\nOnce a NER model is trained, users may want to\ntest the models in the same dataset or a different one\nto assess its general performance across domains.\nTo this end, we implemented \ufb02exible evaluation\nmodules to facilitate cross-domain evaluation com-\nparison, which is also aided by the uni\ufb01cation of\ndatasets into the same format (see Section 3.1) with\na unique label reference lookup.\nThe basic usage of the evaluation module is de-\nscribed below.\nfrom tner import TrainTransformersNER\nmodel = TrainTransformersNER(\n\"path-to-model-checkpoint\"\n)\nmodel.test(\"ontonotes5\")\n9https://colab.research.google.com/\ndrive/1AlcTbEsp8W11yflT7SyT0L4C4HG6MXYr?\nusp=sharing\n10www.tensorflow.org/tensorboardHere, the model would be tested on OntoNotes5\ndataset, and it could be evaluated on any other test\nset including custom dataset. As with the model\ntraining module, we prepared a Google Colab note-\nbook11for an example use case, and further details\ncan be found in our github repository.\n4 Evaluation\nIn this section, we assess the reliability of T-NER\nwith experiments in standard NER datasets.\n4.1 Experimental Setting\n4.1.1 Implementation details\nThrough the experiments, we use XLM-R (Liu et al.,\n2019), which has shown to be one of the most re-\nliable multi-lingual pretrained LMs for discrimi-\nnative tasks at the moment. In all experiments we\nmake use of the default con\ufb01guration and hyper-\npameters of Huggingface\u2019s XLM-R implementation.\nFor WikiAnn/ja (Japanese), we convert the original\ncharacter-level tokenization into proper morpholog-\nical chunk by MeCab12.\n4.1.2 Evaluation metrics and protocols\nAs customary in the NER literature, we report span\nmicro-F1 score computed by seqeval13, a Python\nlibrary to compute metrics for sequence predic-\ntion evaluation. We refer to this F1 score as type-\naware F1 score to distinguish it from the the type-\nignored metric used to assess the cross-domain\nperformance, which we explain below.\n11https://colab.research.google.com/\ndrive/1jHVGnFN4AU8uS-ozWJIXXe2fV8HUj8NZ?\nusp=sharing\n12https://pypi.org/project/\nmecab-python3/\n13https://pypi.org/project/seqeval/\nIn a cross-domain evaluation setting, the type-\naware F1 score easily fails to represent the cross-\ndomain performance if the granularity of entity\ntypes differ across datasets. For instance, the MIT\nrestaurant corpus has entities such as amenity and\nrating , while plotandactor are entities from the\nMIT movie corpus. Thus, we report type-ignored\nF1 score for cross-domain analysis. In this type-\nignored evaluation, the entity type from both of\npredictions and true labels is disregarded, reducing\nthe task into a simpler entity span detection task.\nThis evaluation protocol can be customized by the\nuser at test time.\n4.2 Results\nWe conduct three experiments on the nine datasets\ndescribed in Table 1: (i) in-domain evaluation (Sec-\ntion 4.2.1), (ii) cross-domain evaluation (Section\n4.2.2), and (iii) cross-lingual evaluation (Section\n4.2.3). While the \ufb01rst experiment tests our imple-\nmentation in standard datasets, the second exper-\niment is aimed at investigating the cross-domain\nperformance of transformer-based NER models.\nFinally, as a direct extension of our evaluation mod-\nule, we show the zero-shot cross-lingual perfor-\nmance of NER models on the WikiAnn dataset.\n4.2.1 In-domain results\nThe main results are displayed in Table 2, where we\nreport the type-aware F1 score from XLM-R BASE\nandXLM-R LARGE models along with current state-\nof-the-art (SoTA). One can con\ufb01rm that our frame-\nwork with XLM-R LARGE achieves a comparable\nSoTA score, even surpassing it in the WNUT 2017\ndataset. In general, XLM-R LARGE performs consis-\ntently better than XLM-R BASE but, interestingly, the\nbase model performs better than large on the FIN\ndataset. This can be attributed to the limited train-\ning data in this dataset, which may have caused\nover\ufb01tting in the large model.\nGenerally, it can be expected to get better accu-\nracy with domain-speci\ufb01c or larger language mod-\nels that can be integrated into our library. Nonethe-\nless, our goal for these experiments were not to\nachieve SoTA but rather to provide a competitive\nand easy-to-use framework. In the remaining ex-\nperiments we report results for XLM-R LARGE only,\nbut the results for XLM-R BASE can be found in the\nappendix.Dataset BASE LARGE SoTA\nOntoNotes5 89.0 89.1 92.1\nCoNLL 2003 90.8 92.9 94.3\nWNUT 2017 52.8 58.5 50.3\nFIN 81.3 76.4 82.7\nBioNLP 2004 73.4 74.3 77.4\nBioCreative V 88.0 88.6 89.9\nMIT Restaurant 79.4 79.6 -\nMIT Movie 69.9 71.2 -\nWikiAnn/en 82.7 84.0 84.8\nWikiAnn/ja 83.8 86.5 73.3\nWikiAnn/ru 88.6 90.0 91.4\nWikiAnn/es 90.9 92.1 -\nWikiAnn/ko 87.5 89.6 -\nWikiAnn/ar 88.9 90.3 -\nTable 2: In-domain type-aware F1 score for test set\non each dataset with current SoTA. SoTA on each\ndataset is attained from the result of BERT-MRC-DSC\n(Li et al., 2019) for OntoNotes5, LUKE (Yamada et al.,\n2020) for CoNLL 2003, CrossWeigh (Wang et al.,\n2019) for WNUT 2017, (Pfeiffer et al., 2020a) for\nWikiAnn (en, ja, ru, es, ko, ar), (Salinas Alvarado\net al., 2015) for FIN, (Lee et al., 2020) for BioNLP\n2004, (Nooralahzadeh et al., 2019) for BioCreative V\nand (Pfeiffer et al., 2020a) for WikiAnn/en.\n4.2.2 Cross-domain results\nIn this section, we show cross-domain evalua-\ntion results on the English datasets14: OntoNotes5\n(ontonotes), CoNLL 2003 (conll), WNUT 2017\n(wnut), WikiAnn/en (wiki), BioNLP 2004 (bionlp),\nand BioCreative V (bc5cdr), FIN (\ufb01n). We also\nreport the accuracy of the same XLM-R model\ntrained over a combined dataset resulting from con-\ncatenation of all the above datasets.\nIn Table 3, we present the type-ignored F1 re-\nsults across datasets. Overall cross-domain scores\nare not as competitive as in-domain results. This\ngap reveals the dif\ufb01culty of transferring NER mod-\nels into different domains, which may also be at-\ntributed to different annotation guidelines or data\nconstruction procedures across datasets. Especially,\ntraining on the bionlp and bc5cdr datasets lead to\na null accuracy when they are evaluated on other\ndatasets, as well as others evaluated on them. Those\ndatasets are very domain speci\ufb01c dataset, as they\nhave entities such as DNA ,Protein ,Chemical , and\nDisease , which results in a poor adaptation to other\ndomains. On the other hand, there are datasets\n14We excluded the MIT datasets in this setting since they\nare all lowercased.\ntrainntest ontonotes conll wnut wiki bionlp bc5cdr \ufb01n avg\nontonotes 91.6 65.4 53.6 47.5 0.0 0.0 18.3 40.8\nconll 62.2 96.0 69.1 61.7 0.0 0.0 22.7 35.1\nwnut 41.8 85.7 68.3 54.5 0.0 0.0 20.0 31.7\nwiki 32.8 73.3 53.6 93.4 0.0 0.0 12.2 29.6\nbionlp 0.0 0.0 0.0 0.0 79.0 0.0 0.0 8.7\nbc5cdr 0.0 0.0 0.0 0.0 0.0 88.8 0.0 9.8\n\ufb01n 48.2 73.2 60.9 58.9 0.0 0.0 82.0 38.1\nall 90.9 93.8 60.9 91.3 78.3 84.6 75.5 81.7\nTable 3: Type-ignored F1 score in cross-domain setting over non-lower-cased English datasets. We compute\naverage of accuracy in each test set, named as avg. The model trained on all datasets listed here, is shown as all.\ntest\ntrain en ja ru ko es ar\nen 84.0 46.3 73.1 58.1 71.4 53.2\nja 53.0 86.5 45.7 57.1 74.5 55.4\nru 60.4 53.3 90.0 68.1 76.8 54.9\nko 57.8 62.0 68.6 89.6 66.2 57.2\nes 70.5 50.6 75.8 61.8 92.1 62.1\nar 60.1 55.7 55.7 70.7 79.7 90.3\nTable 4: Cross-lingual type-aware F1 results on vari-\nous languages for the WikiAnn dataset.\nthat are more easily transferable, such as wnut and\nconll. The wnut-trained model achieves 85.7 on\nthe conll dataset and, surprisingly, the conll-trained\nmodel actually works better than the wnut-trained\nmodel when evaluated on the wnut test set. This\ncould be also attributed to the data size, as wnut\nonly has 1,000 sentences, while conll has 14,041.\nNevertheless, the fact that ontonotes has 59,924\nsentences but does not perform better than conll on\nwnut reveals a certain domain similarity between\nconll and wnut.\nFinally, the model trained on the training sets\nof all datasets achieves a type-ignored F1 score\nclose to the in-domain baselines. This indicates\nthat a LM is capable of learning representations of\ndifferent domains. Moreover, leveraging domain\nsimilarity as explained above can lead to better\nresults as, for example, distant datasets such as\nbionlp and bc5cdr surely cause performance drops.\nThis is an example of the type of experiments that\ncould be facilited by T-NER, which we leave for\nfuture work.\n4.2.3 Cross-lingual results\nFinally, we present some results for zero-shot cross-\nlingual NER over the WikiAnn dataset, wherewe include six distinct languages: English (en),\nJapanese (ja), Russian (ru), Korean (ko), Spanish\n(es), and Arabic (ar). In Table 4, we show the cross-\nlingual evaluation results. The diagonal includes\nthe results of the model trained on the training data\nof the same target language. There are a few inter-\nesting \ufb01ndings. First, we observe a high correlation\nbetween Russian and Spanish, which are generally\nconsidered to be distant languages and do not share\nthe alphabet. Second, Arabic also transfers well to\nSpanish which, despite the Arabic (lexical) in\ufb02u-\nence on the Spanish language (Stewart et al., 1999),\nare still languages from distant families.\nClearly, this is a shallow cross-lingual analysis,\nbut it highlights the possibilities of our library for\nresearch in cross-lingual NER. Recently, (Hu et al.,\n2020a) proposed a compilation of multilingual\nbenchmark tasks including the WikiAnn datasets\nas a part of it, and XLM-R proved to be a strong\nbaseline on multilingual NER. This is in line with\nthe results of Conneau et al. (2020), which showed\na high capacity of zero-shot cross-lingual trans-\nferability. On this respect, Pfeiffer et al. (2020b)\nproposed a language/task speci\ufb01c adapter module\nthat can further improve cross-lingual adaptation in\nNER. Given the possibilities and recent advances\nin cross-lingual language models in recent years,\nwe expect our library to help practitioners to exper-\niment and test these advances in NER.\n5 Conclusion\nIn this paper, we have presented a Python library\nto get started with Transformer-based NER mod-\nels. This paper especially focuses on LM \ufb01netun-\ning, and empirically shows the dif\ufb01culty of cross-\ndomain generalization in NER. Our framework is\ndesigned to be as simple as possible so that any\nlevel of users can start running experiments on\nNER on any given dataset. To this end, we have\nalso facilitated the evaluation by unifying some of\nthe most popular NER datasets in the literature,\nincluding languages other than English. We be-\nlieve that our initial experiment results emphasize\nthe importance of NER generalization analysis, for\nwhich we hope that our open-source library can\nhelp NLP community to convey relevant research\nin an ef\ufb01cient and accessible way.\nAcknowledgements\nWe would like to thank Dimosthenis Antypas for\ntesting our library and the anonymous reviewers\nfor their useful comments.\nReferences\nOshin Agarwal, Yinfei Yang, Byron C Wallace, and\nAni Nenkova. 2021. Entity-switched datasets: An\napproach to auditing the in-domain robustness of\nnamed entity recognition models. arXiv preprint\narXiv:2004.04123 .\nRoee Aharoni and Yoav Goldberg. 2020. Unsupervised\ndomain clusters in pretrained language models. In\nProceedings of the 58th Annual Meeting of the Asso-\nciation for Computational Linguistics , pages 7747\u2013\n7763, Online. Association for Computational Lin-\nguistics.\nJason P.C. Chiu and Eric Nichols. 2016. Named entity\nrecognition with bidirectional LSTM-CNNs. Trans-\nactions of the Association for Computational Lin-\nguistics , 4:357\u2013370.\nNigel Collier and Jin-Dong Kim. 2004. Introduc-\ntion to the bio-entity recognition task at JNLPBA.\nInProceedings of the International Joint Workshop\non Natural Language Processing in Biomedicine\nand its Applications (NLPBA/BioNLP) , pages 73\u201378,\nGeneva, Switzerland. COLING.\nRonan Collobert, Jason Weston, L \u00b4eon Bottou, Michael\nKarlen, Koray Kavukcuoglu, and Pavel Kuksa.\n2011. Natural language processing (almost) from\nscratch. Journal of machine learning research ,\n12(ARTICLE):2493\u20132537.\nAlexis Conneau, Shijie Wu, Haoran Li, Luke Zettle-\nmoyer, and Veselin Stoyanov. 2020. Emerging cross-\nlingual structure in pretrained language models. In\nProceedings of the 58th Annual Meeting of the Asso-\nciation for Computational Linguistics , pages 6022\u2013\n6034, Online. Association for Computational Lin-\nguistics.\nLeon Derczynski, Eric Nichols, Marieke van Erp, and\nNut Limsopatham. 2017. Results of the WNUT2017\nshared task on novel and emerging entity recogni-\ntion. In Proceedings of the 3rd Workshop on NoisyUser-generated Text , pages 140\u2013147, Copenhagen,\nDenmark. Association for Computational Linguis-\ntics.\nShrey Desai and Greg Durrett. 2020. Calibra-\ntion of pre-trained transformers. arXiv preprint\narXiv:2003.07892 .\nJacob Devlin, Ming-Wei Chang, Kenton Lee, and\nKristina Toutanova. 2019. BERT: Pre-training of\ndeep bidirectional transformers for language under-\nstanding. In Proceedings of the 2019 Conference\nof the North American Chapter of the Association\nfor Computational Linguistics: Human Language\nTechnologies, Volume 1 (Long and Short Papers) ,\npages 4171\u20134186, Minneapolis, Minnesota. Associ-\nation for Computational Linguistics.\nSuchin Gururangan, Ana Marasovi \u00b4c, Swabha\nSwayamdipta, Kyle Lo, Iz Beltagy, Doug Downey,\nand Noah A Smith. 2020. Don\u2019t stop pretraining:\nAdapt language models to domains and tasks. arXiv\npreprint arXiv:2004.10964 .\nDan Hendrycks, Xiaoyuan Liu, Eric Wallace, Adam\nDziedzic, Rishabh Krishnan, and Dawn Song. 2020.\nPretrained transformers improve out-of-distribution\nrobustness. arXiv preprint arXiv:2004.06100 .\nEduard Hovy, Mitchell Marcus, Martha Palmer, Lance\nRamshaw, and Ralph Weischedel. 2006. OntoNotes:\nThe 90% solution. In Proceedings of the Human\nLanguage Technology Conference of the NAACL,\nCompanion Volume: Short Papers , pages 57\u201360,\nNew York City, USA. Association for Computa-\ntional Linguistics.\nJeremy Howard and Sebastian Ruder. 2018. Universal\nlanguage model \ufb01ne-tuning for text classi\ufb01cation. In\nProceedings of the 56th Annual Meeting of the As-\nsociation for Computational Linguistics (Volume 1:\nLong Papers) , pages 328\u2013339, Melbourne, Australia.\nAssociation for Computational Linguistics.\nJunjie Hu, Sebastian Ruder, Aditya Siddhant, Gra-\nham Neubig, Orhan Firat, and Melvin Johnson.\n2020a. XTREME: A massively multilingual multi-\ntask benchmark for evaluating cross-lingual gener-\nalisation. In International Conference on Machine\nLearning (ICML) .\nJunjie Hu, Sebastian Ruder, Aditya Siddhant, Gra-\nham Neubig, Orhan Firat, and Melvin Johnson.\n2020b. Xtreme: A massively multilingual multi-\ntask benchmark for evaluating cross-lingual gener-\nalization. arXiv preprint arXiv:2003.11080 .\nGuillaume Lample, Miguel Ballesteros, Sandeep Sub-\nramanian, Kazuya Kawakami, and Chris Dyer. 2016.\nNeural architectures for named entity recognition.\nInProceedings of the 2016 Conference of the North\nAmerican Chapter of the Association for Computa-\ntional Linguistics: Human Language Technologies ,\npages 260\u2013270, San Diego, California. Association\nfor Computational Linguistics.\nJinhyuk Lee, Wonjin Yoon, Sungdong Kim,\nDonghyeon Kim, Sunkyu Kim, Chan Ho So, and\nJaewoo Kang. 2020. Biobert: a pre-trained biomed-\nical language representation model for biomedical\ntext mining. Bioinformatics , 36(4):1234\u20131240.\nXiaoya Li, Xiaofei Sun, Yuxian Meng, Junjun\nLiang, Fei Wu, and Jiwei Li. 2019. Dice loss\nfor data-imbalanced nlp tasks. arXiv preprint\narXiv:1911.02855 .\nBing Liu and Ian Lane. 2017. Multi-domain adversar-\nial learning for slot \ufb01lling in spoken language under-\nstanding. arXiv preprint arXiv:1711.11310 .\nYinhan Liu, Myle Ott, Naman Goyal, Jingfei Du, Man-\ndar Joshi, Danqi Chen, Omer Levy, Mike Lewis,\nLuke Zettlemoyer, and Veselin Stoyanov. 2019.\nRoberta: A robustly optimized bert pretraining ap-\nproach. arXiv preprint arXiv:1907.11692 .\nXuezhe Ma and Eduard Hovy. 2016. End-to-end\nsequence labeling via bi-directional LSTM-CNNs-\nCRF. In Proceedings of the 54th Annual Meeting of\nthe Association for Computational Linguistics (Vol-\nume 1: Long Papers) , pages 1064\u20131074, Berlin, Ger-\nmany. Association for Computational Linguistics.\nFarhad Nooralahzadeh, Jan Tore L\u00f8nning, and Lilja\n\u00d8vrelid. 2019. Reinforcement-based denoising of\ndistantly supervised ner with partial annotation. In\nProceedings of the 2nd Workshop on Deep Learning\nApproaches for Low-Resource NLP (DeepLo 2019) ,\npages 225\u2013233.\nXiaoman Pan, Boliang Zhang, Jonathan May, Joel\nNothman, Kevin Knight, and Heng Ji. 2017. Cross-\nlingual name tagging and linking for 282 languages.\nInProceedings of the 55th Annual Meeting of the\nAssociation for Computational Linguistics (Volume\n1: Long Papers) , pages 1946\u20131958, Vancouver,\nCanada. Association for Computational Linguistics.\nAdam Paszke, Sam Gross, Francisco Massa, Adam\nLerer, James Bradbury, Gregory Chanan, Trevor\nKilleen, Zeming Lin, Natalia Gimelshein, Luca\nAntiga, et al. 2019. Pytorch: An imperative style,\nhigh-performance deep learning library. In Ad-\nvances in neural information processing systems ,\npages 8026\u20138037.\nFabian Pedregosa, Ga \u00a8el Varoquaux, Alexandre Gram-\nfort, Vincent Michel, Bertrand Thirion, Olivier\nGrisel, Mathieu Blondel, Peter Prettenhofer, Ron\nWeiss, Vincent Dubourg, et al. 2011. Scikit-learn:\nMachine learning in python. the Journal of machine\nLearning research , 12:2825\u20132830.\nMatthew Peters, Mark Neumann, Mohit Iyyer, Matt\nGardner, Christopher Clark, Kenton Lee, and Luke\nZettlemoyer. 2018. Deep contextualized word rep-\nresentations. In Proceedings of the 2018 Confer-\nence of the North American Chapter of the Associ-\nation for Computational Linguistics: Human Lan-\nguage Technologies, Volume 1 (Long Papers) , pages2227\u20132237, New Orleans, Louisiana. Association\nfor Computational Linguistics.\nJonas Pfeiffer, Ivan Vuli \u00b4c, Iryna Gurevych, and Sebas-\ntian Ruder. 2020a. Mad-x: An adapter-based frame-\nwork for multi-task cross-lingual transfer. arXiv\npreprint arXiv:2005.00052 .\nJonas Pfeiffer, Ivan Vuli \u00b4c, Iryna Gurevych, and Se-\nbastian Ruder. 2020b. MAD-X: An Adapter-Based\nFramework for Multi-Task Cross-Lingual Transfer.\nInProceedings of the 2020 Conference on Empirical\nMethods in Natural Language Processing (EMNLP) ,\npages 7654\u20137673, Online. Association for Computa-\ntional Linguistics.\nAlec Radford, Karthik Narasimhan, Tim Salimans, and\nIlya Sutskever. 2018. Improving language under-\nstanding by generative pre-training.\nAlec Radford, Jeffrey Wu, Rewon Child, David Luan,\nDario Amodei, and Ilya Sutskever. 2019. Language\nmodels are unsupervised multitask learners.\nLev Ratinov and Dan Roth. 2009. Design chal-\nlenges and misconceptions in named entity recog-\nnition. In Proceedings of the Thirteenth Confer-\nence on Computational Natural Language Learning\n(CoNLL-2009) , pages 147\u2013155, Boulder, Colorado.\nAssociation for Computational Linguistics.\nJulio Cesar Salinas Alvarado, Karin Verspoor, and Tim-\nothy Baldwin. 2015. Domain adaption of named en-\ntity recognition to support credit risk assessment. In\nProceedings of the Australasian Language Technol-\nogy Association Workshop 2015 , pages 84\u201390, Par-\nramatta, Australia.\nMiranda Stewart et al. 1999. The Spanish language\ntoday . Psychology Press.\nErik F. Tjong Kim Sang and Fien De Meulder.\n2003. Introduction to the CoNLL-2003 shared task:\nLanguage-independent named entity recognition. In\nProceedings of the Seventh Conference on Natu-\nral Language Learning at HLT-NAACL 2003 , pages\n142\u2013147.\nZihan Wang, Jingbo Shang, Liyuan Liu, Lihao Lu, Ji-\nacheng Liu, and Jiawei Han. 2019. Crossweigh:\nTraining named entity tagger from imperfect anno-\ntations. In Proceedings of the 2019 Conference on\nEmpirical Methods in Natural Language Processing\nand the 9th International Joint Conference on Natu-\nral Language Processing (EMNLP-IJCNLP) , pages\n5157\u20135166.\nChih-Hsuan Wei, Yifan Peng, Robert Leaman, Al-\nlan Peter Davis, Carolyn J Mattingly, Jiao Li,\nThomas C Wiegers, and Zhiyong Lu. 2015.\nOverview of the biocreative v chemical disease re-\nlation (cdr) task. In Proceedings of the \ufb01fth BioCre-\native challenge evaluation workshop , volume 14.\nThomas Wolf, Lysandre Debut, Victor Sanh, Julien\nChaumond, Clement Delangue, Anthony Moi, Pier-\nric Cistac, Tim Rault, R \u00b4emi Louf, Morgan Funtow-\nicz, Joe Davison, Sam Shleifer, Patrick von Platen,\nClara Ma, Yacine Jernite, Julien Plu, Canwen Xu,\nTeven Le Scao, Sylvain Gugger, Mariama Drame,\nQuentin Lhoest, and Alexander M. Rush. 2019.\nHuggingface\u2019s transformers: State-of-the-art natural\nlanguage processing. ArXiv , abs/1910.03771.\nIkuya Yamada, Akari Asai, Hiroyuki Shindo, Hideaki\nTakeda, and Yuji Matsumoto. 2020. LUKE: Deep\ncontextualized entity representations with entity-\naware self-attention. In Proceedings of the 2020\nConference on Empirical Methods in Natural Lan-\nguage Processing (EMNLP) , pages 6442\u20136454, On-\nline. Association for Computational Linguistics.\nA Appendices\nIn all experiments we make use of the default\ncon\ufb01guration and hyperpameters of Huggingface\u2019s\nXLM-R implementation.\nA.1 Cross-lingual Results\nIn this section, we show cross-lingual analysis\nonXLM-R BASE, where the result is shown in Ta-\nble 5. For these cross-lingual results, we rely on\nthe WikiAnn dataset where zero-shot cross-lingual\nNER over six distinct languages is conducted: En-\nglish (en), Japanese (ja), Russian (ru), Korean (ko),\nSpanish (es), and Arabic (ar).\nA.2 Cross-domain Results\nIn this section, we show a few more results on\nour cross-domain analysis, which is based on\nnon-lowercased English datasets: OntoNotes5\n(ontonotes), CoNLL 2003 (conll), WNUT 2017\n(wnut), WikiAnn/en (wiki), BioNLP 2004 (bionlp),\nand BioCreative V (bc5cdr), and FIN (\ufb01n). Table 6\nshows the type-aware F1 score of the XLM-R LARGE\nandXLM-R BASE models trained on all the datasets.\nFurthermore, Table 7 shows additional results for\nXLM-R BASE in the type-ignored evaluation.\ntest\ntrain en ja ru ko es ar\nen 82.8 38.6 65.7 50.4 73.8 44.5\nja 53.8 83.9 46.9 60.1 71.3 46.3\nru 51.9 39.9 88.7 51.9 66.8 51.0\nko 54.7 51.6 53.3 87.5 63.3 52.3\nes 65.7 44.0 66.5 54.1 90.9 59.4\nar 53.1 49.2 49.4 59.7 73.6 88.9\nTable 5: Cross-lingual type-aware F1 score over\nWikiAnn dataset with XLM-R BASE.uppercase lowercase\nDatasets BASE LARGE BASE LARGE\nontonotes 85.8 87.8 81.7 85.6\nconll 87.2 90.3 82.8 87.6\nwnut 49.6 55.1 43.7 51.3\nwiki 79.1 82.7 75.2 80.8\nbionlp 72.9 74.1 71.7 74.0\nbc5cdr 79.4 85.0 78.0 84.2\n\ufb01n 72.4 72.4 72.4 73.5\nrestaurant - - 76.8 80.9\nmovie - - 67.8 71.8\nTable 6: Type-aware F1 score across different test sets\nof models trained on all uppercase /lowercase English\ndatasets with XLM-R BASE orXLM-R LARGE .\nCross-domain results with lowercased datasets.\nIn this section, we show cross-domain results on the\nEnglish datasets including lowercased corpora such\nas MIT Restaurant (restaurant) and MIT Movie\n(movie). Since those datasets are lowercasd, we\nconverted all datasets into lowercase. Tables 8 and\nTable 9 show the type-ignored F1 score across mod-\nels trained on different English datasets including\nlowercased corpora with XLM-R LARGE andXLM-\nRBASE, respectively.\ntrainntest ontonotes conll wnut wiki bionlp bc5cdr \ufb01n avg\nontonotes 91.8 62.2 51.7 44.7 0.0 0.0 31.8 40.3\nconll 60.5 95.7 66.6 60.8 0.0 0.0 33.5 45.3\nwnut 41.3 81.3 63.0 56.3 0.0 0.0 20.5 37.5\nwiki 30.2 71.8 45.3 92.6 0.0 0.0 11.5 35.9\nbionlp 0.0 0.0 0.0 0.0 78.5 0.0 0.0 11.2\nbc5cdr 0.0 0.0 0.0 0.0 0.0 87.5 0.0 12.5\n\ufb01n 49.0 73.5 62.2 60.7 0.0 0.0 82.8 46.9\nall 89.7 92.4 55.8 89.3 78.2 80.0 74.8 80.0\nTable 7: Type-ignored F1 score in cross-domain setting over non-lower-cased English datasets with XLM-R BASE.\nWe compute average of accuracy in each test set, named as avg. The model trained on all datasets listed here, is\nshown as all.\ntrainntest ontonotes conll wnut wiki bionlp bc5cdr \ufb01n restaurant movie avg\nontonotes 89.3 59.9 50.1 44.7 0.0 0.0 15.1 4.5 88.6 39.1\nconll 57.7 94.8 67.0 57.9 0.0 0.0 20.5 23.9 0.0 35.7\nwnut 39.8 80.3 61.3 52.3 0.0 0.0 19.5 18.8 0.0 30.2\nwiki 28.5 69.7 51.2 92.4 0.0 0.0 12.0 3.0 0.0 28.5\nbionlp 0.0 0.0 0.0 0.0 79.0 0.0 0.0 0.0 0.0 8.7\nbc5cdr 0.0 0.0 0.0 0.0 0.0 88.9 0.0 0.0 0.0 9.8\n\ufb01n 46 72.0 61.5 54.8 0.0 0.0 83.0 24.5 0.0 37.9\nrestaurant 4.6 21.7 22.9 22.3 0.0 0.0 5.4 83.4 0.0 17.8\nmovie 10.9 0.0 0.0 0.0 0.0 0.0 0.0 0.0 73.1 9.3\nall 88.5 92.1 58.0 90.0 79.0 84.6 74.5 85.3 74.1 80.7\nTable 8: Type-ignored F1 score in cross-domain setting over lower-cased English datasets with XLM-R LARGE . We\ncompute average of accuracy in each test set, named as avg. The model trained on all datasets listed here, is shown\nasall.\ntrainntest ontonotes conll wnut wiki bionlp bc5cdr \ufb01n restaurant movie avg\nontonotes 88.3 56.7 49.0 41.4 0.0 0.0 11.7 4.2 88.3 37.7\nconll 55.1 93.7 60.5 56.8 0.0 0.0 20.4 21.9 0.0 34.3\nwnut 38.1 73.0 57.5 49.1 0.0 0.0 21.1 20.4 0.0 28.8\nwiki 26.3 66.5 41.4 90.9 0.0 0.0 9.7 7.6 0.0 26.9\nbionlp 0.0 0.0 0.0 0.0 78.7 0.0 0.0 0.0 0.0 8.7\nbc5cdr 0.0 0.0 0.0 0.0 0.0 88.0 0.0 0.0 0.0 9.8\n\ufb01n 41.3 64.4 45.8 57.8 0.0 0.0 81.5 22.0 0.0 34.8\nrestaurant 8.1 19.1 19.6 19.1 0.0 0.0 13.5 83.6 0.0 18.1\nmovie 14.5 0.0 0.0 0.0 0.0 0.0 0.0 0.0 73.1 9.7\nall 86.1 89.5 49.9 86.2 76.9 78.8 75.4 82.4 72.2 77.5\nTable 9: Type-ignored F1 score in cross-domain setting over lower-cased English datasets with XLM-R BASE. We\ncompute average of accuracy in each test set, named as avg. The model trained on all datasets listed here, is shown\nasall.",
  "keywords": [
    "ner1transformer",
    "corpus",
    "ner",
    "nent",
    "multilingual",
    "nlp",
    "lingual",
    "lstm",
    "corpus5and",
    "languagetask"
  ],
  "intent_category": "named_entity_recognition",
  "named_entities": [
    {
      "text": "Transformer",
      "label": "ORG"
    },
    {
      "text": "Entity Recognition",
      "label": "PERSON"
    },
    {
      "text": "Asahi Ushio",
      "label": "ORG"
    },
    {
      "text": "Jose Camacho-Collados\nSchool of Computer",
      "label": "PERSON"
    },
    {
      "text": "United Kingdom",
      "label": "GPE"
    },
    {
      "text": "NLP",
      "label": "ORG"
    },
    {
      "text": "NER",
      "label": "ORG"
    },
    {
      "text": "NER",
      "label": "ORG"
    },
    {
      "text": "NER",
      "label": "ORG"
    },
    {
      "text": "nine",
      "label": "CARDINAL"
    },
    {
      "text": "NER",
      "label": "ORG"
    },
    {
      "text": "hub2\n1 Introduction\nLanguage",
      "label": "ORG"
    },
    {
      "text": "NLP",
      "label": "ORG"
    },
    {
      "text": "Peters",
      "label": "PERSON"
    },
    {
      "text": "al.",
      "label": "PERSON"
    },
    {
      "text": "2018",
      "label": "DATE"
    },
    {
      "text": "Howard",
      "label": "PERSON"
    },
    {
      "text": "Ruder",
      "label": "ORG"
    },
    {
      "text": "2018",
      "label": "DATE"
    },
    {
      "text": "Radford",
      "label": "ORG"
    },
    {
      "text": "2018",
      "label": "DATE"
    },
    {
      "text": "2019",
      "label": "DATE"
    },
    {
      "text": "Devlin",
      "label": "PERSON"
    },
    {
      "text": "al.",
      "label": "PERSON"
    },
    {
      "text": "2019",
      "label": "DATE"
    },
    {
      "text": "NLP",
      "label": "ORG"
    },
    {
      "text": "2https://huggingface.co/models?search=",
      "label": "CARDINAL"
    },
    {
      "text": "1",
      "label": "CARDINAL"
    },
    {
      "text": "NER",
      "label": "ORG"
    },
    {
      "text": "one",
      "label": "CARDINAL"
    },
    {
      "text": "NER",
      "label": "ORG"
    },
    {
      "text": "NER",
      "label": "ORG"
    },
    {
      "text": "Transformer",
      "label": "ORG"
    },
    {
      "text": "1",
      "label": "CARDINAL"
    },
    {
      "text": "NER",
      "label": "ORG"
    },
    {
      "text": "NER",
      "label": "ORG"
    },
    {
      "text": "NER",
      "label": "ORG"
    },
    {
      "text": "https://spacy.io/",
      "label": "GPE"
    },
    {
      "text": "NLP",
      "label": "ORG"
    },
    {
      "text": "NER",
      "label": "ORG"
    },
    {
      "text": "NER",
      "label": "ORG"
    },
    {
      "text": "9",
      "label": "CARDINAL"
    },
    {
      "text": "Sep 2022\nPytorch",
      "label": "EVENT"
    },
    {
      "text": "Paszke et al.",
      "label": "ORG"
    },
    {
      "text": "2019",
      "label": "DATE"
    },
    {
      "text": "Wolf",
      "label": "PERSON"
    },
    {
      "text": "2019",
      "label": "DATE"
    },
    {
      "text": "2011",
      "label": "DATE"
    },
    {
      "text": "NER",
      "label": "ORG"
    },
    {
      "text": "NER",
      "label": "ORG"
    },
    {
      "text": "Section 2",
      "label": "LAW"
    },
    {
      "text": "Section 3",
      "label": "LAW"
    },
    {
      "text": "Section 4",
      "label": "LAW"
    },
    {
      "text": "2",
      "label": "CARDINAL"
    },
    {
      "text": "NER",
      "label": "ORG"
    },
    {
      "text": "Dante",
      "label": "PERSON"
    },
    {
      "text": "Florence",
      "label": "GPE"
    },
    {
      "text": "NER",
      "label": "ORG"
    },
    {
      "text": "NER",
      "label": "ORG"
    },
    {
      "text": "corpora",
      "label": "PERSON"
    },
    {
      "text": "Ratinov",
      "label": "PERSON"
    },
    {
      "text": "Roth",
      "label": "PERSON"
    },
    {
      "text": "2009",
      "label": "DATE"
    },
    {
      "text": "Collobert",
      "label": "PERSON"
    },
    {
      "text": "2011",
      "label": "DATE"
    },
    {
      "text": "2016",
      "label": "DATE"
    },
    {
      "text": "Chiu",
      "label": "PERSON"
    },
    {
      "text": "Nichols",
      "label": "PERSON"
    },
    {
      "text": "2016",
      "label": "DATE"
    },
    {
      "text": "Hovy",
      "label": "PERSON"
    },
    {
      "text": "2016",
      "label": "DATE"
    },
    {
      "text": "NLP",
      "label": "ORG"
    },
    {
      "text": "NER",
      "label": "ORG"
    },
    {
      "text": "Peters",
      "label": "PERSON"
    },
    {
      "text": "al.",
      "label": "PERSON"
    },
    {
      "text": "2018",
      "label": "DATE"
    },
    {
      "text": "Devlin",
      "label": "ORG"
    },
    {
      "text": "2019",
      "label": "DATE"
    },
    {
      "text": "NLP",
      "label": "ORG"
    },
    {
      "text": "al.",
      "label": "PERSON"
    },
    {
      "text": "2020",
      "label": "DATE"
    },
    {
      "text": "Aharoni",
      "label": "PERSON"
    },
    {
      "text": "Goldberg",
      "label": "PERSON"
    },
    {
      "text": "2020",
      "label": "DATE"
    },
    {
      "text": "Desai",
      "label": "PERSON"
    },
    {
      "text": "Durrett",
      "label": "PERSON"
    },
    {
      "text": "2020",
      "label": "DATE"
    },
    {
      "text": "Gururangan",
      "label": "PERSON"
    },
    {
      "text": "2020",
      "label": "DATE"
    },
    {
      "text": "NER",
      "label": "ORG"
    },
    {
      "text": "2021",
      "label": "DATE"
    },
    {
      "text": "Pfeiffer",
      "label": "ORG"
    },
    {
      "text": "2020a",
      "label": "DATE"
    },
    {
      "text": "Hu et al.",
      "label": "PERSON"
    },
    {
      "text": "NER",
      "label": "ORG"
    },
    {
      "text": "3",
      "label": "CARDINAL"
    },
    {
      "text": "NER",
      "label": "ORG"
    },
    {
      "text": "2",
      "label": "CARDINAL"
    },
    {
      "text": "NLP",
      "label": "ORG"
    },
    {
      "text": "NER",
      "label": "ORG"
    },
    {
      "text": "NLP",
      "label": "ORG"
    },
    {
      "text": "3.1",
      "label": "CARDINAL"
    },
    {
      "text": "nine",
      "label": "CARDINAL"
    },
    {
      "text": "NER",
      "label": "ORG"
    },
    {
      "text": "2006",
      "label": "DATE"
    },
    {
      "text": "Kim Sang",
      "label": "PERSON"
    },
    {
      "text": "De Meulder",
      "label": "ORG"
    },
    {
      "text": "2003",
      "label": "DATE"
    },
    {
      "text": "2017",
      "label": "DATE"
    },
    {
      "text": "Derczynski",
      "label": "PERSON"
    },
    {
      "text": "al.",
      "label": "PERSON"
    },
    {
      "text": "2017",
      "label": "DATE"
    },
    {
      "text": "WikiAnn",
      "label": "ORG"
    },
    {
      "text": "Pan et al.",
      "label": "ORG"
    },
    {
      "text": "2017",
      "label": "DATE"
    },
    {
      "text": "Alvarado",
      "label": "GPE"
    },
    {
      "text": "al.",
      "label": "GPE"
    },
    {
      "text": "2015",
      "label": "DATE"
    },
    {
      "text": "BioNLP 2004",
      "label": "DATE"
    },
    {
      "text": "Kim",
      "label": "PERSON"
    },
    {
      "text": "2004",
      "label": "DATE"
    },
    {
      "text": "BioCreative V CDR4(Wei",
      "label": "ORG"
    },
    {
      "text": "2015",
      "label": "DATE"
    },
    {
      "text": "MIT",
      "label": "ORG"
    },
    {
      "text": "MIT",
      "label": "ORG"
    },
    {
      "text": "WikiAnn",
      "label": "ORG"
    },
    {
      "text": "282",
      "label": "CARDINAL"
    },
    {
      "text": "English",
      "label": "LANGUAGE"
    },
    {
      "text": "MIT",
      "label": "ORG"
    },
    {
      "text": "MIT",
      "label": "ORG"
    },
    {
      "text": "4The",
      "label": "CARDINAL"
    },
    {
      "text": "5The",
      "label": "CARDINAL"
    },
    {
      "text": "two",
      "label": "CARDINAL"
    },
    {
      "text": "6The",
      "label": "CARDINAL"
    },
    {
      "text": "MIT",
      "label": "ORG"
    },
    {
      "text": "NER",
      "label": "ORG"
    },
    {
      "text": "2",
      "label": "CARDINAL"
    },
    {
      "text": "NER",
      "label": "ORG"
    },
    {
      "text": "OntoNotes 5",
      "label": "PRODUCT"
    },
    {
      "text": "Wikipedia",
      "label": "ORG"
    },
    {
      "text": "Liu",
      "label": "PERSON"
    },
    {
      "text": "Lane",
      "label": "GPE"
    },
    {
      "text": "2017",
      "label": "DATE"
    },
    {
      "text": "charac-",
      "label": "DATE"
    },
    {
      "text": "1",
      "label": "CARDINAL"
    },
    {
      "text": "Dataset",
      "label": "ORG"
    },
    {
      "text": "IOB",
      "label": "ORG"
    },
    {
      "text": "Tjong Kim Sang",
      "label": "PERSON"
    },
    {
      "text": "De Meulder",
      "label": "ORG"
    },
    {
      "text": "2003",
      "label": "DATE"
    },
    {
      "text": "IOB",
      "label": "ORG"
    },
    {
      "text": "one",
      "label": "CARDINAL"
    },
    {
      "text": "2003",
      "label": "DATE"
    },
    {
      "text": "EU",
      "label": "ORG"
    },
    {
      "text": "German",
      "label": "NORP"
    },
    {
      "text": "British",
      "label": "NORP"
    },
    {
      "text": "Model Training",
      "label": "PERSON"
    },
    {
      "text": "NER",
      "label": "ORG"
    },
    {
      "text": "2019",
      "label": "DATE"
    },
    {
      "text": "Huggingface",
      "label": "ORG"
    },
    {
      "text": "Wolf",
      "label": "PERSON"
    },
    {
      "text": "2019",
      "label": "DATE"
    },
    {
      "text": "one",
      "label": "CARDINAL"
    },
    {
      "text": "Transformer",
      "label": "ORG"
    },
    {
      "text": "NER",
      "label": "ORG"
    },
    {
      "text": "7https://github.com/NVIDIA/apex",
      "label": "CARDINAL"
    },
    {
      "text": "8To",
      "label": "CARDINAL"
    },
    {
      "text": "OntoNotes5 News",
      "label": "ORG"
    },
    {
      "text": "18 59,924/8,582/8,262",
      "label": "CARDINAL"
    },
    {
      "text": "4 14,041/3,250/3,453",
      "label": "DATE"
    },
    {
      "text": "6",
      "label": "CARDINAL"
    },
    {
      "text": "282",
      "label": "CARDINAL"
    },
    {
      "text": "3 20,000/10,000/10,000",
      "label": "CARDINAL"
    },
    {
      "text": "BioNLP 2004",
      "label": "PRODUCT"
    },
    {
      "text": "5",
      "label": "CARDINAL"
    },
    {
      "text": "BioCreative V Biomedical",
      "label": "ORG"
    },
    {
      "text": "5",
      "label": "CARDINAL"
    },
    {
      "text": "8",
      "label": "CARDINAL"
    },
    {
      "text": "12",
      "label": "CARDINAL"
    },
    {
      "text": "NER",
      "label": "ORG"
    },
    {
      "text": "BASE",
      "label": "PERSON"
    },
    {
      "text": "Liu et al.",
      "label": "PERSON"
    },
    {
      "text": "2019",
      "label": "DATE"
    },
    {
      "text": "Google Colab notebook9",
      "label": "LOC"
    },
    {
      "text": "Tensorboard10to",
      "label": "PRODUCT"
    },
    {
      "text": "3.3",
      "label": "CARDINAL"
    },
    {
      "text": "NER",
      "label": "ORG"
    },
    {
      "text": "one",
      "label": "CARDINAL"
    },
    {
      "text": "Section 3.1",
      "label": "LAW"
    },
    {
      "text": "10www.tensorflow.org/tensorboardHere",
      "label": "DATE"
    },
    {
      "text": "Google Colab",
      "label": "LOC"
    },
    {
      "text": "NER",
      "label": "ORG"
    },
    {
      "text": "4.1",
      "label": "CARDINAL"
    },
    {
      "text": "Experimental Setting",
      "label": "ORG"
    },
    {
      "text": "XLM",
      "label": "ORG"
    },
    {
      "text": "Liu et al.",
      "label": "PERSON"
    },
    {
      "text": "2019",
      "label": "DATE"
    },
    {
      "text": "Huggingface\u2019s XLM-R",
      "label": "ORG"
    },
    {
      "text": "WikiAnn",
      "label": "ORG"
    },
    {
      "text": "Japanese",
      "label": "NORP"
    },
    {
      "text": "MeCab12",
      "label": "PERSON"
    },
    {
      "text": "NER",
      "label": "ORG"
    },
    {
      "text": "seqeval13",
      "label": "GPE"
    },
    {
      "text": "F1",
      "label": "GPE"
    },
    {
      "text": "F1",
      "label": "GPE"
    },
    {
      "text": "11https://colab.research.google.com/",
      "label": "CARDINAL"
    },
    {
      "text": "12https://pypi.org/project/",
      "label": "CARDINAL"
    },
    {
      "text": "13https://pypi.org/project/seqeval/",
      "label": "CARDINAL"
    },
    {
      "text": "F1",
      "label": "GPE"
    },
    {
      "text": "MIT",
      "label": "ORG"
    },
    {
      "text": "MIT",
      "label": "ORG"
    },
    {
      "text": "F1",
      "label": "GPE"
    },
    {
      "text": "4.2",
      "label": "CARDINAL"
    },
    {
      "text": "three",
      "label": "CARDINAL"
    },
    {
      "text": "nine",
      "label": "CARDINAL"
    },
    {
      "text": "Table 1:",
      "label": "LAW"
    },
    {
      "text": "second",
      "label": "ORDINAL"
    },
    {
      "text": "NER",
      "label": "ORG"
    },
    {
      "text": "zero",
      "label": "CARDINAL"
    },
    {
      "text": "NER",
      "label": "ORG"
    },
    {
      "text": "WikiAnn",
      "label": "ORG"
    },
    {
      "text": "Table 2",
      "label": "EVENT"
    },
    {
      "text": "F1",
      "label": "GPE"
    },
    {
      "text": "XLM",
      "label": "ORG"
    },
    {
      "text": "andXLM",
      "label": "NORP"
    },
    {
      "text": "SoTA",
      "label": "ORG"
    },
    {
      "text": "XLM",
      "label": "ORG"
    },
    {
      "text": "SoTA",
      "label": "ORG"
    },
    {
      "text": "2017",
      "label": "DATE"
    },
    {
      "text": "XLM",
      "label": "ORG"
    },
    {
      "text": "XLM",
      "label": "NORP"
    },
    {
      "text": "SoTA",
      "label": "ORG"
    },
    {
      "text": "XLM",
      "label": "ORG"
    },
    {
      "text": "XLM",
      "label": "ORG"
    },
    {
      "text": "89.0 89.1 92.1",
      "label": "QUANTITY"
    },
    {
      "text": "2003",
      "label": "DATE"
    },
    {
      "text": "90.8 92.9 94.3\n",
      "label": "QUANTITY"
    },
    {
      "text": "2017",
      "label": "DATE"
    },
    {
      "text": "58.5 50.3",
      "label": "CARDINAL"
    },
    {
      "text": "82.7",
      "label": "CARDINAL"
    },
    {
      "text": "BioNLP 2004",
      "label": "PRODUCT"
    },
    {
      "text": "74.3 77.4",
      "label": "CARDINAL"
    },
    {
      "text": "BioCreative V",
      "label": "PRODUCT"
    },
    {
      "text": "88.0",
      "label": "CARDINAL"
    },
    {
      "text": "88.6 89.9\nMIT",
      "label": "QUANTITY"
    },
    {
      "text": "MIT",
      "label": "ORG"
    },
    {
      "text": "69.9",
      "label": "CARDINAL"
    },
    {
      "text": "WikiAnn",
      "label": "ORG"
    },
    {
      "text": "82.7 84.0 84.8",
      "label": "QUANTITY"
    },
    {
      "text": "WikiAnn",
      "label": "ORG"
    },
    {
      "text": "83.8",
      "label": "CARDINAL"
    },
    {
      "text": "86.5 73.3",
      "label": "CARDINAL"
    },
    {
      "text": "WikiAnn",
      "label": "ORG"
    },
    {
      "text": "88.6",
      "label": "CARDINAL"
    },
    {
      "text": "WikiAnn",
      "label": "ORG"
    },
    {
      "text": "90.9 92.1",
      "label": "CARDINAL"
    },
    {
      "text": "WikiAnn",
      "label": "ORG"
    },
    {
      "text": "87.5",
      "label": "CARDINAL"
    },
    {
      "text": "WikiAnn",
      "label": "ORG"
    },
    {
      "text": "88.9",
      "label": "CARDINAL"
    },
    {
      "text": "F1",
      "label": "GPE"
    },
    {
      "text": "SoTA",
      "label": "ORG"
    },
    {
      "text": "BERT-MRC-DSC",
      "label": "ORG"
    },
    {
      "text": "Li et al.",
      "label": "PERSON"
    },
    {
      "text": "2019",
      "label": "DATE"
    },
    {
      "text": "LUKE",
      "label": "PERSON"
    },
    {
      "text": "Yamada",
      "label": "PERSON"
    },
    {
      "text": "2020",
      "label": "DATE"
    },
    {
      "text": "2003",
      "label": "DATE"
    },
    {
      "text": "CrossWeigh",
      "label": "ORG"
    },
    {
      "text": "Wang et al.",
      "label": "PERSON"
    },
    {
      "text": "2019",
      "label": "DATE"
    },
    {
      "text": "2017",
      "label": "DATE"
    },
    {
      "text": "Pfeiffer",
      "label": "ORG"
    },
    {
      "text": "2020a",
      "label": "DATE"
    },
    {
      "text": "WikiAnn",
      "label": "ORG"
    },
    {
      "text": "ko",
      "label": "PERSON"
    },
    {
      "text": "Salinas Alvarado",
      "label": "PERSON"
    },
    {
      "text": "al.",
      "label": "PERSON"
    },
    {
      "text": "2015",
      "label": "DATE"
    },
    {
      "text": "Lee et al.",
      "label": "PERSON"
    },
    {
      "text": "2020",
      "label": "DATE"
    },
    {
      "text": "2004",
      "label": "DATE"
    },
    {
      "text": "Nooralahzadeh et al.",
      "label": "FAC"
    },
    {
      "text": "2019",
      "label": "DATE"
    },
    {
      "text": "BioCreative",
      "label": "ORG"
    },
    {
      "text": "Pfeiffer",
      "label": "ORG"
    },
    {
      "text": "2020a",
      "label": "DATE"
    },
    {
      "text": "WikiAnn",
      "label": "ORG"
    },
    {
      "text": "English",
      "label": "NORP"
    },
    {
      "text": "2003",
      "label": "DATE"
    },
    {
      "text": "WikiAnn",
      "label": "ORG"
    },
    {
      "text": "BioNLP 2004",
      "label": "DATE"
    },
    {
      "text": "BioCreative V",
      "label": "ORG"
    },
    {
      "text": "XLM",
      "label": "ORG"
    },
    {
      "text": "Table 3",
      "label": "DATE"
    },
    {
      "text": "F1",
      "label": "GPE"
    },
    {
      "text": "NER",
      "label": "ORG"
    },
    {
      "text": "Protein ,Chemical",
      "label": "ORG"
    },
    {
      "text": "14We",
      "label": "CARDINAL"
    },
    {
      "text": "MIT",
      "label": "ORG"
    },
    {
      "text": "91.6",
      "label": "CARDINAL"
    },
    {
      "text": "53.6",
      "label": "CARDINAL"
    },
    {
      "text": "18.3 40.8",
      "label": "CARDINAL"
    },
    {
      "text": "62.2",
      "label": "CARDINAL"
    },
    {
      "text": "69.1 61.7",
      "label": "CARDINAL"
    },
    {
      "text": "22.7",
      "label": "CARDINAL"
    },
    {
      "text": "41.8",
      "label": "CARDINAL"
    },
    {
      "text": "68.3 54.5",
      "label": "CARDINAL"
    },
    {
      "text": "20.0 31.7",
      "label": "CARDINAL"
    },
    {
      "text": "32.8",
      "label": "CARDINAL"
    },
    {
      "text": "53.6 93.4",
      "label": "CARDINAL"
    },
    {
      "text": "12.2 29.6",
      "label": "CARDINAL"
    },
    {
      "text": "0.0",
      "label": "CARDINAL"
    },
    {
      "text": "8.7",
      "label": "CARDINAL"
    },
    {
      "text": "0.0 0.0 0.0 0.0 88.8",
      "label": "WORK_OF_ART"
    },
    {
      "text": "9.8",
      "label": "CARDINAL"
    },
    {
      "text": "48.2",
      "label": "CARDINAL"
    },
    {
      "text": "60.9 58.9",
      "label": "CARDINAL"
    },
    {
      "text": "82.0 38.1",
      "label": "CARDINAL"
    },
    {
      "text": "90.9",
      "label": "CARDINAL"
    },
    {
      "text": "60.9",
      "label": "CARDINAL"
    },
    {
      "text": "91.3",
      "label": "CARDINAL"
    },
    {
      "text": "78.3",
      "label": "CARDINAL"
    },
    {
      "text": "84.6",
      "label": "CARDINAL"
    },
    {
      "text": "75.5 81.7",
      "label": "CARDINAL"
    },
    {
      "text": "3",
      "label": "CARDINAL"
    },
    {
      "text": "F1",
      "label": "GPE"
    },
    {
      "text": "English",
      "label": "NORP"
    },
    {
      "text": "ja ru ko",
      "label": "PERSON"
    },
    {
      "text": "84.0 46.3",
      "label": "QUANTITY"
    },
    {
      "text": "58.1",
      "label": "CARDINAL"
    },
    {
      "text": "71.4 53.2",
      "label": "CARDINAL"
    },
    {
      "text": "53.0",
      "label": "CARDINAL"
    },
    {
      "text": "86.5",
      "label": "CARDINAL"
    },
    {
      "text": "45.7",
      "label": "CARDINAL"
    },
    {
      "text": "57.1",
      "label": "CARDINAL"
    },
    {
      "text": "55.4",
      "label": "CARDINAL"
    },
    {
      "text": "60.4",
      "label": "CARDINAL"
    },
    {
      "text": "76.8 54.9",
      "label": "CARDINAL"
    },
    {
      "text": "68.6",
      "label": "CARDINAL"
    },
    {
      "text": "66.2 57.2",
      "label": "CARDINAL"
    },
    {
      "text": "70.5",
      "label": "CARDINAL"
    },
    {
      "text": "61.8 92.1 62.1",
      "label": "CARDINAL"
    },
    {
      "text": "60.1",
      "label": "CARDINAL"
    },
    {
      "text": "90.3",
      "label": "CARDINAL"
    },
    {
      "text": "4",
      "label": "CARDINAL"
    },
    {
      "text": "F1",
      "label": "GPE"
    },
    {
      "text": "WikiAnn",
      "label": "ORG"
    },
    {
      "text": "85.7",
      "label": "CARDINAL"
    },
    {
      "text": "1,000",
      "label": "CARDINAL"
    },
    {
      "text": "14,041",
      "label": "CARDINAL"
    },
    {
      "text": "59,924",
      "label": "CARDINAL"
    },
    {
      "text": "F1",
      "label": "GPE"
    },
    {
      "text": "zero",
      "label": "CARDINAL"
    },
    {
      "text": "NER",
      "label": "ORG"
    },
    {
      "text": "WikiAnn",
      "label": "ORG"
    },
    {
      "text": "wherewe",
      "label": "GPE"
    },
    {
      "text": "six",
      "label": "CARDINAL"
    },
    {
      "text": "English",
      "label": "LANGUAGE"
    },
    {
      "text": "Japanese",
      "label": "NORP"
    },
    {
      "text": "Russian",
      "label": "NORP"
    },
    {
      "text": "Korean",
      "label": "NORP"
    },
    {
      "text": "ko",
      "label": "PERSON"
    },
    {
      "text": "Spanish",
      "label": "NORP"
    },
    {
      "text": "Arabic",
      "label": "LANGUAGE"
    },
    {
      "text": "Table 4",
      "label": "DATE"
    },
    {
      "text": "First",
      "label": "ORDINAL"
    },
    {
      "text": "Russian",
      "label": "NORP"
    },
    {
      "text": "Spanish",
      "label": "NORP"
    },
    {
      "text": "Second",
      "label": "ORDINAL"
    },
    {
      "text": "Arabic",
      "label": "LANGUAGE"
    },
    {
      "text": "Spanish",
      "label": "NORP"
    },
    {
      "text": "Arabic",
      "label": "NORP"
    },
    {
      "text": "in\ufb02u-",
      "label": "CARDINAL"
    },
    {
      "text": "Spanish",
      "label": "LANGUAGE"
    },
    {
      "text": "Stewart",
      "label": "PERSON"
    },
    {
      "text": "1999",
      "label": "DATE"
    },
    {
      "text": "NER",
      "label": "ORG"
    },
    {
      "text": "Hu et al.",
      "label": "PERSON"
    },
    {
      "text": "2020a",
      "label": "DATE"
    },
    {
      "text": "WikiAnn",
      "label": "ORG"
    },
    {
      "text": "XLM",
      "label": "ORG"
    },
    {
      "text": "NER",
      "label": "ORG"
    },
    {
      "text": "Conneau et al",
      "label": "FAC"
    },
    {
      "text": "2020",
      "label": "DATE"
    },
    {
      "text": "zero",
      "label": "CARDINAL"
    },
    {
      "text": "Pfeiffer",
      "label": "ORG"
    },
    {
      "text": "NER",
      "label": "ORG"
    },
    {
      "text": "recent years",
      "label": "DATE"
    },
    {
      "text": "NER",
      "label": "ORG"
    },
    {
      "text": "5",
      "label": "CARDINAL"
    },
    {
      "text": "Transformer",
      "label": "ORG"
    },
    {
      "text": "NER",
      "label": "ORG"
    },
    {
      "text": "NER",
      "label": "ORG"
    },
    {
      "text": "NER",
      "label": "ORG"
    },
    {
      "text": "NER",
      "label": "ORG"
    },
    {
      "text": "English",
      "label": "LANGUAGE"
    },
    {
      "text": "NER",
      "label": "ORG"
    },
    {
      "text": "NLP",
      "label": "ORG"
    },
    {
      "text": "Dimosthenis Antypas",
      "label": "PERSON"
    },
    {
      "text": "Yinfei Yang",
      "label": "PERSON"
    },
    {
      "text": "Byron C Wallace",
      "label": "PERSON"
    },
    {
      "text": "Ani Nenkova",
      "label": "PERSON"
    },
    {
      "text": "2021",
      "label": "DATE"
    },
    {
      "text": "Roee Aharoni",
      "label": "PERSON"
    },
    {
      "text": "Yoav Goldberg",
      "label": "PERSON"
    },
    {
      "text": "2020",
      "label": "DATE"
    },
    {
      "text": "Computational Linguistics",
      "label": "ORG"
    },
    {
      "text": "7747",
      "label": "DATE"
    },
    {
      "text": "7763",
      "label": "DATE"
    },
    {
      "text": "Computational",
      "label": "ORG"
    },
    {
      "text": "Jason P.C. Chiu",
      "label": "PERSON"
    },
    {
      "text": "Eric Nichols",
      "label": "PERSON"
    },
    {
      "text": "2016",
      "label": "DATE"
    },
    {
      "text": "the Association for Computational",
      "label": "ORG"
    },
    {
      "text": "Nigel Collier",
      "label": "PERSON"
    },
    {
      "text": "Jin-Dong Kim",
      "label": "PERSON"
    },
    {
      "text": "2004",
      "label": "DATE"
    },
    {
      "text": "JNLPBA",
      "label": "ORG"
    },
    {
      "text": "the International Joint Workshop",
      "label": "ORG"
    },
    {
      "text": "Natural Language Processing",
      "label": "ORG"
    },
    {
      "text": "73\u201378",
      "label": "MONEY"
    },
    {
      "text": "Geneva",
      "label": "GPE"
    },
    {
      "text": "Switzerland",
      "label": "GPE"
    },
    {
      "text": "Ronan Collobert",
      "label": "PERSON"
    },
    {
      "text": "Jason Weston",
      "label": "PERSON"
    },
    {
      "text": "Michael\nKarlen",
      "label": "PERSON"
    },
    {
      "text": "Koray Kavukcuoglu",
      "label": "PERSON"
    },
    {
      "text": "Pavel Kuksa",
      "label": "PERSON"
    },
    {
      "text": "2011",
      "label": "DATE"
    },
    {
      "text": "Alexis Conneau",
      "label": "PERSON"
    },
    {
      "text": "Shijie Wu",
      "label": "PERSON"
    },
    {
      "text": "Haoran Li",
      "label": "PERSON"
    },
    {
      "text": "Luke Zettle-",
      "label": "PERSON"
    },
    {
      "text": "Veselin Stoyanov",
      "label": "PERSON"
    },
    {
      "text": "2020",
      "label": "DATE"
    },
    {
      "text": "Computational Linguistics",
      "label": "ORG"
    },
    {
      "text": "6022",
      "label": "DATE"
    },
    {
      "text": "6034",
      "label": "DATE"
    },
    {
      "text": "Computational",
      "label": "ORG"
    },
    {
      "text": "Leon Derczynski",
      "label": "PERSON"
    },
    {
      "text": "Eric Nichols",
      "label": "PERSON"
    },
    {
      "text": "Marieke van Erp",
      "label": "PERSON"
    },
    {
      "text": "Nut Limsopatham",
      "label": "ORG"
    },
    {
      "text": "2017",
      "label": "DATE"
    },
    {
      "text": "140\u2013147",
      "label": "CARDINAL"
    },
    {
      "text": "Copenhagen",
      "label": "ORG"
    },
    {
      "text": "Denmark",
      "label": "GPE"
    },
    {
      "text": "Shrey Desai",
      "label": "PERSON"
    },
    {
      "text": "Greg Durrett",
      "label": "PERSON"
    },
    {
      "text": "2020",
      "label": "DATE"
    },
    {
      "text": "arXiv:2003.07892",
      "label": "PERSON"
    },
    {
      "text": "Jacob Devlin",
      "label": "PERSON"
    },
    {
      "text": "Ming-Wei Chang",
      "label": "PERSON"
    },
    {
      "text": "Kenton Lee",
      "label": "PERSON"
    },
    {
      "text": "Kristina Toutanova",
      "label": "PERSON"
    },
    {
      "text": "2019",
      "label": "DATE"
    },
    {
      "text": "BERT",
      "label": "ORG"
    },
    {
      "text": "2019",
      "label": "DATE"
    },
    {
      "text": "the North American Chapter",
      "label": "ORG"
    },
    {
      "text": "Association",
      "label": "ORG"
    },
    {
      "text": "1",
      "label": "CARDINAL"
    },
    {
      "text": "4171\u20134186",
      "label": "DATE"
    },
    {
      "text": "Minneapolis",
      "label": "GPE"
    },
    {
      "text": "Minnesota",
      "label": "GPE"
    },
    {
      "text": "Computational Linguistics",
      "label": "ORG"
    },
    {
      "text": "Suchin Gururangan",
      "label": "PERSON"
    },
    {
      "text": "Swabha",
      "label": "GPE"
    },
    {
      "text": "Swayamdipta",
      "label": "GPE"
    },
    {
      "text": "Kyle Lo",
      "label": "PERSON"
    },
    {
      "text": "Iz Beltagy",
      "label": "PERSON"
    },
    {
      "text": "Doug Downey",
      "label": "PERSON"
    },
    {
      "text": "Noah A Smith",
      "label": "ORG"
    },
    {
      "text": "2020",
      "label": "DATE"
    },
    {
      "text": "Adapt",
      "label": "PRODUCT"
    },
    {
      "text": "Dan Hendrycks",
      "label": "PERSON"
    },
    {
      "text": "Xiaoyuan Liu",
      "label": "PERSON"
    },
    {
      "text": "Eric Wallace",
      "label": "PERSON"
    },
    {
      "text": "Adam\nDziedzic",
      "label": "PERSON"
    },
    {
      "text": "Rishabh Krishnan",
      "label": "PERSON"
    },
    {
      "text": "Dawn Song",
      "label": "PERSON"
    },
    {
      "text": "2020",
      "label": "DATE"
    },
    {
      "text": "Eduard Hovy",
      "label": "PERSON"
    },
    {
      "text": "Martha Palmer",
      "label": "PERSON"
    },
    {
      "text": "Lance\nRamshaw",
      "label": "PERSON"
    },
    {
      "text": "Ralph Weischedel",
      "label": "PERSON"
    },
    {
      "text": "2006",
      "label": "DATE"
    },
    {
      "text": "OntoNotes",
      "label": "ORG"
    },
    {
      "text": "90%",
      "label": "PERCENT"
    },
    {
      "text": "Language Technology Conference of the",
      "label": "ORG"
    },
    {
      "text": "NAACL",
      "label": "ORG"
    },
    {
      "text": "57\u201360",
      "label": "DATE"
    },
    {
      "text": "New York City",
      "label": "GPE"
    },
    {
      "text": "USA",
      "label": "GPE"
    },
    {
      "text": "Computa-",
      "label": "PERSON"
    },
    {
      "text": "Linguistics",
      "label": "PERSON"
    },
    {
      "text": "Jeremy Howard",
      "label": "PERSON"
    },
    {
      "text": "Sebastian Ruder",
      "label": "PERSON"
    },
    {
      "text": "2018",
      "label": "DATE"
    },
    {
      "text": "56th",
      "label": "ORDINAL"
    },
    {
      "text": "Computational Linguistics (",
      "label": "ORG"
    },
    {
      "text": "1",
      "label": "CARDINAL"
    },
    {
      "text": "328\u2013339",
      "label": "CARDINAL"
    },
    {
      "text": "Melbourne",
      "label": "GPE"
    },
    {
      "text": "Australia",
      "label": "GPE"
    },
    {
      "text": "Junjie Hu",
      "label": "PERSON"
    },
    {
      "text": "Sebastian Ruder",
      "label": "PERSON"
    },
    {
      "text": "Aditya Siddhant",
      "label": "PERSON"
    },
    {
      "text": "Neubig, Orhan Firat",
      "label": "ORG"
    },
    {
      "text": "Melvin Johnson",
      "label": "PERSON"
    },
    {
      "text": "2020a",
      "label": "DATE"
    },
    {
      "text": "Junjie Hu",
      "label": "PERSON"
    },
    {
      "text": "Sebastian Ruder",
      "label": "PERSON"
    },
    {
      "text": "Aditya Siddhant",
      "label": "PERSON"
    },
    {
      "text": "Neubig, Orhan Firat",
      "label": "ORG"
    },
    {
      "text": "Melvin Johnson",
      "label": "PERSON"
    },
    {
      "text": "2020b",
      "label": "DATE"
    },
    {
      "text": "Xtreme",
      "label": "PERSON"
    },
    {
      "text": "Guillaume Lample",
      "label": "PERSON"
    },
    {
      "text": "Miguel Ballesteros",
      "label": "PERSON"
    },
    {
      "text": "Kazuya Kawakami",
      "label": "PERSON"
    },
    {
      "text": "Chris Dyer",
      "label": "PERSON"
    },
    {
      "text": "2016",
      "label": "DATE"
    },
    {
      "text": "the 2016 Conference of the North\nAmerican Chapter of the Association for Computa-",
      "label": "EVENT"
    },
    {
      "text": "260\u2013270",
      "label": "CARDINAL"
    },
    {
      "text": "San Diego",
      "label": "GPE"
    },
    {
      "text": "California",
      "label": "GPE"
    },
    {
      "text": "Jinhyuk Lee",
      "label": "PERSON"
    },
    {
      "text": "Wonjin",
      "label": "GPE"
    },
    {
      "text": "Yoon",
      "label": "GPE"
    },
    {
      "text": "Sungdong Kim",
      "label": "PERSON"
    },
    {
      "text": "Donghyeon Kim",
      "label": "PERSON"
    },
    {
      "text": "Sunkyu Kim",
      "label": "PERSON"
    },
    {
      "text": "Chan Ho",
      "label": "PERSON"
    },
    {
      "text": "Jaewoo Kang",
      "label": "PERSON"
    },
    {
      "text": "2020",
      "label": "DATE"
    },
    {
      "text": "Biobert",
      "label": "PERSON"
    },
    {
      "text": "36(4):1234\u20131240",
      "label": "DATE"
    },
    {
      "text": "Xiaoya Li",
      "label": "PERSON"
    },
    {
      "text": "Xiaofei Sun",
      "label": "PERSON"
    },
    {
      "text": "Yuxian Meng",
      "label": "PERSON"
    },
    {
      "text": "Junjun",
      "label": "GPE"
    },
    {
      "text": "Fei Wu",
      "label": "PERSON"
    },
    {
      "text": "Jiwei Li",
      "label": "PERSON"
    },
    {
      "text": "2019",
      "label": "DATE"
    },
    {
      "text": "Bing Liu",
      "label": "PERSON"
    },
    {
      "text": "Ian Lane",
      "label": "PERSON"
    },
    {
      "text": "2017",
      "label": "DATE"
    },
    {
      "text": "Yinhan Liu",
      "label": "PERSON"
    },
    {
      "text": "Myle Ott",
      "label": "PERSON"
    },
    {
      "text": "Naman Goyal",
      "label": "PERSON"
    },
    {
      "text": "Jingfei Du",
      "label": "PERSON"
    },
    {
      "text": "Joshi",
      "label": "PERSON"
    },
    {
      "text": "Danqi Chen",
      "label": "PERSON"
    },
    {
      "text": "Omer Levy",
      "label": "PERSON"
    },
    {
      "text": "Mike Lewis",
      "label": "PERSON"
    },
    {
      "text": "Luke Zettlemoyer",
      "label": "PERSON"
    },
    {
      "text": "Veselin Stoyanov",
      "label": "PERSON"
    },
    {
      "text": "2019",
      "label": "DATE"
    },
    {
      "text": "Roberta",
      "label": "PERSON"
    },
    {
      "text": "Xuezhe Ma",
      "label": "PERSON"
    },
    {
      "text": "Eduard Hovy",
      "label": "PERSON"
    },
    {
      "text": "2016",
      "label": "DATE"
    },
    {
      "text": "the Association for Computational Linguistics",
      "label": "ORG"
    },
    {
      "text": "1",
      "label": "CARDINAL"
    },
    {
      "text": "1064\u20131074",
      "label": "CARDINAL"
    },
    {
      "text": "Berlin",
      "label": "GPE"
    },
    {
      "text": "Farhad Nooralahzadeh",
      "label": "FAC"
    },
    {
      "text": "Lilja\n\u00d8vrelid",
      "label": "ORG"
    },
    {
      "text": "2019",
      "label": "DATE"
    },
    {
      "text": "2nd",
      "label": "ORDINAL"
    },
    {
      "text": "Workshop on Deep Learning\nApproaches for Low-Resource NLP",
      "label": "EVENT"
    },
    {
      "text": "2019",
      "label": "DATE"
    },
    {
      "text": "225\u2013233",
      "label": "CARDINAL"
    },
    {
      "text": "Boliang Zhang",
      "label": "PERSON"
    },
    {
      "text": "Jonathan May",
      "label": "PERSON"
    },
    {
      "text": "Joel\nNothman",
      "label": "PERSON"
    },
    {
      "text": "Kevin Knight",
      "label": "PERSON"
    },
    {
      "text": "Heng Ji",
      "label": "PERSON"
    },
    {
      "text": "2017",
      "label": "DATE"
    },
    {
      "text": "282",
      "label": "CARDINAL"
    },
    {
      "text": "55th",
      "label": "ORDINAL"
    },
    {
      "text": "the\nAssociation for Computational Linguistics",
      "label": "ORG"
    },
    {
      "text": "1",
      "label": "CARDINAL"
    },
    {
      "text": "1946\u20131958",
      "label": "DATE"
    },
    {
      "text": "Vancouver",
      "label": "GPE"
    },
    {
      "text": "Canada",
      "label": "GPE"
    },
    {
      "text": "Adam Paszke",
      "label": "PERSON"
    },
    {
      "text": "Sam Gross",
      "label": "PERSON"
    },
    {
      "text": "Francisco Massa",
      "label": "PERSON"
    },
    {
      "text": "Adam\nLerer",
      "label": "PERSON"
    },
    {
      "text": "James Bradbury",
      "label": "PERSON"
    },
    {
      "text": "Gregory Chanan",
      "label": "PERSON"
    },
    {
      "text": "Killeen",
      "label": "PERSON"
    },
    {
      "text": "Zeming Lin",
      "label": "PERSON"
    },
    {
      "text": "Natalia Gimelshein",
      "label": "ORG"
    },
    {
      "text": "al",
      "label": "PERSON"
    },
    {
      "text": "2019",
      "label": "DATE"
    },
    {
      "text": "8026\u20138037",
      "label": "DATE"
    },
    {
      "text": "Fabian",
      "label": "NORP"
    },
    {
      "text": "Ga",
      "label": "PERSON"
    },
    {
      "text": "Varoquaux",
      "label": "PERSON"
    },
    {
      "text": "Alexandre",
      "label": "PERSON"
    },
    {
      "text": "Vincent Michel",
      "label": "PERSON"
    },
    {
      "text": "Bertrand Thirion",
      "label": "PERSON"
    },
    {
      "text": "Olivier\nGrisel",
      "label": "PERSON"
    },
    {
      "text": "Mathieu Blondel",
      "label": "ORG"
    },
    {
      "text": "Peter Prettenhofer",
      "label": "PERSON"
    },
    {
      "text": "Ron\nWeiss",
      "label": "PERSON"
    },
    {
      "text": "Vincent Dubourg",
      "label": "PERSON"
    },
    {
      "text": "al",
      "label": "PERSON"
    },
    {
      "text": "2011",
      "label": "DATE"
    },
    {
      "text": "Journal",
      "label": "ORG"
    },
    {
      "text": "12:2825\u20132830",
      "label": "CARDINAL"
    },
    {
      "text": "Matthew Peters",
      "label": "PERSON"
    },
    {
      "text": "Mark Neumann",
      "label": "PERSON"
    },
    {
      "text": "Mohit Iyyer",
      "label": "PERSON"
    },
    {
      "text": "Matt\nGardner",
      "label": "PERSON"
    },
    {
      "text": "Christopher Clark",
      "label": "PERSON"
    },
    {
      "text": "Kenton Lee",
      "label": "PERSON"
    },
    {
      "text": "Luke\nZettlemoyer",
      "label": "PERSON"
    },
    {
      "text": "2018",
      "label": "DATE"
    },
    {
      "text": "2018",
      "label": "DATE"
    },
    {
      "text": "the North American Chapter",
      "label": "ORG"
    },
    {
      "text": "Computational Linguistics: Human",
      "label": "ORG"
    },
    {
      "text": "1",
      "label": "CARDINAL"
    },
    {
      "text": "New Orleans",
      "label": "GPE"
    },
    {
      "text": "Louisiana",
      "label": "GPE"
    },
    {
      "text": "Jonas Pfeiffer",
      "label": "PERSON"
    },
    {
      "text": "Ivan Vuli",
      "label": "PERSON"
    },
    {
      "text": "Iryna Gurevych",
      "label": "PERSON"
    },
    {
      "text": "Sebas-\n",
      "label": "PERSON"
    },
    {
      "text": "2020a",
      "label": "DATE"
    },
    {
      "text": "Jonas Pfeiffer",
      "label": "PERSON"
    },
    {
      "text": "Ivan Vuli",
      "label": "PERSON"
    },
    {
      "text": "Iryna Gurevych",
      "label": "PERSON"
    },
    {
      "text": "2020b",
      "label": "DATE"
    },
    {
      "text": "MAD",
      "label": "ORG"
    },
    {
      "text": "Multi-Task Cross-Lingual Transfer",
      "label": "ORG"
    },
    {
      "text": "the 2020 Conference on Empirical\nMethods in Natural Language Processing (EMNLP",
      "label": "ORG"
    },
    {
      "text": "7654\u20137673",
      "label": "DATE"
    },
    {
      "text": "Computa-",
      "label": "PERSON"
    },
    {
      "text": "Linguistics",
      "label": "PERSON"
    },
    {
      "text": "Alec Radford",
      "label": "PERSON"
    },
    {
      "text": "Karthik Narasimhan",
      "label": "PERSON"
    },
    {
      "text": "Tim Salimans",
      "label": "PERSON"
    },
    {
      "text": "2018",
      "label": "DATE"
    },
    {
      "text": "Alec Radford",
      "label": "PERSON"
    },
    {
      "text": "Jeffrey Wu",
      "label": "PERSON"
    },
    {
      "text": "Rewon Child",
      "label": "PERSON"
    },
    {
      "text": "David Luan",
      "label": "PERSON"
    },
    {
      "text": "Dario Amodei",
      "label": "PERSON"
    },
    {
      "text": "2019",
      "label": "DATE"
    },
    {
      "text": "Lev Ratinov",
      "label": "PERSON"
    },
    {
      "text": "Dan Roth",
      "label": "PERSON"
    },
    {
      "text": "2009",
      "label": "DATE"
    },
    {
      "text": "Thirteenth",
      "label": "ORDINAL"
    },
    {
      "text": "Computational Natural Language Learning",
      "label": "ORG"
    },
    {
      "text": "147\u2013155",
      "label": "CARDINAL"
    },
    {
      "text": "Boulder",
      "label": "GPE"
    },
    {
      "text": "Colorado",
      "label": "GPE"
    },
    {
      "text": "Julio Cesar Salinas Alvarado",
      "label": "PERSON"
    },
    {
      "text": "Karin Verspoor",
      "label": "ORG"
    },
    {
      "text": "Tim-",
      "label": "CARDINAL"
    },
    {
      "text": "Baldwin",
      "label": "GPE"
    },
    {
      "text": "2015",
      "label": "DATE"
    },
    {
      "text": "Association Workshop 2015",
      "label": "ORG"
    },
    {
      "text": "84\u201390",
      "label": "CARDINAL"
    },
    {
      "text": "Australia",
      "label": "GPE"
    },
    {
      "text": "Miranda Stewart",
      "label": "PERSON"
    },
    {
      "text": "al",
      "label": "PERSON"
    },
    {
      "text": "1999",
      "label": "DATE"
    },
    {
      "text": "Spanish",
      "label": "LANGUAGE"
    },
    {
      "text": "today",
      "label": "DATE"
    },
    {
      "text": "Erik F. Tjong Kim Sang",
      "label": "PERSON"
    },
    {
      "text": "Fien De Meulder",
      "label": "ORG"
    },
    {
      "text": "2003",
      "label": "DATE"
    },
    {
      "text": "CoNLL-2003",
      "label": "ORG"
    },
    {
      "text": "Language Learning",
      "label": "FAC"
    },
    {
      "text": "2003",
      "label": "DATE"
    },
    {
      "text": "142\u2013147",
      "label": "CARDINAL"
    },
    {
      "text": "Zihan Wang",
      "label": "PERSON"
    },
    {
      "text": "Jingbo Shang",
      "label": "PERSON"
    },
    {
      "text": "Liyuan Liu",
      "label": "PERSON"
    },
    {
      "text": "Lihao Lu",
      "label": "PERSON"
    },
    {
      "text": "Ji-\nacheng Liu",
      "label": "PERSON"
    },
    {
      "text": "Jiawei Han",
      "label": "PERSON"
    },
    {
      "text": "2019",
      "label": "DATE"
    },
    {
      "text": "the 2019 Conference on\nEmpirical Methods in Natural Language Processing",
      "label": "EVENT"
    },
    {
      "text": "9th",
      "label": "ORDINAL"
    },
    {
      "text": "5157\u20135166",
      "label": "CARDINAL"
    },
    {
      "text": "Hsuan Wei",
      "label": "PERSON"
    },
    {
      "text": "Yifan Peng",
      "label": "PERSON"
    },
    {
      "text": "Robert Leaman",
      "label": "PERSON"
    },
    {
      "text": "Peter Davis",
      "label": "PERSON"
    },
    {
      "text": "Carolyn J Mattingly",
      "label": "PERSON"
    },
    {
      "text": "Jiao Li",
      "label": "PERSON"
    },
    {
      "text": "Thomas C Wiegers",
      "label": "PERSON"
    },
    {
      "text": "Zhiyong Lu",
      "label": "PERSON"
    },
    {
      "text": "2015",
      "label": "DATE"
    },
    {
      "text": "14",
      "label": "CARDINAL"
    },
    {
      "text": "Thomas Wolf",
      "label": "PERSON"
    },
    {
      "text": "Lysandre Debut",
      "label": "PERSON"
    },
    {
      "text": "Victor Sanh",
      "label": "PERSON"
    },
    {
      "text": "Julien\nChaumond",
      "label": "PERSON"
    },
    {
      "text": "Clement Delangue",
      "label": "PERSON"
    },
    {
      "text": "Anthony Moi",
      "label": "PERSON"
    },
    {
      "text": "Tim Rault",
      "label": "PERSON"
    },
    {
      "text": "Louf",
      "label": "ORG"
    },
    {
      "text": "Joe Davison",
      "label": "PERSON"
    },
    {
      "text": "Sam Shleifer",
      "label": "PERSON"
    },
    {
      "text": "Patrick von Platen",
      "label": "PERSON"
    },
    {
      "text": "Clara Ma",
      "label": "PERSON"
    },
    {
      "text": "Yacine Jernite",
      "label": "PERSON"
    },
    {
      "text": "Julien Plu",
      "label": "PERSON"
    },
    {
      "text": "Canwen Xu",
      "label": "PERSON"
    },
    {
      "text": "Teven Le Scao",
      "label": "PERSON"
    },
    {
      "text": "Sylvain Gugger",
      "label": "PERSON"
    },
    {
      "text": "Mariama Drame",
      "label": "PERSON"
    },
    {
      "text": "Quentin Lhoest",
      "label": "PERSON"
    },
    {
      "text": "Alexander M. Rush",
      "label": "PERSON"
    },
    {
      "text": "2019",
      "label": "DATE"
    },
    {
      "text": "Huggingface",
      "label": "ORG"
    },
    {
      "text": "Ikuya Yamada",
      "label": "PERSON"
    },
    {
      "text": "Akari Asai",
      "label": "PERSON"
    },
    {
      "text": "Hiroyuki Shindo",
      "label": "PERSON"
    },
    {
      "text": "Hideaki\nTakeda",
      "label": "ORG"
    },
    {
      "text": "Yuji Matsumoto",
      "label": "PERSON"
    },
    {
      "text": "2020",
      "label": "DATE"
    },
    {
      "text": "LUKE",
      "label": "PERSON"
    },
    {
      "text": "2020",
      "label": "DATE"
    },
    {
      "text": "6442\u20136454",
      "label": "CARDINAL"
    },
    {
      "text": "Huggingface",
      "label": "ORG"
    },
    {
      "text": "5",
      "label": "CARDINAL"
    },
    {
      "text": "WikiAnn",
      "label": "ORG"
    },
    {
      "text": "zero",
      "label": "CARDINAL"
    },
    {
      "text": "NER",
      "label": "ORG"
    },
    {
      "text": "six",
      "label": "CARDINAL"
    },
    {
      "text": "Japanese",
      "label": "NORP"
    },
    {
      "text": "Russian",
      "label": "NORP"
    },
    {
      "text": "Korean",
      "label": "NORP"
    },
    {
      "text": "ko",
      "label": "PERSON"
    },
    {
      "text": "Spanish",
      "label": "NORP"
    },
    {
      "text": "Arabic",
      "label": "LANGUAGE"
    },
    {
      "text": "English",
      "label": "NORP"
    },
    {
      "text": "2003",
      "label": "DATE"
    },
    {
      "text": "WikiAnn",
      "label": "ORG"
    },
    {
      "text": "BioNLP 2004",
      "label": "DATE"
    },
    {
      "text": "BioCreative V",
      "label": "ORG"
    },
    {
      "text": "6",
      "label": "CARDINAL"
    },
    {
      "text": "F1",
      "label": "GPE"
    },
    {
      "text": "andXLM",
      "label": "NORP"
    },
    {
      "text": "ja ru ko",
      "label": "PERSON"
    },
    {
      "text": "82.8 38.6 65.7 50.4 73.8 44.5",
      "label": "QUANTITY"
    },
    {
      "text": "53.8",
      "label": "CARDINAL"
    },
    {
      "text": "46.9",
      "label": "CARDINAL"
    },
    {
      "text": "71.3 46.3\nru",
      "label": "QUANTITY"
    },
    {
      "text": "51.9",
      "label": "CARDINAL"
    },
    {
      "text": "39.9",
      "label": "PRODUCT"
    },
    {
      "text": "88.7",
      "label": "CARDINAL"
    },
    {
      "text": "51.9",
      "label": "CARDINAL"
    },
    {
      "text": "66.8 51.0",
      "label": "CARDINAL"
    },
    {
      "text": "54.7",
      "label": "CARDINAL"
    },
    {
      "text": "87.5",
      "label": "CARDINAL"
    },
    {
      "text": "63.3 52.3",
      "label": "CARDINAL"
    },
    {
      "text": "65.7 44.0",
      "label": "QUANTITY"
    },
    {
      "text": "66.5",
      "label": "CARDINAL"
    },
    {
      "text": "54.1",
      "label": "CARDINAL"
    },
    {
      "text": "90.9 59.4",
      "label": "PRODUCT"
    },
    {
      "text": "53.1",
      "label": "CARDINAL"
    },
    {
      "text": "49.2",
      "label": "MONEY"
    },
    {
      "text": "49.4 59.7 73.6 88.9",
      "label": "QUANTITY"
    },
    {
      "text": "5",
      "label": "CARDINAL"
    },
    {
      "text": "F1",
      "label": "GPE"
    },
    {
      "text": "WikiAnn",
      "label": "ORG"
    },
    {
      "text": "XLM",
      "label": "ORG"
    },
    {
      "text": "85.8",
      "label": "CARDINAL"
    },
    {
      "text": "81.7 85.6",
      "label": "CARDINAL"
    },
    {
      "text": "87.2",
      "label": "CARDINAL"
    },
    {
      "text": "82.8 87.6",
      "label": "EVENT"
    },
    {
      "text": "49.6",
      "label": "CARDINAL"
    },
    {
      "text": "55.1",
      "label": "CARDINAL"
    },
    {
      "text": "51.3",
      "label": "CARDINAL"
    },
    {
      "text": "79.1",
      "label": "CARDINAL"
    },
    {
      "text": "82.7",
      "label": "CARDINAL"
    },
    {
      "text": "75.2 80.8",
      "label": "PRODUCT"
    },
    {
      "text": "72.9 74.1 71.7 74.0",
      "label": "QUANTITY"
    },
    {
      "text": "79.4",
      "label": "CARDINAL"
    },
    {
      "text": "85.0 78.0 84.2",
      "label": "QUANTITY"
    },
    {
      "text": "72.4",
      "label": "CARDINAL"
    },
    {
      "text": "80.9",
      "label": "CARDINAL"
    },
    {
      "text": "67.8 71.8",
      "label": "CARDINAL"
    },
    {
      "text": "6",
      "label": "CARDINAL"
    },
    {
      "text": "F1",
      "label": "GPE"
    },
    {
      "text": "English",
      "label": "LANGUAGE"
    },
    {
      "text": "XLM",
      "label": "ORG"
    },
    {
      "text": "English",
      "label": "NORP"
    },
    {
      "text": "MIT Restaurant",
      "label": "ORG"
    },
    {
      "text": "MIT Movie",
      "label": "PERSON"
    },
    {
      "text": "8",
      "label": "CARDINAL"
    },
    {
      "text": "Table 9",
      "label": "PRODUCT"
    },
    {
      "text": "F1",
      "label": "GPE"
    },
    {
      "text": "English",
      "label": "NORP"
    },
    {
      "text": "XLM",
      "label": "ORG"
    },
    {
      "text": "91.8",
      "label": "CARDINAL"
    },
    {
      "text": "51.7",
      "label": "CARDINAL"
    },
    {
      "text": "44.7",
      "label": "CARDINAL"
    },
    {
      "text": "31.8 40.3",
      "label": "QUANTITY"
    },
    {
      "text": "60.5",
      "label": "CARDINAL"
    },
    {
      "text": "66.6 60.8",
      "label": "CARDINAL"
    },
    {
      "text": "33.5 45.3",
      "label": "CARDINAL"
    },
    {
      "text": "41.3",
      "label": "CARDINAL"
    },
    {
      "text": "81.3 63.0",
      "label": "PRODUCT"
    },
    {
      "text": "56.3",
      "label": "DATE"
    },
    {
      "text": "20.5 37.5",
      "label": "CARDINAL"
    },
    {
      "text": "30.2",
      "label": "CARDINAL"
    },
    {
      "text": "71.8 45.3",
      "label": "MONEY"
    },
    {
      "text": "92.6",
      "label": "CARDINAL"
    },
    {
      "text": "11.5 35.9",
      "label": "CARDINAL"
    },
    {
      "text": "11.2",
      "label": "CARDINAL"
    },
    {
      "text": "0.0 0.0 0.0 0.0",
      "label": "WORK_OF_ART"
    },
    {
      "text": "87.5",
      "label": "CARDINAL"
    },
    {
      "text": "12.5",
      "label": "CARDINAL"
    },
    {
      "text": "49.0",
      "label": "CARDINAL"
    },
    {
      "text": "82.8 46.9",
      "label": "QUANTITY"
    },
    {
      "text": "89.7",
      "label": "CARDINAL"
    },
    {
      "text": "55.8",
      "label": "CARDINAL"
    },
    {
      "text": "80.0",
      "label": "CARDINAL"
    },
    {
      "text": "74.8 80.0",
      "label": "CARDINAL"
    },
    {
      "text": "F1",
      "label": "GPE"
    },
    {
      "text": "English",
      "label": "NORP"
    },
    {
      "text": "XLM",
      "label": "ORG"
    },
    {
      "text": "89.3 59.9",
      "label": "QUANTITY"
    },
    {
      "text": "50.1",
      "label": "CARDINAL"
    },
    {
      "text": "0.0",
      "label": "CARDINAL"
    },
    {
      "text": "15.1",
      "label": "CARDINAL"
    },
    {
      "text": "88.6 39.1",
      "label": "CARDINAL"
    },
    {
      "text": "57.7",
      "label": "CARDINAL"
    },
    {
      "text": "57.9",
      "label": "CARDINAL"
    },
    {
      "text": "20.5",
      "label": "CARDINAL"
    },
    {
      "text": "23.9",
      "label": "CARDINAL"
    },
    {
      "text": "0.0 35.7",
      "label": "CARDINAL"
    },
    {
      "text": "39.8",
      "label": "CARDINAL"
    },
    {
      "text": "80.3",
      "label": "CARDINAL"
    },
    {
      "text": "61.3",
      "label": "CARDINAL"
    },
    {
      "text": "52.3",
      "label": "CARDINAL"
    },
    {
      "text": "18.8",
      "label": "DATE"
    },
    {
      "text": "30.2",
      "label": "CARDINAL"
    },
    {
      "text": "28.5",
      "label": "CARDINAL"
    },
    {
      "text": "69.7",
      "label": "CARDINAL"
    },
    {
      "text": "51.2",
      "label": "CARDINAL"
    },
    {
      "text": "92.4",
      "label": "CARDINAL"
    },
    {
      "text": "12.0",
      "label": "CARDINAL"
    },
    {
      "text": "28.5",
      "label": "CARDINAL"
    },
    {
      "text": "0.0",
      "label": "CARDINAL"
    },
    {
      "text": "8.7",
      "label": "CARDINAL"
    },
    {
      "text": "0.0 0.0 0.0 0.0 88.9",
      "label": "WORK_OF_ART"
    },
    {
      "text": "46",
      "label": "CARDINAL"
    },
    {
      "text": "61.5",
      "label": "CARDINAL"
    },
    {
      "text": "54.8",
      "label": "CARDINAL"
    },
    {
      "text": "37.9",
      "label": "CARDINAL"
    },
    {
      "text": "4.6",
      "label": "CARDINAL"
    },
    {
      "text": "22.9",
      "label": "CARDINAL"
    },
    {
      "text": "22.3",
      "label": "DATE"
    },
    {
      "text": "5.4",
      "label": "CARDINAL"
    },
    {
      "text": "17.8",
      "label": "CARDINAL"
    },
    {
      "text": "10.9",
      "label": "CARDINAL"
    },
    {
      "text": "0.0 0.0 0.0 0.0 0.0 0.0 0.0",
      "label": "WORK_OF_ART"
    },
    {
      "text": "73.1 9.3",
      "label": "CARDINAL"
    },
    {
      "text": "88.5",
      "label": "CARDINAL"
    },
    {
      "text": "58.0",
      "label": "CARDINAL"
    },
    {
      "text": "79.0",
      "label": "CARDINAL"
    },
    {
      "text": "84.6",
      "label": "PRODUCT"
    },
    {
      "text": "74.1 80.7",
      "label": "CARDINAL"
    },
    {
      "text": "8",
      "label": "CARDINAL"
    },
    {
      "text": "F1",
      "label": "GPE"
    },
    {
      "text": "English",
      "label": "NORP"
    },
    {
      "text": "XLM",
      "label": "ORG"
    },
    {
      "text": "88.3",
      "label": "CARDINAL"
    },
    {
      "text": "49.0",
      "label": "CARDINAL"
    },
    {
      "text": "0.0 11.7 4.2 88.3 37.7",
      "label": "QUANTITY"
    },
    {
      "text": "55.1",
      "label": "CARDINAL"
    },
    {
      "text": "93.7",
      "label": "CARDINAL"
    },
    {
      "text": "60.5 56.8",
      "label": "CARDINAL"
    },
    {
      "text": "20.4",
      "label": "CARDINAL"
    },
    {
      "text": "34.3",
      "label": "CARDINAL"
    },
    {
      "text": "38.1",
      "label": "CARDINAL"
    },
    {
      "text": "57.5 49.1",
      "label": "CARDINAL"
    },
    {
      "text": "0.0",
      "label": "CARDINAL"
    },
    {
      "text": "20.4",
      "label": "DATE"
    },
    {
      "text": "28.8",
      "label": "CARDINAL"
    },
    {
      "text": "26.3",
      "label": "CARDINAL"
    },
    {
      "text": "66.5",
      "label": "CARDINAL"
    },
    {
      "text": "41.4",
      "label": "CARDINAL"
    },
    {
      "text": "0.0",
      "label": "CARDINAL"
    },
    {
      "text": "8.7",
      "label": "CARDINAL"
    },
    {
      "text": "0.0 0.0 0.0 0.0",
      "label": "WORK_OF_ART"
    },
    {
      "text": "41.3 64.4 45.8",
      "label": "MONEY"
    },
    {
      "text": "57.8",
      "label": "CARDINAL"
    },
    {
      "text": "0.0 81.5 22.0",
      "label": "PRODUCT"
    },
    {
      "text": "8.1 19.1",
      "label": "PERCENT"
    },
    {
      "text": "19.6 19.1",
      "label": "CARDINAL"
    },
    {
      "text": "13.5",
      "label": "CARDINAL"
    },
    {
      "text": "18.1",
      "label": "CARDINAL"
    },
    {
      "text": "14.5",
      "label": "CARDINAL"
    },
    {
      "text": "0.0 0.0 0.0 0.0 0.0 0.0 0.0",
      "label": "WORK_OF_ART"
    },
    {
      "text": "86.1",
      "label": "CARDINAL"
    },
    {
      "text": "89.5 49.9",
      "label": "QUANTITY"
    },
    {
      "text": "86.2",
      "label": "CARDINAL"
    },
    {
      "text": "78.8 75.4 82.4 72.2 77.5",
      "label": "QUANTITY"
    },
    {
      "text": "9",
      "label": "CARDINAL"
    },
    {
      "text": "F1",
      "label": "GPE"
    },
    {
      "text": "English",
      "label": "NORP"
    },
    {
      "text": "XLM",
      "label": "ORG"
    }
  ],
  "summary": "T-NER is a Python library designed for Transformer-based Named Entity Recognition (NER), enabling efficient fine-tuning, cross-domain, and cross-lingual analysis of language models. It provides tools for model training, evaluation, and a user-friendly web app for interactive predictions, while releasing pre-trained checkpoints to facilitate future research.",
  "embedding": [
    0.03452850505709648,
    0.00890926830470562,
    0.021468646824359894,
    0.0446460135281086,
    0.02028696797788143,
    0.06889896094799042,
    0.007858972065150738,
    -0.005181959830224514,
    0.020764697343111038,
    -0.05354207009077072,
    -0.048269446939229965,
    -0.029834402725100517,
    0.0021777478978037834,
    0.033034902065992355,
    0.03156823292374611,
    -0.035115085542201996,
    0.012902148999273777,
    -0.018875008448958397,
    0.004236326552927494,
    0.03926632180809975,
    -0.021275047212839127,
    0.020516566932201385,
    -0.0054672472178936005,
    0.03431499004364014,
    0.010963237844407558,
    0.02237207628786564,
    -0.012499019503593445,
    0.02352861315011978,
    0.022363372147083282,
    -0.048603881150484085,
    0.03269970044493675,
    0.0452982597053051,
    -0.0042581576853990555,
    0.03844446688890457,
    2.1545979507209267e-06,
    -0.05058332532644272,
    -0.05325278267264366,
    -0.011587316170334816,
    -0.0015381104312837124,
    -0.028025353327393532,
    0.04499484598636627,
    -0.05591244623064995,
    -0.019397011026740074,
    0.023958316072821617,
    -0.037143390625715256,
    -0.0675375908613205,
    0.04551670327782631,
    0.06951609253883362,
    0.03937982767820358,
    0.09528841823339462,
    -0.004429244436323643,
    -0.019635213539004326,
    0.025958772748708725,
    -0.0118568055331707,
    -0.019998837262392044,
    -0.04733184725046158,
    0.04357531666755676,
    -0.021820183843374252,
    -0.04413839802145958,
    -0.01572425663471222,
    0.0042152623645961285,
    0.02861313335597515,
    -0.0247916541993618,
    0.02112734317779541,
    0.005837967153638601,
    0.040509097278118134,
    -0.03865951672196388,
    -0.02294616587460041,
    -0.026454787701368332,
    0.06536735594272614,
    -0.03493534401059151,
    0.0022151859011501074,
    0.033302903175354004,
    -0.007412475999444723,
    -0.032934218645095825,
    -0.0021674041636288166,
    -0.008622625842690468,
    0.006756916176527739,
    -0.02088002674281597,
    -0.0013493997976183891,
    0.002938065445050597,
    -0.01118468213826418,
    0.02024224027991295,
    -0.0024822924751788378,
    -0.025333493947982788,
    0.01973818987607956,
    0.01682279445230961,
    -0.026115352287888527,
    0.016163431107997894,
    0.045244019478559494,
    0.005180743057280779,
    -0.06860905885696411,
    0.040084533393383026,
    0.04230800271034241,
    0.02070382609963417,
    0.014397460035979748,
    -0.032132986932992935,
    -0.007804094348102808,
    0.0032509840093553066,
    -0.045517273247241974,
    0.01587645336985588,
    0.00972581934183836,
    -0.004796674940735102,
    0.02703315019607544,
    -0.056594815105199814,
    0.03879924118518829,
    -0.011788707226514816,
    0.01902259886264801,
    0.01285001914948225,
    -0.01683204621076584,
    -0.06308723241090775,
    -0.009675082750618458,
    -0.032384272664785385,
    0.02370247058570385,
    -0.010810760781168938,
    0.009401002898812294,
    -0.05434050038456917,
    0.008997004479169846,
    0.011458663269877434,
    0.011298619210720062,
    0.04251384362578392,
    -0.025629427284002304,
    0.008859016001224518,
    -0.001113327918574214,
    -0.04310626536607742,
    0.05045844614505768,
    0.003710131160914898,
    -0.010212462395429611,
    -0.04198325797915459,
    -0.062433160841464996,
    -0.011127261444926262,
    -0.03012855537235737,
    0.03380660340189934,
    -0.059563446789979935,
    0.06284467875957489,
    0.07412008941173553,
    0.033554743975400925,
    -0.10782626271247864,
    -0.05245891213417053,
    0.019508082419633865,
    0.018764736130833626,
    -0.061882421374320984,
    0.011377514339983463,
    -0.0461784191429615,
    0.029396776109933853,
    0.03827756270766258,
    0.028615662828087807,
    -0.07316988706588745,
    0.012367945164442062,
    -0.010308431461453438,
    -0.049797046929597855,
    0.09398384392261505,
    -0.008723488077521324,
    0.004552298225462437,
    0.022479306906461716,
    0.0009289711015298963,
    0.040743496268987656,
    0.04798493534326553,
    0.028160398826003075,
    0.015255077742040157,
    0.05062799155712128,
    -0.027476277202367783,
    0.01715599186718464,
    0.04206632822751999,
    0.006658781319856644,
    -0.021112235262989998,
    0.02573353424668312,
    0.0012824423611164093,
    0.011071176268160343,
    -0.018216175958514214,
    0.019853608682751656,
    0.022193972021341324,
    0.012708812020719051,
    -0.006239031907171011,
    0.020571531727910042,
    0.024033013731241226,
    0.03916177153587341,
    -0.012085678055882454,
    0.046980153769254684,
    -0.006986895576119423,
    -0.004226973280310631,
    -0.013817355036735535,
    -0.049819838255643845,
    0.010539240203797817,
    -0.0419628843665123,
    0.02849234826862812,
    -0.022425366565585136,
    0.09549147635698318,
    -0.028115320950746536,
    -0.004716337192803621,
    0.0018697207560762763,
    -0.021944966167211533,
    0.015244798734784126,
    0.003952098079025745,
    0.07301448285579681,
    0.01714998297393322,
    -0.08283825218677521,
    0.08588828146457672,
    0.03882521763443947,
    -0.040523797273635864,
    0.02045232430100441,
    -0.022292140871286392,
    -0.026213817298412323,
    0.040409211069345474,
    0.015423932112753391,
    -0.03869246691465378,
    -0.056382857263088226,
    -0.0458117239177227,
    -0.027780678123235703,
    0.04581146314740181,
    0.018800197169184685,
    -0.002349181566387415,
    0.041828591376543045,
    -0.04188285022974014,
    -0.01841527782380581,
    -0.008227117359638214,
    0.017845312133431435,
    0.04257284849882126,
    0.04720168560743332,
    0.057020023465156555,
    0.054893285036087036,
    -0.008987647481262684,
    -0.029818309471011162,
    0.06353727728128433,
    -0.09521643072366714,
    -0.026252202689647675,
    -0.0010618094820529222,
    0.03232717886567116,
    -0.009455217979848385,
    0.03940911963582039,
    -0.02168855629861355,
    -0.03479135408997536,
    0.025324061512947083,
    -0.009399131871759892,
    0.00013973223394714296,
    -0.026510141789913177,
    0.01734321564435959,
    -0.03332921490073204,
    0.031027870252728462,
    -0.028625883162021637,
    -0.020037002861499786,
    0.03020407073199749,
    -0.04047263041138649,
    -0.029660232365131378,
    -0.0210596714168787,
    0.045269906520843506,
    0.028779830783605576,
    -0.023665715008974075,
    0.0670555830001831,
    -0.0008226637728512287,
    0.03772003576159477,
    -0.0014027432771399617,
    0.03572399541735649,
    0.025549570098519325,
    0.023621205240488052,
    0.00827045738697052,
    -0.01896803453564644,
    -0.0027394734788686037,
    -0.009501266293227673,
    -0.06593230366706848,
    0.011189289391040802,
    -0.022055473178625107,
    -0.014583326876163483,
    0.012390155345201492,
    0.018148021772503853,
    -0.05000166594982147,
    -0.03284311667084694,
    -0.09153005480766296,
    0.012530573643743992,
    -0.026515372097492218,
    0.04899764060974121,
    0.007901880890130997,
    0.04213639721274376,
    -0.041580699384212494,
    -0.026000522077083588,
    0.018896346911787987,
    -0.021793577820062637,
    -0.00566853815689683,
    0.0029742035549134016,
    0.038153547793626785,
    0.0012518932344391942,
    -0.034536492079496384,
    -0.010016283951699734,
    0.008319942280650139,
    -0.03351549059152603,
    0.04605524614453316,
    0.022715089842677116,
    -0.043558306992053986,
    -0.07157769799232483,
    0.06725252419710159,
    -0.035064488649368286,
    0.011602159589529037,
    -0.0016933372244238853,
    0.0009142753551714122,
    -0.02326049841940403,
    0.03836488723754883,
    0.03207077458500862,
    0.044308729469776154,
    0.0018699289066717029,
    0.0009660811629146338,
    0.0021052013617008924,
    -0.021049467846751213,
    -0.033467236906290054,
    0.030139923095703125,
    -0.02960669994354248,
    0.002121081342920661,
    -0.020646950230002403,
    -0.041324567049741745,
    0.04295700043439865,
    0.10372959822416306,
    -0.047621674835681915,
    0.009009682573378086,
    -0.04707969352602959,
    0.009784195572137833,
    -0.006838992703706026,
    -0.013295161537826061,
    -0.009981686249375343,
    0.028636198490858078,
    -0.0016696329694241285,
    0.006587099749594927,
    -0.004766711965203285,
    -0.031685806810855865,
    0.06047913059592247,
    -0.0686323493719101,
    -0.03253593668341637,
    -0.020964259281754494,
    -0.02036125957965851,
    -0.06913077086210251,
    0.07638740539550781,
    0.016013721004128456,
    -0.006048537325114012,
    0.07073841243982315,
    -0.10045956820249557,
    -0.009569238871335983,
    0.04444080591201782,
    -0.00926162302494049,
    -0.03010270930826664,
    0.04383067786693573,
    0.006427603308111429,
    0.0020474183838814497,
    -0.022588472813367844,
    -0.008218802511692047,
    -0.022905947640538216,
    -0.014658080413937569,
    -0.0645277351140976,
    -0.012285823933780193,
    -0.014585246331989765,
    -0.014563717879354954,
    -0.019481424242258072,
    0.05495177209377289,
    0.0074621387757360935,
    0.03657178953289986,
    -0.0037390380166471004,
    -0.015927335247397423,
    -0.005394370760768652,
    0.017726201564073563,
    0.016957545652985573,
    0.005564318969845772,
    0.008325155824422836,
    -0.006128314882516861,
    -0.021189093589782715,
    0.006623825524002314,
    -0.02155870385468006,
    -0.020228492096066475,
    0.0005264189094305038,
    0.00293647195212543,
    0.02090601995587349,
    -0.07233574241399765,
    -0.009791218675673008,
    -0.030192656442523003,
    0.026181403547525406,
    -0.02790450118482113,
    0.00788472406566143,
    0.1237352266907692,
    0.0025749756023287773,
    -0.014885526150465012,
    -0.03998425975441933,
    0.024878814816474915,
    0.01116577722132206,
    0.04148997738957405,
    0.023066148161888123,
    -0.06344863027334213,
    -0.037164099514484406,
    0.01285558845847845,
    -0.008411126211285591,
    0.01753973215818405,
    -0.0577780157327652,
    -0.008569511584937572,
    -0.09597769379615784,
    -0.0037047204095870256,
    -0.031204795464873314,
    -0.057275038212537766,
    0.009592150337994099,
    -0.0744951069355011,
    -0.013800605200231075,
    -0.05862373486161232,
    0.0027411403134465218,
    -0.036975547671318054,
    -0.05614479258656502,
    -0.000551008153706789,
    0.008683915250003338,
    0.015697628259658813,
    -0.05433792248368263,
    0.02030074968934059,
    -0.07890819013118744,
    0.017448609694838524,
    0.03170662000775337,
    0.054998431354761124,
    -0.029871249571442604,
    -0.01628611423075199,
    0.016384337097406387,
    -0.0138310007750988,
    0.0065023815259337425,
    -0.02520931139588356,
    0.0675886869430542,
    -0.0432908833026886,
    -0.029298793524503708,
    0.002532986691221595,
    -0.038957465440034866,
    -0.05239754542708397,
    -0.0019367054337635636,
    0.01587938331067562,
    0.03237244859337807,
    0.024262815713882446,
    0.0087540652602911,
    0.01093348953872919,
    -0.011542268097400665,
    0.0025537938345223665,
    0.07770601660013199,
    -0.0011535132071003318,
    -0.01729131117463112,
    -0.03416398540139198,
    0.0055730645544826984,
    -0.005656280089169741,
    -0.0032249523792415857,
    -0.07940894365310669,
    0.005112390965223312,
    -0.04462979733943939,
    -0.04618073254823685,
    -0.028006359934806824,
    -0.03393520414829254,
    0.059602610766887665,
    0.03804677724838257,
    0.015991894528269768,
    0.0004746887425426394,
    0.014129933901131153,
    0.030609572306275368,
    -0.07767233997583389,
    0.04921175539493561,
    -0.02728089690208435,
    0.04121585190296173,
    -0.0821138396859169,
    -0.005137941800057888,
    0.04253046587109566,
    -0.0038335842546075583,
    -0.03838187828660011,
    -0.0059507801197469234,
    -0.06865604221820831,
    -0.049492742866277695,
    -0.005688824225217104,
    0.024070024490356445,
    0.019651196897029877,
    0.031242623925209045,
    -0.003074366832152009,
    -0.006708514876663685,
    0.03867323324084282,
    0.056769587099552155,
    -0.04573478922247887,
    -0.008942670188844204,
    0.015433433465659618,
    -0.008920440450310707,
    -0.019367419183254242,
    0.005779496394097805,
    -0.03005656786262989,
    0.013081305660307407,
    0.029931068420410156,
    0.03447265550494194,
    0.007111371494829655,
    -0.04854132607579231,
    -0.016687514260411263,
    0.03468892350792885,
    0.074691541492939,
    -0.0031856202986091375,
    -0.04356061667203903,
    -0.06391918659210205,
    0.015865933150053024,
    0.018800968304276466,
    0.01936119608581066,
    -0.016876164823770523,
    -0.033273421227931976,
    0.039970170706510544,
    -0.004388940520584583,
    -0.020464079454541206,
    0.06825819611549377,
    -0.031256139278411865,
    0.026706991717219353,
    -0.05888631194829941,
    0.04343666881322861,
    0.012133562006056309,
    0.0651644915342331,
    0.030403539538383484,
    -0.0253278985619545,
    0.020389674231410027,
    0.018083129078149796,
    0.07081273943185806,
    0.046322353184223175,
    -0.031014492735266685,
    0.00016939593479037285,
    -0.030323337763547897,
    0.02690812759101391,
    -0.03464033082127571,
    0.044686321169137955,
    -0.03807452321052551,
    -0.003937097731977701,
    -0.0496380440890789,
    0.014642832800745964,
    0.05398702621459961,
    -0.02228155918419361,
    0.07692364603281021,
    0.00023626405163668096,
    0.013081107288599014,
    0.0022619536612182856,
    0.014080331660807133,
    -0.00686293002218008,
    -0.007389857899397612,
    0.023729147389531136,
    -0.0037874181289225817,
    -0.04554205760359764,
    -0.004138587974011898,
    0.06675884872674942,
    0.01006137765944004,
    0.03433622047305107,
    0.04955066740512848,
    -0.024941816926002502,
    -0.03794028237462044,
    -0.010038094595074654,
    0.03838816657662392,
    -0.03956155478954315,
    -0.04217676818370819,
    -0.0005860550445504487,
    -0.028357001021504402,
    -0.07049141824245453,
    0.03308769315481186,
    -0.05159839987754822,
    -0.006842462345957756,
    0.010751559399068356,
    0.002501318696886301,
    0.04521042853593826,
    0.017801456153392792,
    0.004255618900060654,
    -0.034947801381349564,
    0.0028927545063197613,
    0.006404026411473751,
    -0.02885422110557556,
    -0.009595975279808044,
    -6.419274732820692e-33,
    -0.04814949259161949,
    -0.020612087100744247,
    0.024208534508943558,
    0.002886731643229723,
    -0.010152284055948257,
    0.04326578602194786,
    0.0009312666370533407,
    0.024667320773005486,
    -0.00031441825558431447,
    -0.05037549138069153,
    -0.02402973547577858,
    0.002021895721554756,
    0.042190071195364,
    -0.00795047078281641,
    -0.022302312776446342,
    -0.02932751551270485,
    0.04504869505763054,
    0.030457880347967148,
    -0.032208725810050964,
    0.006930061150342226,
    0.014593222178518772,
    0.08755245804786682,
    0.1100945696234703,
    -0.081410251557827,
    0.025637885555624962,
    0.01764286868274212,
    0.004366075154393911,
    -0.016898630186915398,
    0.07975142449140549,
    0.06204500421881676,
    -0.03597284108400345,
    -0.016060462221503258,
    0.018559059128165245,
    -0.0902099683880806,
    0.008699784986674786,
    0.0074768830090761185,
    -0.1370985358953476,
    0.005365455988794565,
    -0.02450472116470337,
    0.05349632725119591,
    0.017237821593880653,
    -0.014750427566468716,
    0.03927803412079811,
    -0.008471137844026089,
    0.0042130849324166775,
    -0.007642663083970547,
    0.042423997074365616,
    -0.011688106693327427,
    0.0037268423475325108,
    -0.03617844730615616,
    -0.07949262112379074,
    0.039652276784181595,
    0.011072237975895405,
    0.016285540536046028,
    0.050504203885793686,
    0.010288320481777191,
    0.021890167146921158,
    0.03196316584944725,
    -0.07055234909057617,
    -0.007759780157357454,
    0.03274313360452652,
    -0.011798961088061333,
    0.05399573966860771,
    0.027402818202972412,
    -0.009323403239250183,
    0.036909546703100204,
    0.021870136260986328,
    0.008826998062431812,
    -0.024992605671286583,
    -0.005478899460285902,
    0.03145666420459747,
    0.034752052277326584,
    -0.028654402121901512,
    0.029890015721321106,
    0.019021082669496536,
    -0.044710732996463776,
    -0.059516146779060364,
    0.06465378403663635,
    -0.008683555759489536,
    0.02233045920729637,
    0.004102491308003664,
    -0.0303494893014431,
    -0.026578858494758606,
    0.006675119511783123,
    -0.01985761895775795,
    -0.016397997736930847,
    -0.0516199991106987,
    -0.03631417453289032,
    0.011810308322310448,
    0.031776510179042816,
    -0.06885070353746414,
    0.033743251115083694,
    0.01266458723694086,
    -0.0392281673848629,
    -0.06525168567895889,
    0.024192919954657555,
    0.02544444613158703,
    0.010528781451284885,
    -0.017724445089697838,
    0.010340020060539246,
    -0.040106672793626785,
    -0.05750444903969765,
    0.01597699336707592,
    -0.003951051272451878,
    0.04202721267938614,
    -0.027197210118174553,
    0.031797148287296295,
    -0.0004033659351989627,
    -0.08096455782651901,
    0.0021455474197864532,
    -0.005554338917136192,
    0.024001576006412506,
    -0.015138962306082249,
    0.08557570725679398,
    0.004870675969868898,
    -0.00636494904756546,
    -0.029142066836357117,
    0.015316818840801716,
    0.05377936363220215,
    -0.03646684065461159,
    -0.04207382723689079,
    0.02567712403833866,
    0.040865108370780945,
    0.0518483929336071,
    -0.03277883678674698,
    -0.021081995218992233,
    -0.021048514172434807,
    -0.013289925642311573,
    0.0432443842291832,
    -0.05999123305082321,
    -0.01641383208334446,
    -0.01795257441699505,
    2.789324753393885e-07,
    0.027855442836880684,
    0.037336524575948715,
    0.017843399196863174,
    0.006242923438549042,
    -0.03084684908390045,
    0.025925325229763985,
    -0.017479218542575836,
    0.04034749045968056,
    0.023023046553134918,
    0.01708756573498249,
    -0.016111169010400772,
    -0.025144807994365692,
    0.020791660994291306,
    0.026341155171394348,
    -0.08619459718465805,
    -0.022049961611628532,
    -0.01839332841336727,
    0.008769446052610874,
    -0.05523189157247543,
    0.04054545611143112,
    0.00010345042392145842,
    0.09280198812484741,
    -0.002171953208744526,
    -0.018306812271475792,
    -0.027706939727067947,
    -0.03760027140378952,
    0.04989064112305641,
    -0.033504582941532135,
    0.029488418251276016,
    0.036535993218421936,
    0.002622817875817418,
    0.0578225702047348,
    -0.016342544928193092,
    0.015278329141438007,
    -0.025855863466858864,
    0.037893347442150116,
    0.01943078078329563,
    0.06519704312086105,
    0.0030957984272390604,
    0.02243947982788086,
    0.0035077640786767006,
    -0.023802001029253006,
    0.019566727802157402,
    -0.05696835368871689,
    0.08173839002847672,
    -0.04234594479203224,
    -0.019537661224603653,
    -0.0041237156838178635,
    -0.02773023396730423,
    -0.006599102169275284,
    0.028907787054777145,
    0.006718986202031374,
    -0.001555022899992764,
    0.058746252208948135,
    0.04566630348563194,
    -0.021642033010721207,
    -0.024169953539967537,
    -0.07460235059261322,
    0.01049011666327715,
    0.008225656114518642,
    0.023386523127555847,
    -0.002975801005959511,
    -0.02014283649623394,
    -0.027489615604281425,
    0.028814567252993584,
    -0.03848065435886383,
    0.028052376583218575,
    2.8625137927770284e-34,
    -0.012810052372515202,
    0.011829116381704807,
    -0.025380544364452362,
    0.04310755059123039,
    0.04299802705645561,
    -0.01802840642631054,
    -0.011400026269257069,
    -0.003970229998230934,
    -0.037237536162137985,
    -0.06242026388645172,
    0.02465592883527279
  ]
}