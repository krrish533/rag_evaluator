{
  "filename": "TXT-SUM.txt",
  "length": 103820,
  "context": "Open Access\n\u00a9 The Author(s) 2023. Open Access  This article is licensed under a Creative Commons Attribution 4.0 International License, which permits \nuse, sharing, adaptation, distribution and reproduction in any medium or format, as long as you give appropriate credit to the original \nauthor(s) and the source, provide a link to the Creative Commons licence, and indicate if changes were made. The images or other third \nparty material in this article are included in the article\u2019s Creative Commons licence, unless indicated otherwise in a credit line to the mate -\nrial. If material is not included in the article\u2019s Creative Commons licence and your intended use is not permitted by statutory regulation or \nexceeds the permitted use, you will need to obtain permission directly from the copyright holder. To view a copy of this licence, visit http://  \ncreat iveco mmons. org/ licen ses/ by/4. 0/.RESEARCHAlami\u00a0Merrouni\u00a0 et\u00a0al. Journal of Big Data          (2023) 10:163  \nhttps://doi.org/10.1186/s40537-023-00836-yJournal of Big Data\nEXABSUM: a\u00a0new text summarization \napproach for\u00a0generating extractive \nand\u00a0abstractive summaries\nZakariae Alami Merrouni1*  , Bouchra Frikh1 and Brahim Ouhbi2 \nAbstract \nDue to the exponential growth of online information, the ability to efficiently extract \nthe most informative content and target specific information without extensive \nreading is becoming increasingly valuable to readers. In this paper, we present \u2019EXAB-\nSUM,\u2019 a novel approach to Automatic Text Summarization (ATS), capable of generat -\ning the two primary types of summaries: extractive and abstractive. We propose two \ndistinct approaches: (1) an extractive technique  (EXABSUMExtractive ), which integrates \nstatistical and semantic scoring methods to select and extract relevant, non-repetitive \nsentences from a text unit, and (2) an abstractive technique  (EXABSUMAbstractive ), which \nemploys a word graph approach (including compression and fusion stages) and re-\nranking based on keyphrases to generate abstractive summaries using the source \ndocument as an input. In the evaluation conducted on multi-domain benchmarks, \nEXABSUM outperformed extractive summarization methods and demonstrated com-\npetitiveness against abstractive baselines.\nKeywords: Extractive and abstractive summarization, Graph-based approach, \nKeyphrase-based approach\nIntroduction\nThe accessibility of the ever-expanding volume of online information by humans would \nbe impeded without the presence of summaries. Given the extensive nature of textual \ncontent, pertinent information can inadvertently evade readers\u2019 attention. Consequently, \nthe condensation of critical information into summaries holds significant value. Since \nthe 1950s, researchers have diligently endeavored to enhance text summarization algo -\nrithms, with the aim of achieving a level of summarization comparable to human capa -\nbilities. Text summarization remains a formidable yet promising challenge within the \ndomain of NLP .\nIn text summarization, two pivotal inquiries arise: (i) the process of identifying per -\ntinent content within a document, and (ii) the art of succinctly conveying the selected \nmaterial while minimizing redundancy [1 \u20133]. The landscape of ATS approaches can \nbe categorized into three primary categories: extractive, abstractive, and presently, *Correspondence:   \nzakariae.alamimerrouni@usmba.ac.ma\n1 LIASSE Lab, National School \nof Applied Sciences (ENSA), Sidi \nMohamed Ben Abdellah University, \nB.P . 72, Route d\u2019imouzer, Fez, \nMorocco\n2 Mathematical Modeling \nand Computer Laboratory (LM2I), \nNational Higher School of Arts \nand Crafts (ENSAM), Moulay Ismail \nUniversity (UMI), Marjane II, B.P . 4024, \nMeknes, Morocco\nPage 2 of 34 Alami\u00a0Merrouni\u00a0et\u00a0al. Journal of Big Data          (2023) 10:163 \nemphasis is gravitating toward hybrid summarization\u2014a fusion of extractive and \nabstractive techniques [4 \u20136].\nDespite the notable advancements in information technology, the domain of sum -\nmarization remains an area necessitating substantial advancements. Within the realm \nof text summarization, several critical challenges persist, which can be encapsulated \nas follows:\n\u2022 Initially, the challenge of Text Relevancy Detection emerges. Conventional meth -\nods assume that a word\u2019s significance within a text correlates with its frequency of \noccurrence, with each word representing a distinct concept. However, quantify -\ning concept occurrences poses complexity due to the presence of synonymy and \ncoreferential expressions that contribute to text cohesion. The information flow \nwithin a document exhibits fluctuations, indicating that specific segments hold \ngreater importance than others. Consequently, the task of effectively discerning \nthe most pertinent details and statically and semantically distinguishing relevant \nterms from source documents proves to be a pervasive challenge (e.g., selection \npredicated on pertinent keywords or keyphrases).\n\u2022 Subsequently, the lack issue of coherence and redundancy. Extractive summariza -\ntion faces hurdles of cohesion and coherence in the summaries produced, stem -\nming from redundancy (phrases with comparable meaning), disjointed sentence \nconnections, and unresolved co-reference relationships.\n\u2022 The third challenge pertains to abstractive and hybrid summarization. The \ndemand for abstractive or hybrid Automatic Text Summarization (ATS) tech -\nniques becomes apparent. This genre of technique remains an evolving and intri -\ncate domain. Crafting an efficacious abstractive summary has proven challenging \nthus far. It is imperative to cultivate overarching guidelines and viable strategies to \ntransition from extractive to abstract summaries, thereby harnessing the advan -\ntages offered by both ATS approaches.\nIn this paper, we introduce EXABSUM, an ATS SYSTEM equipped to generate two \ndistinct summary categories. Firstly, extracts  (EXABSUMExtractive ) are shaped through \na strictly extractive methodology, while abstracts  (EXABSUMAbstractive ) are crafted \nvia an abstractive approach. The outlined approach effectively addresses limitations \nintrinsic to both extractive and abstractive summarization techniques. Consequently, \nour contributions to state-of-the-art systems encompass the following:\n\u2022 Diverging from certain extant extractive systems reliant solely on statistical scor -\ning mechanisms for verbatim phrase extraction from the source document, our \napproach introduces a distinctive unsupervised extraction strategy aimed at tack -\nling the challenge of Text Relevancy Detection. This innovative method combines \nthe strengths of both statistical and semantic scoring techniques to discern crucial \ninformation, while concurrently proposing a novel one.\n\u2022 Unlike certain extant extractive systems, our approach introduces the element \nof Semantic redundancy mitigation\u2014a pivotal concern within ATS. To circum -\nvent the inclusion of semantically and contextually redundant information in final \nPage 3 of 34\n Alami\u00a0Merrouni\u00a0et\u00a0al. Journal of Big Data          (2023) 10:163 \n \nsummaries, we advocate the adoption of textual entailment. This approach serves \nto mitigate the readability challenges inherent in existing methods, thereby allevi -\nating a drawback commonly associated with the produced text.\n\u2022 We confront the challenge of generating abstractive summaries by presenting a \ngraph-based summarization model designed to yield resilient abstractive summaries. \nThis model builds upon and extends a pioneering multi-sentence compression and \nfusion approach, bolstered by a re-ranking method based on key-extraction. Nota -\nbly, this approach functions independently of any need for training data or acquiring \nknowledge of the document\u2019s structure or domain.\nThe paper\u2019s structure is delineated as follows. The subsequent section introduces per -\ntinent related works and outlines ATS systems developed to cater to distinct applica -\ntions. Sect.\u00a0\"EXABSUM ATS Approach \" delves into the description of our proposed ATS \nsystem, EXABSUM. Within this section, we expound upon its primary stages, recom -\nmended architecture, and the two methodologies employed for the creation of extractive \nand abstractive summaries. In Sect.\u00a0 \"Experimental setup \", we detail the experimental \nframework. Here, we provide insight into the datasets utilized, elucidate the conducted \nexperiments aimed at parameter tuning, and subsequently discuss the evaluation pro -\ncess. The achieved results, compared to the other state-of-the-art systems, are presented \nin the final part of the section. Finally, Sect. \u201cSummary and conclusions\u201d discusses the \nconclusion and future work.\nRelated works\nThe initial efforts in the domain of automatic summarization focused on extractive \napproaches, which aim to select pertinent existing words, phrases, or sentences directly \nfrom a source text to capture its most pivotal content. Extractive Automatic Text Sum -\nmarization (ATS) approaches are typically carried out in three steps [5]: (1) Construct \nan intermediate representation of the original text (usually involving preprocessing and \nsegmenting the text into paragraphs, phrases, and tokens); (2) Sentence scoring (the \nscore should measure the importance of a sentence to the comprehensive understand -\ning of the text) by attributing scores to the most relevant words, followed by an assess -\nment of sentence characteristics such as position within the document, sentence length, \ntitle alignment, and other factors. Previous research of extractive summarization has \npredominantly focused on (1) sentence-clustering-based, (2) statistical, (3) graph-based, \nand (4) optimization-based techniques. In the context of the first approach, the docu -\nment comprises n sentences, each sharing an identical set of terms. Consequently, the \nset of terms in the document corresponds to the set of terms in each phrase. The dis -\ntance between corresponding sentences can be employed to illustrate the similarity in \nlanguage patterns [7\u201310].\nSentence-clustering algorithms organize related textual units (paragraphs, sentences) \ninto multiple clusters to uncover common themes of information, subsequently select -\ning text units from these clusters in the final summary. One of the noteworthy extrac -\ntive summarization techniques is the centroid-based method [11]. An instance of an \nAutomatic Text Summarization (ATS) system employing sentence-clustering algorithms \nis the MEAD system [12], a bilingual (English and Chinese) summarizer system that \nPage 4 of 34 Alami\u00a0Merrouni\u00a0et\u00a0al. Journal of Big Data          (2023) 10:163 \nprovides extractive single and multi-document generic or query-focused summaries. \nThe MEAD system computes centroid topic characterizations for individual documents \nor provided clusters, leveraging tf\u2013idf-type data. It evaluates candidate summary sen -\ntences by weighing sentence scores against the centroid, text position value, and tf\u2013idf \ntitle/lead overlap. A summary length threshold governs sentence selection, while cosine \nsimilarity analysis against prior phrases curbs redundant new phrases.\nIncorporating a summarization technique within a comprehensive retrieval and \ngrouping process, the QCS system [13] generates a single extractive summary for each \ncluster. This is achieved through a method that combines sentence \"trimming\" and a hid -\nden Markov model, followed by pivoting QR decomposition. The model identifies sen -\ntences with the highest likelihood for inclusion in the summary.\nStatistical approaches [14] rely on elementary metrics like TF-IDF scores and word \nco-occurrence [1, 15, 16]. Ko and Seo [17] introduced a proficient methodology for \ntext summarization that harnesses contextual insights and statistical methodologies to \nextract pertinent sentences.\nGraph-based approaches [7] depict text as a network of phrases and devise summa -\nries through graph-based scoring mechanisms. An innovative and versatile summarizer, \nGRAPHSUM, rooted in a graph model, was proposed by Baralis et\u00a0al. [18]. It captures \ninterrelationships among various elements by uncovering association rules. Parveen and \nStrube [19] presented an extractive graph-based unsupervised technique for summariz -\ning individual documents that accounts for three critical summary attributes: signifi -\ncance, non-redundancy, and local coherence. Optimization-based methods [20] employ \noptimization techniques such as integer linear programming [21], constraint optimiza -\ntion [22], and sparse optimization [23].\nOther ATS systems, like SummGraph [24], employ graph-based algorithms and knowl -\nedge databases to discern the substance of pertinent texts. Notably, this specific system \nhas demonstrated efficacy across domains encompassing news, biomedical research, and \ntourism. Summaries have also embraced the incorporation of Natural Language Genera -\ntion (NLG) to introduce fresh terminologies and linguistic structures. Belz [25] presents \na text summarization technique grounded in \u2019NLG\u2019 to automatically generate weather \nforecast reports. Mohammad et\u00a0al. [26] elucidated a system for the automated creation \nof technical surveys rooted in citations. More recently, Erera et\u00a0al. [27] introduced the \nIBM Science Summarizer, an innovative methodology catering to Computer Science \npapers. This approach crafts summaries contingent upon user-provided information \nrequisites, be it a natural language inquiry, scientific tasks (e.g., \"Machine Translation\"), \ndatasets, or scholarly venues.\nAlthough extractive methods can adeptly identify significant information, they may \nlack the fluidity and precision inherent in human-generated summaries. Consequently, \nabstractive ATS approaches strive to enhance sentence coherence by diminishing \nredundancies, elucidating sentence context, and potentially introducing supplemen -\ntary phrases into the summary. For the synthesis of the final summary, abstractive tech -\nniques generally leverage sentence compression, fusion, or modification mechanisms. \nBarzilay and McKeown [28] pioneered a system wherein dependency trees represent \ninput phrases, and select words are aligned to integrate these trees into a lattice struc -\nture. The lattice is subsequently linearized via tree traversal to generate fusion sentences. \nPage 5 of 34\n Alami\u00a0Merrouni\u00a0et\u00a0al. Journal of Big Data          (2023) 10:163 \n \nFilippova and Strube [29] introduced an innovative approach to sentence fusion, fram -\ning the fusion task as an optimization problem. This unsupervised technique draws on \ndependency structure alignment, semantic and syntactically informed phrase aggrega -\ntion, and pruning strategies. Later, Filippova delved into the challenge of condensing a \ncollection of interconnected sentences into a succinct single sentence, termed as multi-\nsentence compression, and presented a foundational technique based on shortest paths \nin word graphs [30]. Her method yielded grammatically sound and informative summa -\nries, subsequently finding application in diverse contemporary summary systems [4, 31]. \nBoudin [32] extended Filippova\u2019s approach by addressing Multi-Sentence Compression \n(MSC) as the task of generating a concise single-sentence summary from a cluster of \ninterconnected sentences. He introduced an N-best reranking algorithm based on the \nfrequency and relevance of keyphrases within the documents, resulting in more inform -\native summaries. Banerjee et\u00a0 al. [33] devised multi-document abstractive summaries \nusing word graphs and Integer Linear Programming (ILP). They clustered akin sentences \namong pivotal documents and employed word-graphs to identify shortest paths. The ILP \nmodel facilitated the identification of sentences with maximal information and reada -\nbility, effectively reducing redundancy. Nayeem et\u00a0al. [34] formulated an unsupervised \nabstractive summarization system. Their innovation was a paraphrastic sentence fusion \nmodel amalgamating sentence fusion with paraphrasing at the sentence level through \na skip-gram word embedding model. This model augmented information coverage and \nheightened the abstract nature of the generated phrases. Shang et\u00a0al. [35] introduced a \nfully unsupervised graph-based architecture tailored for abstractive summarization of \nmeeting speeches. Their unified framework amalgamated the strengths of six prevailing \napproaches across three distinct tasks (keyword extraction, multi-sentence compression, \nand summarization), effectively addressing their respective limitations. Their abstractive \nsummarization approach underwent four key processes: preprocessing, community rec -\nognition, multi-sentence compression, and submodular maximization.\nRecently, the NLP research community has increasingly directed its attention towards \nHybrid ATS techniques. In hybrid approaches, extractive methods are harnessed to \nidentify content terms and sentences deemed essential for inclusion in the summary, \nwhile simultaneously guiding the development of abstracts [36]. Such methods amal -\ngamate the strengths of both extractive and abstractive ATS techniques. Di Fabbrizio \net\u00a0al. [37] introduced a hybrid approach that crafts summaries for product and service \nreviews by blending natural language generation with salient sentence selection tech -\nniques. Their \u2019STARLET-H\u2019 system operates as a hybrid abstractive/extractive sum -\nmarizer. It employs extractive summarization techniques to identify significant quotes \nfrom input reviews, incorporating them into an automatically generated abstractive \nsummary to provide validation, disclosure, or justification for favorable and/or nega -\ntive viewpoints. However, the algorithm necessitates a substantial amount of training \ndata to comprehend aspect order. LLORET and ROM-FERRI [38] proposed the COM -\nPENDIUM ATS system for generating research publication abstracts in the biomedical \ndomain. This system produces two distinct types of generic summaries: extractive and \nabstractive-oriented, accompanied by their respective COMPENDIUM variants: COM -\nPENDIUM-E and COMPENDIUM-A. The extractive approach selectively picks and \nextracts the most pertinent sentences, while the abstractive-oriented approach blends \nPage 6 of 34 Alami\u00a0Merrouni\u00a0et\u00a0al. Journal of Big Data          (2023) 10:163 \nextractive and abstractive techniques, incorporating an information compression and \nfusion stage. Bhat et\u00a0al. introduced \"SumItUp,\" a single-document hybrid TS system, in \n[39]. The hybrid system consists of two phases: (1) Extractive Sentence Selection, which \ngenerates the summary using statistical features (sentence length, sentence position, \nTF-IDF, noun phrases, verb phrases, proper nouns, aggregate cosine similarity, and cue \nphrases), along with a semantic feature (emotion described in the text). In the extractive \nsummary, cosine similarity is utilized to eliminate redundant sentences. For abstractive \nsummary generation, the extracted sentences undergo processing by a language genera -\ntor (a fusion of Wordnet, part-of-speech tagger, and Lesk algorithm) to transform the \nextractive summary into an abstractive rendition.\nEXABSUM ATS approach\nSystem\u2019s architecture\nIn this subsection, we explain the two approaches introduced by the EXABSUM \nATS system for generating the two types of summaries. It is pertinent to high -\nlight that our proposed ATS architecture comprises two distinct components. The \nfirst component, denoted as  EXABSUMExtractive , represents a purely extractive ATS \napproach (Sect.\u00a0 \"EXABSUMExtractive core stages \"), while the second component, \n EXABSUMAbstractive , encompasses abstractive techniques to yield an abstractive sum -\nmary (Sect.\u00a0\"EXABSUMAbstractive core stages \").\nEXABSUMExtractive  core stages\nThe preliminary phase of our methodology is centered on extractive summarization. A \nconventional approach to extractive summarization treats sentences as individual enti -\nties, extracting the most pertinent ones from the text based on specific characteristic \nfeatures (which gauge the suitability of a sentence for inclusion in the summary). Subse -\nquently, the top N extracted sentences are organized to create the summary. The extrac -\ntion procedure is compartmentalized into four stages (illustrated in Fig.\u00a01).\nThe following core stages are covered in detail:\nText pre\u2011processing\nFirst, we initiate the process by conducting fundamental linguistic analysis to prime \nthe text for subsequent stages of processing. This involves the application of text \nFig. 1 EXABSUMExtractive  stages for extractive summary. a preprocessing (surface linguistic analysis); b \nredundancy elimination; c sentence relevance; and d summary generation\nPage 7 of 34\n Alami\u00a0Merrouni\u00a0et\u00a0al. Journal of Big Data          (2023) 10:163 \n \npre-processing (TP) to standardize input files and establish clear sentence boundaries \nwithin word sequences. TP encompasses two primary categories: noise removal and \nnormalization. Noise refers to data components that contribute redundancy to the pri -\nmary text analytics. The manner in which this foundational phase is executed can signifi -\ncantly influence the accuracy of the sentence selection technique. Thus, it is imperative \nto provide explicit details regarding our implementation approach. Depending on the \ndataset type, each document undergoes the subsequent pre-processing stages:\n\u2022 Sentence splitting or segmentation: As an initial step routinely conducted on texts \nprior to subsequent processing, this involves the process of dividing the input text \ninto individual sentences. This division is undertaken to extract pertinent informa -\ntion from the text\n\u2022 Tokenization: Each sentence undergoes intelligent tokenization, wherein all marks, \npunctuation, brackets, digits, and special characters are removed, and all words are \nconverted to lowercase. For instance, given the sentence: \"(text summurizagtnst \nBion;,;:,appR;aochAs is; NL = P a*nd I2r s)\", the result would be: \"( Text summariza -\ntion approach is NLP and IR)\". This process allows for the identification of individual \nwords within the document, facilitating subsequent tasks such as calculating word \nco-occurrences and distinguishing between stop words and nonstop words.\n\u2022 Part-of-speech tagging : Each word is assigned a morphological category using a part-\nof-speech tagger (such as noun, verb, adjective, preposition, adverb, determiner, pro -\nnoun, and conjunction). This process proves advantageous for discerning between \nvarious types of words, as certain categories (e.g., nouns or verbs) hold greater signif -\nicance than others (e.g., determiners). This tool\u2019s application will be evident in sub -\nsequent data compression and fusion phases. Notably, the Stanford POS tagger was \nutilized for this part-of-speech tagging process.\n\u2022 Lemmatization: Variations in a term can impact its frequency. Lemmatization \ninvolves reducing a word\u2019s inflectional forms and derivationally related forms to a \nstandardized base form, referred to as its lemma. Unlike stemming, lemmatization \nrelies on the precise identification of a word\u2019s intended part of speech and mean -\ning within a phrase and in the broader context of surrounding sentences or even an \nentire document. To achieve this, we utilize the Stanford Core NLP package [40] to \nlemmatize our statements.\n\u2022 Stop Word Identification: Certain stop words contribute to the reduction of feature \nspace, resulting in decreased time and space complexity. Stop words encompass vari -\nous prepositions, pronouns, and conjunctions commonly found in sentences. The \nremoval of these terms prior to text analysis ensures that the prevalent words pri -\nmarily pertain to the context rather than being commonplace throughout the text. \nIn our process, this step is conducted before computing single keyword relevance, as \nstop words are excluded from consideration in subsequent phases.\nRedundancy detection and\u00a0removal\nRedundancy is regarded as an undesirable attribute that affects the quality of summa -\nries. In fact, the identified redundant sentences need to be removed from the texts, \nPage 8 of 34 Alami\u00a0Merrouni\u00a0et\u00a0al. Journal of Big Data          (2023) 10:163 \npreserving only a single collection of non-repetitive sentences to be used as input for the \nsummarization process. Our objective at this point is to identify semantically identical \ncontent within the source documents and exclude it from the summary. Textual Entail -\nment (TE) is employed for this precise purpose [41].\nThe objective of TE is to determine whether the meaning of a text sample, referred \nto as a hypothesis (H), can be inferred from another text, known as the text (T) [41]. \nTextual Entailment (TE) involves predicting whether the information presented in the \nfirst sentence unquestionably implies the information in the second sentence for a pair \nof sentences. It addresses semantic inference as a direct mapping between linguistic \nexpressions and abstracts the typical semantic inferences required for text-oriented NLP \napplications. TE has found successful application to the general summarization problem \n[42\u201344], and specifically for identifying duplicate information while addressing summa -\nrization [45]. The entailment relationships are computed using the TE method described \nin [46]. The TE tool relies on lexical (cosine similarity, Levenshtein distance), syntactic \n(dependency trees), and semantic measures based on WordNet [10].\nAfter eliminating the redundant sentences from the source texts, the non-repetitive \nsentences that remain will be input into the extractive summarization approach. This \napproach employs a range of scoring techniques to identify pertinent content, encom -\npassing both statistical and semantic aspects.\nSentence relevance\nThe significance of a sentence in relation to the overall comprehension of the text should \nbe employed to ascertain its importance. This involves assigning scores to the most per -\ntinent terms and subsequently assessing and computing sentence attributes such as doc -\nument position, sentence length, and title similarity. These features can be integrated to \nassess the remaining sentences and select those with the highest scores for inclusion in \nthe summary [47\u201351].\nSentence salience scoring techniques (or combinations thereof) are employed to \nassign a score to each sentence based on its significance. In this work, we introduce a \nhybrid model based on extraction, which integrates statistical, structural, and semantic \nfeatures. The subsequent subsections offer a concise overview of the methods utilized in \nthis phase:\na. Term Relevance-Inverse sentence frequency (TR-ISF)\nWe introduced a novel metric named TR-ISF, derived from the conventional Informa -\ntion Retrieval IR technique Term Frequency-Inverse Document Frequency (TF-IDF). \nThis modified version of TF-IDF is tailored for sentence-level text summarization, as \nopposed to the document-level summary for which TF-IDF is traditionally used. In this \napproach, the relevancy TR of term t is established through its statistical and seman -\ntic relationship across the entire document-dataset level. Subsequently, the ISF gauges \nthe descriptiveness of a word, assessing its prevalence or rarity across all sentences. This \nmethodology operates under the assumption that if a term is both relevant and present \nin a limited number of sentences, it is likely to be included in the summary. In essence, \nPage 9 of 34\n Alami\u00a0Merrouni\u00a0et\u00a0al. Journal of Big Data          (2023) 10:163 \n \npertinent keywords can be employed to detect or quantify sentence relevance, as well as \nto pinpoint the most relevant topic or topics within a text.\nInitially, we employ a Hybrid Feature Selection Model (HFSM) to compute the term \nrelevance using the \u2019TR\u2019 metric. This model integrates both statistical and semantic fea -\ntures. Subsequently, the TR-ISF Equation (Eq.\u00a0(12)) is employed to ascertain the ultimate \nsynthetic score for each term, which is subsequently leveraged to compute the sentence\u2019s \nsalience score (Eq.\u00a0(13)). It\u2019s important to note that not all terms are taken into account, \nand to ensure accuracy, stop word filtering and stemming are applied prior to evaluating \na term\u2019s relevance.\nThe chi-square statistic permits the testing of statistical independence between a term \nand a category by contrasting the observed frequency with the expected frequency, cal -\nculated under the assumption of their independence. The \u03c72 value is defined as:\nwhere O/parenleftbig\ni,j/parenrightbig\n  represents the observed frequency and E/parenleftbig\ni,j/parenrightbig\n denotes the count of docu -\nments that fall under category c and also contain the term w . To discern the nature of the \ndependency when present, Li et\u00a0al. [52] introduced a novel measure called term category \ndependency, defined as:\nwhere Rw,c is the ratio between O(w ,c) and E(w ,c) . Rw,c should be close to 1 if there is \nno dependency between the term w and the category c(i.e., \u03c72\nw,c is not statistically sig -\nnificant), Rw,c should be larger than 1 if there is a positive dependency, meaning the \nobserved frequency is greater than the expected frequency. Conversely, Rw,c should be \nsmaller than 1 if there is a negative dependency.\nIn order to calculate the feature significance of the word w within a corpus contain -\ning k categories, Li et\u00a0al. [52] combine Eqs.\u00a0(1) and (2) which results in a novel measure \nknown as CHIR, defined as follows:\nwhere p(Rw,cj) is the weight of chi-square statistic \u03c72\nw,cj in the corpus in terms of Rw,cj . It \nis defined as:\nThis new term-goodness measure, r\u03c72(w) , is the weighted sum of \u03c72\nw,cj statistics when \nthere is a positive dependency between the term \u03c72\nw,cj and the category cj , a bigger r\u03c72(w) \nor CHIR measure value indicates that the term is more relevant.\nWe utilized the Mutual Information (SIM) measure, a commonly employed concept \nin information theory, to enhance the semantic aspect of the chosen words within (1) \u03c72\nw,c=/summationdisplay\ni\u2208{w ,w}/summationdisplay\nj\u2208{c ,c}(O/parenleftbig\ni,j/parenrightbig\n\u2212E(i,j))2\nE(i,j)\n(2) Rw,c=O(w ,c)\nE(w ,c)\n(3) r\u03c72(w)=k/summationdisplay\nj=1p/parenleftBig\nRw,cj/parenrightBig\n\u03c72\nw,cjwith R w,cj>1\n(4)p/parenleftBig\nRw,cj/parenrightBig\n=Rw,cj/summationtextk\nj=1Rw,cjwith R w,cj>1\nPage 10 of 34 Alami\u00a0Merrouni\u00a0et\u00a0al. Journal of Big Data          (2023) 10:163 \na specific context. This measure quantifies the significance of words based on their \nsemantic content and serves as a gauge of their value. SIM was introduced as a means \nof gauging word association, indicating the intensity of the connection between words \nby contrasting their actual probability of co-occurrence with the probability antici -\npated by chance.\nMutual Information indicates the proportionate shift in the likelihood of encoun -\ntering x when y is present (the amount of information that y provides about x ) [8]. It \nis based on the fact that two words are considered similar if their mutual information \nwith all the words in the vocabulary V is nearly the same [8 ]. The semantic similarity \nmeasure between two terms w1 and w2 is defined as follows:\nwhere V is the vocabulary and  I(zi,w1) is the mutual information between the term zi \nand w1 . I(zi,w1) is evaluated using the following formula:\nwhere d  represent the size of a sliding window, Pd(zi,w1) is the probability of succession \nof  zi  and w1  in a window of (d+1) words and  P(zi) is the priori probability of the term \nzi . This probability can be estimated by the ratio of the number of times that zi is fol -\nlowed by w within the window and by the cardinal of the vocabulary.\nThe similarity between a term w and a document centro\u00efd d is defined in [53] as the \naverage of the similarities between the word w and the x  words of the document cen -\ntro\u00efd. This measure is given by:\nso as to determine the semantic relevance of a term w in a corpus of k clusters, for each \ncluster we calculate the weighted sum of its similarities with the document centroid \ndcen j of each cluster cj using the following formula:\nwhere P/parenleftbig\nI/parenleftbig\nw,dcen j/parenrightbig/parenrightbig\n  is the weight of the similarity between the term w and the doc -\nument centro\u00efd dcen j and I/parenleftbig\nw,dcen j/parenrightbig\n is the mutual information between w and dcen j . \nConsidering the contingency table of a term w and a centro\u00efd d where A is the number \nof times w and d co-occur i.e., w occur in documents that belong to the cluster whose \ncentroid is d , B is the number of times w occurs without d, C is the number of times d \noccurs without w and N is the total number of documents.(5) sim (w1,w2)=1\n2|V||V|/summationdisplay\ni=1(min (I(zi,w1),I(zi,w2))\nmax (I(zi,w1),I(zi,w2))+\nmin (I(w1,zi),I(w2,zi))\nmax (I(w1,zi),I(w2,zi)))\n(6) I(zi,w1)=Pd(zi,w1)log/parenleftbiggPd(zi,w1)\nP(zi)P(w 1)/parenrightbigg\n(7) SIM (w,d)=/summationtextx\nj=1sim(w ,wj)\n/summationtextx\nj=1/summationtextx\ni=1sim(w j,wi)\n(8) SIM (w)=k/summationdisplay\nj=1P/parenleftbig\nI/parenleftbig\nw,dcen j/parenrightbig/parenrightbig\nSIM (w,dcen j)\nPage 11 of 34\n Alami\u00a0Merrouni\u00a0et\u00a0al. Journal of Big Data          (2023) 10:163 \n \nThe mutual information criterion between a term w and a  document dcen j is defined \nby:\nIf there is a strong association between w and dcen j then the joint probabil -\nity P(w ,dcen j) will be larger than P(w)P(dcen j) ; consequently I/parenleftbig\nw,dcen j/parenrightbig\n>0 . If \nw and dcen j are in complementary distribution, then P(w ,dcen j) will be less than \nP(w)P(dcen j) hence I(w,dcen j)<0  . In the case of poor association between w and \ndcen j , then P(w ,dcen j)\u2248 P(w) P ( dcen j ), consequently I(w ,dcen j)\u2248 0. The weight of \nP/parenleftbig\nI/parenleftbig\nw,dcen j/parenrightbig/parenrightbig\n defined as:\nA term with a high weight in the SIM(w) metric implies that it is semantically \nrelevant.\nWe define the feature goodness of a term as a combination of its statistical meas -\nure chir (w) , and its semantic measure sim (w) . The overall measure of a term\u2019s rele -\nvance, TR(w) , is defined as follows:\nwhere \u03b1 is a weighting parameter between 0 and 1.\nTo select the most p  pertinent terms, three steps are followed: (1) calculate the \nhybrid measure TR(w) for each term in the document and the dataset, (2) sort the \nterm in descending order of their criterion function, and (3) finally select the top p \nterms from the sorted list. A threshold \u03b4  is set to 0.25 to filter terms with a low TR(w) \nvalue. In other words, the higher the relevancy of a word, the more important it is in \nindicating the main topic of a document.\nHence, the TR\u2212ISF of a word is computed as shown in Eq.\u00a0(12) and the salience \nscore of a sentence is calculated as presented in Eq.\u00a0(13).\nwhere\n\u2022 TR returns the relevancy of a term(word) wi in the document(s),\n\u2022 T is the total of terms (words) in si,\n\u2022 Swi is the total of sentences in which a relevant word wi is presented (calculated by \nEq.\u00a011),\n\u2022 S is the total of sentences in the document.(9) I(w ,dcen j)=P(w ,dcen j)log/parenleftbiggP(w ,dcen j)\nP(w)P(dcen j)/parenrightbigg\n(10) P/parenleftbig\nI/parenleftbig\nw,dcen j/parenrightbig/parenrightbig\n=I/parenleftbig\nw,dcen j/parenrightbig\n/summationtextk\ni=1/parenleftbig\nI/parenleftbig\nw,dcen j/parenrightbig/parenrightbigwithI/parenleftbig\nw,dcen j/parenrightbig\n>0\n(11) TR(w)=\u03b1\u2217chir (w)+(1\u2212\u03b1)\u2217sim(w)\n(12) TR\u2212ISF (wi)=TR(wi)\u00d7log/parenleftbiggS\nSwi/parenrightbigg\n(13) TR\u2212ISF (si)=S/summationdisplay\nwi\u2208TTR\u2212ISF (wi)\nPage 12 of 34 Alami\u00a0Merrouni\u00a0et\u00a0al. Journal of Big Data          (2023) 10:163 \nb. Sentence resemblance to the title\nThe title of a document often captures the main subjects discussed within it, particu -\nlarly in news articles and scientific publications. The \"sentence resemblance to the title\" \nmethodology assesses the similarity between sentences in a document and its title. By \nemploying this technique, we deduce that sentences exhibiting greater similarity to the \ntitle signify the primary topic addressed in the document. This feature is computed as \nillustrated in the following Equation:\nwhere,\n\u2022 wsi is the set of the relevant words in si\n\u2022 wt is the set of words in the title,\n\u2022 |wt| is the total of words in the title.\nc. Sentence length\nThe consideration of sentence length aims to avoid selecting sentences that might be too \nshort to convey the document\u2019s key points, as well as sentences that are excessively long \nand may result in wasted space. Acknowledging the possibility that a sentence could \ncontain essential information in one part and unrelated information in another, this \nmethod takes into account the sentence\u2019s word count as a measure of its length.\nThis approach is utilized to discourage the selection of sentences that are either \nexcessively short or excessively long, as they are not deemed optimal. Initially, sen -\ntences that fall below a specific size threshold (sentences with fewer than ten non-\nstop words) or exceed a certain length (sentences containing more than 50 non-stop \nwords) are filtered out before computing the sentence score. Subsequently, the \nremaining sentences are assigned scores as depicted in Eq.\u00a0(15).\nIn practice, the penalty score is determined by a conditional:\nwhere,\n\u2022 Li is the length of sentence i and\n\u2022 C is a certain length defined by user.(14) SenRT (Si)=wsi\u2229wt\n|wt|\n(15) SentenceLen (si)=#number _of_words _in_s i\n#max_number _of_words _in_a_sentence\n(16) Score (Si)=/braceleftbigg\nLi if(Li>C)\nLi\u2212C othetwise\nPage 13 of 34\n Alami\u00a0Merrouni\u00a0et\u00a0al. Journal of Big Data          (2023) 10:163 \n \nd. Sentence position\nThe sentence position heuristic is among the most effective strategies for selecting rel -\nevant sentences in automatic text summarization (ATS). This heuristic operates on the \nassumption that the introductory sentences within a document hold the most crucial \ninformation. As the document unfolds, the significance of sentences tends to diminish. \nIn our approach, we prioritize sentences that are located closer to the beginning of a \ndocument.\nThe score for this feature is calculated using the following formula:\nwhere\n\u2022 i is the ith sentence in the document, with i starting by zero,\n\u2022 S is the total of sentences in the document.\nSummary generation\nOnce the scores for each sentence have been computed, the objective of this stage is \nto create a summary by arranging sentences based on their relevance scores. The high -\nest-scoring sentences are selected and extracted in the order they appear in the origi -\nnal document, resulting in a meaningful extractive summary. To determine the overall \nsignificance of a sentence, we employed the averaged combination approach, which \nis considered the most effective combination method and often leads to substan -\ntial improvements [48, 54]. The salience score of a sentence is determined by averag -\ning the individual scores obtained through the N considered scoring procedures in this \ncombination.\nEXABSUMAbstractive  core stages\nThis stage aims to create an abstractive summary through the generation of new text \nthat captures the core content or conceptual elements of the original text. This summary \nsuccinctly and coherently communicates the primary information within the document. \nFor this purpose, we employ a graph-based approach to construct a comprehensive (17) SentPosition (Si)=1\u2212i\nS\nFig. 2 EXABSUMAbstractive  stages for generating abstractive summary\nPage 14 of 34 Alami\u00a0Merrouni\u00a0et\u00a0al. Journal of Big Data          (2023) 10:163 \nabstractive summary, followed by a re-ranking stage that relies on keyphrases. The fol -\nlowing steps (Fig.\u00a02) outline the main procedures involved in this stage:\nWord graph generation and\u00a0re\u2011ranking\nTo generate a summary containing novel sentences, this stage involves compressing \nand merging sentences, followed by a re-ranking process based on the quantity and rel -\nevance of keyphrases present. This approach has demonstrated its efficacy in producing \nmore informative summaries [30, 32].\nA weighted directed word graph is constructed using a document (represented as a \ndirected weighted graph) as input. Nodes in the graph correspond to words, and edges \nsignify adjacency relationships between pairs of words. Each edge\u2019s weight is determined \nby the reciprocal frequency of co-occurrence of the two words.\nOnce the document is transformed into a word graph, a set of new sentences is gen -\nerated by identifying the shortest path between nodes. This begins with the first word \nof each phrase in the extracted document, spanning its entire content. The following \ndetails the methodology:\nLet G = (V,E) be a directed graph with vertices (nodes) V and directed edges E, where \nE is a subset of V*V. Given a set of related sentences S=(s1,s2,...,sn) , a word graph is \nconstructed by iteratively adding sentences to it.\nFigure\u00a0 3 illustrates the word graph built from the four provided sentences. Edge \nweights have been omitted for clarity, and italicized sentence fragments are represented \nby dots.\n1. The president of U.S. Donald Trump visited Venezuela last Thursday.\n2. Donald Trump did a visit to the People Republic of Venezuela on Thursday.\n3. Last week the President of State M. Trump visited Venezuela officials.\n4. Donald Trump wanted to visit Venezuela last month but suspended his arrange -\nments till Thursday last week.\nFig. 3 Word graph constructed from sentences (1\u20134), along with a potential compression path\nPage 15 of 34\n Alami\u00a0Merrouni\u00a0et\u00a0al. Journal of Big Data          (2023) 10:163 \n \nIn the first step, the graph represents a single sentence (a sequence of word nodes \nwithout punctuation) along with the start and end symbols (depicted as start and end \nsymbols in Fig.\u00a0 3). For each word in the sentence, a corresponding node is added to the \ngraph, and directed edges connect words that are adjacent in the sentence. If two words \nin subsequent sentences share the same lowercase form, they are linked to an existing \nnode in the graph, provided that no word from the current sentence has been associ -\nated with that node before. Incorporating part-of-speech (POS) information reduces the \nlikelihood of combining verbs with nouns (e.g., \"visit\"), thus preventing the generation \nof ungrammatical sequences. In cases where no suitable candidates exist in the graph, a \nnew node is generated.\nThe process of word mapping and creation (adding words to the graph) is carried out \nin three distinct steps during the second stage:\n1. non-stop words for which no candidate exists in the graph or for which an unam -\nbiguous mapping is possible;\n2. non-stop words for which there are either several possible candidates in the graph, or \nwhich occur more than once in the sentence\n3. stop words\nFor the last two groups of words where the mapping is ambiguous (i.e., there are two \nor more nodes in the graph that refer to the same word / POS tuple), the immediate con -\ntext (the preceding and following words in the sentence and the adjacent nodes in the \ngraph) is examined. As a result, the candidate that exhibits a greater overlap in context is \nselected. Alternatively, the candidate node with the highest frequency (i.e., the node with \nthe most words mapped to it) is chosen. In Fig.\u00a0 3, for example, when sentence (3) is to be \ninserted, there are two potential candidate nodes for \"last\". Stop words are only linked \nif they overlap with their non-stop word neighbors. If this condition is not met, a new \nnode is created. We utilize the NLTK stop word list, supplemented with temporal nouns \n(e.g., Thursday, today). Filippova\u2019s method prohibits the inclusion of punctuation marks. \nBoudin and Morin [32] introduced a fourth step for constructing well-punctuated com -\npressions, involving the addition of punctuation marks to the graph. When ambiguity \narises in mapping, the candidate with the same immediate context is preferred. Words \ncontiguous in the sentence are connected with directed edges once the sentence\u2019s words \nare added to the graph.\nThe weighting function is defined in Eq.\u00a0 18 to compute edge weights and determine the \noptimal path, representing the most effective compression for the input sentences.\n(18) w/parenleftbig\ni,j/parenrightbig\n=cohesion(i ,j)\nfreq (i)\u00d7freq (j)\n(19) cohesion/parenleftbig\ni,j/parenrightbig\n=freq (i)+freq/parenleftbig\nj/parenrightbig\n/summationtext\ns\u2208Sd(s,i,j)\u22121\nPage 16 of 34 Alami\u00a0Merrouni\u00a0et\u00a0al. Journal of Big Data          (2023) 10:163 \n where freq (i) is the number of words mapped to the node i . The function d(s,i,j) refers \nto the distance between the offset positions of words i and j in sentence s.\nThis function has two objectives:\n(1) to achieve grammatical compression, it prioritizes connections between words that \nfrequently appear in a particular order (refer to Eq.\u00a019).\n(2) to generate an informative compression, it promotes paths passing through salient \nnodes.\nThe weighting function utilized in the K-shortest path algorithm serves to identify \nthe shortest paths within the graph from the starting point to the endpoint (Eq.\u00a0 20). \nPaths with a length of less than eight words or those lacking a verb are filtered out. The \nremaining paths are subsequently re-evaluated by normalizing the cumulative weight of \nthe path over its length. Consequently, the path with the lowest average edge weight is \nconsidered the optimal compression. In our scenario, the initial node corresponds to the \nfirst word of each sentence during the generation of new sentences. This ensures that \nevery sentence in the source text yields at least one derived sentence, guaranteeing com -\nprehensive coverage of the document\u2019s content.\nPaths filtering\nFollowing the compilation of sentences through the shortest pathways, it\u2019s possible that \ncertain sentences are nonsensical, improperly constructed, or incomplete. Therefore, a \nfiltering stage is imperative to discard inappropriate pathways and uphold the integrity \nand coherence of the statements. To achieve this, we establish rules that necessitate sen -\ntences to satisfy all of the defined criteria; those that fail to do so are disregarded.\nThese rules are defined as follows:\n\u2013 Every sentence must contain a verb.\n\u2013 A sentence must be at least three words long.\n\u2013 The sentence should not end in an article (e.g., a, the), a preposition (e.g., of), an \ninterrogative word (e.g., who), or conjunction (e.g., and).\nUpon the removal of erroneous sentences, the replacement sentences can seamlessly \nsubstitute the original ones.\nRe\u2011Ranking candidate sentences using keyphrases\nDespite the apparent effectiveness of Filippova\u2019s method, a notable drawback is the \nabsence of substantial information in a range of 48 to 60% of the generated sentences \n[30]. This limitation arises because node salience is solely determined by the frequency \nmeasure. In response to this concern, we proposed a re-ranking approach that re-evalu -\nates the N-best list of compressions by considering both the quantity and significance of \nkeyphrases present within them. A truly informative and pertinent sentence is expected \nto incorporate the most relevant keyphrases [55].\nHence, we integrated a re-ranking stage that prioritizes compressions featuring \nthe most pertinent keyphrases derived from the initial set of input sentences. This \nPage 17 of 34\n Alami\u00a0Merrouni\u00a0et\u00a0al. Journal of Big Data          (2023) 10:163 \n \nadditional step involves re-evaluating the N-best multi-sentence compression candi -\ndates generated through the word graph-based method, considering the quantity and \nimportance of keyphrases encompassed within each candidate compression.\nWe opted for the shortest path approach followed by a re-ranking step due to three \nmain reasons:\n1. Retaining Salient Terms: the shortest path method allows us to compress sentences \nwhile retaining important terms from the original input. It also facilitates grouping \nwords that frequently appear together in many sentences.\n2. Inclusion of Content: by fusing multiple sentences, we can incorporate more content \ninto the summary, enhancing its comprehensiveness.\n3. Improved Informativeness: the re-ranking stage further enhances the summary by \nmaximizing the diversity of covered topics and producing informative and grammat -\nically accurate sentences. The utilization of keyphrases aids in crafting sentences that \neffectively capture the core ideas across a set of interconnected statements.\nThe unsupervised technique by Wan and Xiao [56] involves extracting significant \nwords from interconnected sentence groups. This approach is built on the concept \nthat a word\u2019s importance can suggest the presence of other words that often occur \ntogether. The strength of this suggestion is recursively determined based on the sig -\nnificance of the suggesting word.\nTo initiate the process of keyphrase extraction, a weighted graph is constructed \nfrom the connected sentences. In this graph, nodes represent words, identified as \nword and POS tuples. When two words co-occur in a sentence, corresponding nodes \nare connected by edges, with edge weights denoting the frequency of their co-occur -\nrence. The TextRank algorithm [57], a graph-based ranking method that incorporates \nedge weights, is employed to compute the salience score for each node. The score for \na node Vi is initialized with a default value and is iteratively calculated until it con -\nverges using the following Equation:\nwhere adj(Vi) represents the neighbors of Vi and d is the damping factor set to 0.85.\nThe second phase involves generating and evaluating potential keywords. We \nmerge sequences of adjacent words that adhere to a given syntactic pattern to cre -\nate multi-word phrases. In our case, we defined noun phrases based on our POS tag \ndefinitions, satisfying the regular expression rule: (NN | NNS | NNP | NNPS | VBN \n| JJ | JJS | RB) * (NN | NNS | NNP | NNPS | VBG) + . Unlike other definitions, our \nnoun phrase structure includes adverbial nouns (tag RB) like \"double experience\" \n(RB NN) and present participle verbs (tag VBG) such as \"virtual desktop conferenc -\ning\" (JJ NN VBG), with the VBG tag appearing at various positions within the noun \nphrase. Adverbial nouns, also known as adverbial objectives, occupy the position that \na verb\u2019s direct object typically occupies and modify the verb by providing informa -\ntion about time, distance, weight, age, or monetary value. Adverbs can interact with \nnoun phrases, impacting the context and meaning of a candidate keyphrase. This (20)(Vi)=1\u2212d\nN+d\u00d7/summationdisplay\nVj\u2208adj(Vi)Wji/summationtext\nVk\u2208adj (Vi)wjkS(Vi)\nPage 18 of 34 Alami\u00a0Merrouni\u00a0et\u00a0al. Journal of Big Data          (2023) 10:163 \ninteraction is particularly notable in scientific contexts, where authors are precise in \nexplaining specific situations.\nThe score of a candidate keyphrase k is calculated by summing the salience scores of \nthe words it contains, normalized by its length + 1 to favor longer n-grams (as shown in \nEq.\u00a021).\nThe generated keyphrases are grouped into clusters based on word overlap. In each \ncluster, the keyphrase with the highest score is selected. This filtering process produces \na smaller subset of keyphrases that better represent the content of the cluster. However, \nthe limited scope of the N-best list can hinder the effectiveness of re-ranking techniques, \nas they may discard many potentially suitable candidates. To address this, various other \npaths are considered. These paths are re-ranked by normalizing the overall weight of the \npath (as defined in Eq.\u00a0 18) across its length and then multiplying it by the sum of the key \nscores it contains. The score for sentence compression c is determined as follows:\nAbstractive summary generation\nThe objective of this concluding stage is to create an abstractive summary based on the \ninput document. Once the preceding processes have been carried out, the remaining \nsentences are employed to generate abstractive summaries. Through these stages, an \nabstractive summary is produced, composed of properly structured and complete sen -\ntences extracted using the shortest paths. Among these, the top N relevant sentences are \nselected, considering their high number of keyphrases. Consequently, the resulting sum -\nmaries encompass abstractive content. These summaries are categorized as abstracts, as \nthey do not replicate the exact sentences found in the source document.\nExperimental setup\nA comprehensive evaluation of EXABSUM\u2019s performance has been conducted using \ndiverse corpora spanning a wide array of topics. In this section, we will outline the fol -\nlowing aspects: (i) the datasets employed and the methodologies used to assess the \nexperiments; (ii) the experimentation process involving parameter refinement. Ulti -\nmately, we will compare our results with those of other analogous works.\nDatasets\nIt is common practice to assess an algorithm by conducting experiments on a spe -\ncific corpus of text summarization tasks, which encompasses both the source texts \nand manually generated summaries. In our case, we employed several datasets from \ndiverse domains as our corpora. By encompassing domains like newswire, tourism, Web \n2.0, science, business, health, justice, lifestyle, opinion, politics, entertainment, sports, (21) score (k)=/summationtext\nw\u2208kTextRank (w)\nlength (k)+1\n(23) score (c)=/summationtext\ni,j\u2208path (c)w(i,j)\nlength (c)\u00d7/summationtext\nk\u2208cscore(k )\nPage 19 of 34\n Alami\u00a0Merrouni\u00a0et\u00a0al. Journal of Big Data          (2023) 10:163 \n \ntechnology, and travel, EXABSUM\u2019s evaluation is carried out from a comprehensive \nperspective.\nEXABSUM\u2019s evaluation focuses on the following datasets:\n\u2013 DUC 2001 and DUC 2002: these datasets are widely used in ATS tasks and were \nprovided by the Document Understanding Collection (DUC) and Text Analytics \nConferences (TAC). DUC 2001 consists of 309 English news articles, each accompa -\nnied by two separate golden summaries prepared by different individuals. DUC 2002 \ncontains 567 news articles in English, covering various topics and lengths, and also \nincludes two gold-standard summaries. The length of the accompanying summa -\nries for both datasets is approximately 100 words. Notably, the DUC collections are \nsentence-divided to identify the most informative sentences. The DUC datasets are \norganized into different categories, including biography, politics, law, society, culture, \nbusiness, health, natural disasters, science, sports, and international topics. Certain \ncategories like \u2019Natural Disaster, \u2019 \u2019Politics and History, \u2019 and \u2019Natural Disaster\u2019 consti -\ntute a significant portion of DUC 2002, making up about 60% of the documents in \nthese categories. All DUC publications and clusters include human-generated sum -\nmaries of approximately 100 words.\n\u2013 CNN Corpus [58] is a substantial collection of news documents used for single-docu -\nment summarization tasks, sourced from CNN\u2019s website (http:// www. cnn. com). This \ncorpus stands as the largest available dataset for single-document extractive sum -\nmarization. It comprises 3,000 English articles that are grouped into twelve subject \ncategories, as originally categorized by CNN: Business, Opinion, Politics, Showbiz, \nHealth, Justice, Living, Sports, World News, Technology, United States, and Travel. \nThe CNN Corpus offers high-quality abstractive summaries for each document, \nknown as \"highlights,\" which are authored by the original writers. In addition to \nthese abstractive summaries, extractive summaries (gold standards) are also pro -\nvided, each containing around 90 to 100 words. These summaries serve as essential \nreferences for both qualitative and quantitative assessments of automated summari -\nzation methods. The gold standard summaries encompass approximately 10,754 sen -\ntences, constituting around 10% of the total number of sentences in the 3,000 texts \nof the CNN Corpus. Numerous research projects are employing the CNN Corpus, \nranging from addressing dangling co-references to enhancing extractive summari -\nzation techniques and even generating abstractive summaries from extractive ones. \nNotably, the CNN Corpus was used in the DocEng\u201919 Extractive Text Summariza -\ntion Competition [58, 59]. This rich dataset plays a crucial role in advancing the field \nof automatic summarization.\nTable\u00a0 1 offers an overview of the datasets utilized in this study, providing basic infor -\nmation about each corpus. The table showcases details such as the number of clusters, \ndocument domains, total document count in each dataset, total sentence count, avail -\nable test documents, average summary length in terms of words, and the intended task \nfor each corpus.\nPage 20 of 34 Alami\u00a0Merrouni\u00a0et\u00a0al. Journal of Big Data          (2023) 10:163 \nEvaluation method\nWe conducted two types of evaluations: quantitative and qualitative. In the quantita -\ntive evaluation, we employed state-of-the-art assessment methods to compare our out -\ncomes with the gold-standard models of the articles. The qualitative evaluation aimed to \ndetermine the extent to which our generated summaries comprehensively covered the \nkey topics of the research articles. Thus, we evaluated the summaries in terms of user \nsatisfaction.\nQuantitative evaluation\nIn the quantitative evaluation, we measure the similarity between a set of candi -\ndate summaries and a collection of reference models (gold standard summaries). This \nevaluation aims to assess the informativeness of the summaries in terms of their con -\ntent. To achieve this, we utilize the ROUGE-N metric, which captures various levels of \nN-gram co-occurrences between candidate summaries and reference models. Notably, \nROUGE-1 and ROUGE-2 are well-known ROUGE metrics that compute the overlaps \nof unigrams and bigrams. Among these metrics, ROUGE-1 recall exhibits the strongest \nrecall ability to identify a better summary within a pair [60, 61]. ROUGE-N quantifies \nthe n-gram recall between a candidate summary and a set of reference summaries using \nthe following formula:\nwhere n stands for the length of the n-gram, gramn , and Count match (gramn) is the \nmaximum number of n-grams co-occurring in a candidate summary and a set of refer -\nence summaries [60, 61]. Lin [60, 61] also demonstrated a strong correlation between \nROUGE-1 recall and human judgments. Additionally, we employ ROUGE-SU4, which \ncounts overlapping skip-bigrams between a candidate summary and a reference model, \nallowing for a maximum gap of four words. Lastly, we use ROUGE-L, which measures \nthe longest common subsequence between two summaries [60, 61].(24) ROUGE \u2212N=/summationtext\nS\u2208{ReferemceSummaries}/summationtext\ngramn\u2208SCount match (gramn)\n/summationtext\nS\u2208{ReferenceSummaries/summationtext\ngramn\u2208SCount(gramn)Table 1 Statistics of the CNN and DUC datasets\nDataset Number \nof clustersDomain\u2019s \ndocumentsNumber of \nDocumentsSentences Number \nof test \ndocumentsAvg. length\n(Model sum)Task\nDUC01 30 Multi-Domain 309 269,990 309 100 Single and \nMulti\nDUC02 59 Multi-Domain 567 348,012 567 100 Single and \nMulti\nCNN 0 Multi-Domain 3000 2,628,336 2000 90 Single\nPage 21 of 34\n Alami\u00a0Merrouni\u00a0et\u00a0al. Journal of Big Data          (2023) 10:163 \n \nQualitative evaluation\nIn this evaluation, our objective is to measure user satisfaction with the generated sum -\nmaries. For this purpose, we carried out a qualitative evaluation by inviting ten English-\nspeaking individuals to rate our summaries. We adopted the same qualitative evaluation \nmethod outlined in [38]. To illustrate, while a 3-level scale might include the catego -\nries \"low,\" \"medium,\" and \"high,\" a 5-level Likert scale provides varying degrees to gauge \nagreement on a specific matter, ranging from \"strongly agree,\" \"agree,\" \"neither agree nor \ndisagree,\" \"disagree,\" to \"strongly disagree.\"\nSpecifically, the asked questions are:\n\u2022 Q1: The summary reflects the most important issues of the document.\n\u2022 Q2: The summary allows the reader to know what the article is about.\n\u2022 Q3: After reading the original summary provided with the document, the alternative \nsummary is also valid.\nGiven the diverse lengths of the documents, our evaluation approach focused on uti -\nlizing 10 randomly selected documents from each of the tested datasets.\nExperiments results and\u00a0discussion\nIn this section, we conducted experiments to evaluate different types of EXABSUM \nsummaries. We employed two variations of EXABSUM: (i)  EXABSUMExtractive , which \ngenerates extractive summaries, and (ii)  EXABSUMAbstractive , which generates abstrac -\ntive summaries. By evaluating both types of summaries, we aimed to assess EXABSUM\u2019s \nability to extract relevant information and its performance in addressing the abstrac -\ntive text summarization challenge. Additionally, we aimed to determine whether the \nstrategies employed in EXABSUM are effective in generating summaries across various \ndomains, such as Business, Opinion, Politics, Showbiz, Health, Justice, Living, Sports, \nTechnology, Travel, newswire, and more. We compared the results with those of existing \nautomatic text summarization systems to strengthen our findings.\nParameter value selection and\u00a0analysis of\u00a0scoring techniques\u2019 suitability\nThe aim of this evaluation is to appraise the effectiveness of the proposed features for \nsentence relevance detection. This assessment involves examining these features both \nindividually and in combination, as outlined in the relevant subsections.\nThe weighting parameter \u03b1, as specified in Eq.\u00a0(13), plays a crucial role in determining \nthe relevance of a specific term within a sentence. This parameter governs the weight \nassigned to both the statistical feature (CHIR) and the semantic feature (SIM) within \nthe hybrid weighting model. To evaluate the impact of each feature on the keyword\u2019s rel -\nevancy measure TR(w), we conducted multiple trials using different \u03b1 values (\u03b1 \u2208 {0, 0.2, \n0.5, 0.6, 0.8, 1}). Our findings show that the most favorable outcomes are achieved when \n\u03b1 = 0.6 is utilized, closely followed by \u03b1 = 0.5. This observation underscores the signifi -\ncance of combining both statistical and semantic relationships to enhance the overall \nrelevancy determination.\nPage 22 of 34 Alami\u00a0Merrouni\u00a0et\u00a0al. Journal of Big Data          (2023) 10:163 \nIn our experiments, we consistently set the TR-ISF measure parameter \u03b1 to 0.6. To \ncomprehensively assess the effectiveness of various sentence relevancy scoring tech -\nniques, we conducted an ablation study using a backward-like total exclusion proce -\ndure. This involved individually excluding or adding the scores from each approach in \nthe weighted averaged model. This evaluation enabled us to achieve three objectives: (1) \ndetermining whether the scoring techniques are suitable for enhancing ROUGE scores; \n(2) identifying their contribution to topic coverage within the document; and (3) gauging \nthe sentence importance.\nThe ablation technique allowed us to compute ROUGE-1 and ROUGE-2 scores for the \nDUC01 dataset (Table\u00a0 2), as well as ROUGE-1, ROUGE-2, ROUGE-SU4, and ROUGE-L \nscores for the DUC02 dataset (Table\u00a0 3). Additionally, we presented the ROUGE-1 and \nROUGE-2 scores for the CNN dataset in Table\u00a0 4. Visual representations of the perfor -\nmance of our proposed approach under varied scoring technique values are depicted in \nFigs.\u00a04, 5, and 6 for the DUC01, DUC02, and CNN datasets, respectively.\nIn the first experiment, as depicted in Tables\u00a0 2 and 3, we focused on selecting sum -\nmary sentences that include relevant keywords and topics determined by the TR-ISF \nscoring technique, corresponding to the sentence relevance identification stage of \n EXABSUMExtractive . The TR component pinpoints significant keywords that signify \nessential topics, while the ISF component gauges a word\u2019s descriptiveness. We then com -\npared the resulting combinations to the output of  EXABSUMAbstractive . In generating the Table 2 ROUGE results for  EXABSUMExtractive  and  EXABSUMAbstractive  in Feature Analysis of the \nDUC2001 Dataset: Comb Represents the Combination of Selected Scoring Approaches\nSummary type Scoring techniques DUC 2001\nROUGE\u20111 ROUGE\u20112\nEXABSUMExtractive TR\u2212ISF ONLY 0.398 0.131\nEXABSUMExtractive Comb1: TR\u2212ISF + Sentence position 0.402 0.143\nEXABSUMExtractive Comb2: TR\u2212ISF + Sentence Position + Sentence Length 0.453 0.192\nEXABSUMExtractive Comb3: TR\u2212ISF + Sentence Position + Sentence \nLength + Sentence resemblance To the Title0.480 0.208\nEXABSUMAbstractive Graphs + Reranking based on keyphrases ONLY 0.319 0.151\nTable 3 ROUGE results for EXABSUMExtractive on DUC2002 dataset: analysis of features with comb \nas the combined scoring techniques\nSummary Type Scoring Techniques DUC 2002\nROUGE\u20111 ROUGE\u20112 ROUGE\u2011 SU4 ROUGE\u2011L\nEXABSUMExtractive TR\u2212ISF ONLY 0.439 0.188 0.205 0.396\nEXABSUMExtractive Comb1: TR\u2212ISF + Sentence position 0.441 0.189 0.207 0.401\nEXABSUMExtractive Comb2: TR\u2212ISF + Sentence Posi-\ntion + Sentence Length0.488 0.236 0.251 0.442\nEXABSUMExtractive Comb3: TR\u2212ISF + Sentence Posi-\ntion + Sentence Length + Sentence \nresemblance To the Title0.493 0.257 0.288 0.472\nEXABSUMAbstractive Graphs + Reranking based on keyphrases \nONLY0.341 0.104 0.134 0.322\nPage 23 of 34\n Alami\u00a0Merrouni\u00a0et\u00a0al. Journal of Big Data          (2023) 10:163 \n \nTable 4 ROUGE results for  EXABSUMExtractive  and  EXABSUMAbstractive  on CNN dataset while analyzing \ntheir features, Comb denotes the combination of the selected scoring techniques\nSummary type Scoring techniques CNN\nROUGE\u20111 ROUGE\u20112\nEXABSUMExtractive TR\u2212ISF ONLY 0.519 0.351\nEXABSUMExtractive Comb1: TR\u2212ISF + Sentence position 0.541 0.379\nEXABSUMExtractive Comb2: TR\u2212ISF + Sentence Position + Sentence Length 0.592 0.434\nEXABSUMExtractive Comb3: TR\u2212ISF + Sentence Position + Sentence \nLength + Sentence resemblance To the Title0.601 0.451\nEXABSUMAbstractive Graphs + Reranking based on keyphrases 0.501 0.332\n0.0000.1000.2000.3000.4000.5000.600\nTR-ISF ONLY Comb 1C omb2 Graphs +\nRerankingComb 3Results for DUC 2001\nROUGE-1 ROUGE-2\nFig. 4 ROUGE-1 and ROUGE-2 Results of EXABSUM on the DUC 2001 Collection with Varied Scoring \nTechniques and Summary Types\n0.0000.1000.2000.3000.4000.5000.600\nTR-ISF ONLY COMB1C OMB2G RAPHS + \nRERANKINGCOMB3RESULTS FOR DUC 2002\nROUGE-1 ROUGE-2 ROUGE-SU4 ROUGE-L\nFig. 5 ROUGE-1, ROUGE-2, ROUGE-SU4, ROUGE-L Results of EXABSUMExtractive on the DUC 2002 collection: \nvariations in scoring techniques and summary types\nPage 24 of 34 Alami\u00a0Merrouni\u00a0et\u00a0al. Journal of Big Data          (2023) 10:163 \nsummary, we assigned scores to phrases using Eq.\u00a0 13, and the highest-ranked phrases \nwere utilized to construct the summary.\nIn the second experiment, we focus on selecting summary sentences based solely \non sentence resemblance to the title, sentence length, sentence position, or a combi -\nnation of these factors. As evident from Tables\u00a0 2, 3, and 4 , a clear trend is observed \nin most cases with  EXABSUMExtractive  yielding the best results, particularly when all \nscoring methodologies are combined (comb3). For instance, the ROUGE-1 results for \n EXABSUMExtractive  with combination 3 show an average improvement of 13.44% com -\npared to the  EXABSUMExtractive  approach that solely employs the TR-ISF for scoring \nphrases.\nIn the case of Combination 2, the same approach yielded an improvement of 11.85% \nover the results obtained for EXABSUMExtractive using only TR-ISF.\nIn terms of individual feature analysis, it is noteworthy that summaries generated \nsolely utilizing the TR-ISF scoring technique generally perform well. This could be \nattributed to the use of a robust scoring technique (incorporating statistical and seman -\ntic features) to identify the most relevant terms or topics in a document. However, the \nresults show improvement when the three recommended features are combined in the \nsame approach (Comb3). Consequently, the well-incorporated features are well-suited \nfor the extractive text summarization task, especially in the case of  EXABSUMExtractive . \nThe superior ROUGE scores achieved by our system stem not only from the incorpo -\nration of TR-ISF and other scoring methodologies but also from the inclusion of the \nredundancy elimination phase using The Textual Entailment (TE) tool [62]. This phase \nplays a crucial role in generating semantically and syntactically non-redundant summa -\nries. It identifies and removes sentences that are semantically redundant within docu -\nments. As a result, sentences with contextual overlap in other sentences can be omitted, \nleading to improved precision scores and overall system performance.0.0000.1000.2000.3000.4000.5000.6000.700\nTR-ISF ONLY COMB1 COMB2 GRAPHS + \nRERANKINGCOMB3RESULTS FOR CNN\nROUGE-1 ROUGE-2\nFig. 6 ROUGE-1 and ROUGE-2 results of our proposed approach for the large CNN dataset while varying the \nscoring techniques and summary types\nPage 25 of 34\n Alami\u00a0Merrouni\u00a0et\u00a0al. Journal of Big Data          (2023) 10:163 \n \nRegarding  EXABSUMAbstractive , based on preliminary findings, it is evident that \nrelying solely on graphs and re-ranking based on key approaches does not yield high \nROUGE scores, although the results are promising for future research endeavors. \nThe moderate performance of this abstractive technique can be attributed to the \nconstrained summary length of 100 words. Consequently, the selection process for \nthe most significant sentences before or after generating new ones might lead to the \nomission of certain concepts, impacting the overall performance of the summaries \nand resulting in lower ROUGE scores. Contrary to common assumptions, longer \nsentences do not consistently equate to better summaries, nor do shorter sentences \nguarantee more informative summaries. To address these limitations, a potential \napproach to enhance the selection of the newly generated summary sentences would \ninvolve devising an optimization function to identify the best-performing sentences. \nOne avenue for improving  EXABSUMAbstractive  could involve leveraging the optimal \n EXABSUMExtractive  combination (Comb3) to achieve this objective.\nQualitative evaluation\nTable\u00a0 5 presents our qualitative evaluation, designed to assess user satisfaction with the \nproduced summaries. When examining the varying percentages of assessed summa -\nries within each category, we observe a moderate number of abstractive summaries that \nhave received agreement compared to extractive summaries evaluated under the same \ncriteria.\nThe information presented in the summaries generated using  EXABSUMAbstractive  was \nassessed positively in contrast to the extractive technique, and in terms of human per -\nception, the abstractive summaries surpass the extractive ones in terms of quality. Addi -\ntionally, it is noteworthy that the utilization of  EXABSUMAbstractive  leads to a reduction \nin the proportion of summaries receiving lower scores (strongly disagree and disagree). \nTable\u00a0 6 illustrates an example of two summaries produced by  EXABSUMExtractive  and \n EXABSUMAbstractive , respectively. As evident, certain sentences are shared by both sum -\nmaries, while others have been truncated in the latter.\"\nTable 5 Results of user satisfaction for various text summarization approaches\n% TS approach Q1 Q2 Q3\n1. Strongly disagree EXABSUMExtractive 8.76 17.25 17.25\nEXABSUMAbstractive 1.44 0 1.21\n2. Disagree EXABSUMExtractive 38.6 19.01 30.1\nEXABSUMAbstractive 28.37 18.41 27.61\n3. Neither agree nor disagree EXABSUMExtractive 21.39 17.44 22.83\nEXABSUMAbstractive 19.2 17.44 22.83\n4. Agree EXABSUMExtractive 19.2 48.06 42.1\nEXABSUMAbstractive 50.46 34.83 5.32\n5. Strongly agree EXABSUMExtractive 6.29 13.78 22.2\nEXABSUMAbstractive 6.29 13.78 8.55\nPage 26 of 34 Alami\u00a0Merrouni\u00a0et\u00a0al. Journal of Big Data          (2023) 10:163 \nComparison to\u00a0baselines\nIn this subsection, we will compare the top results achieved by  EXABSUMExtractive  and \n EXABSUMAbstractive  in generating single-document summaries with the performance \nof various state-of-the-art summarization techniques. Specifically, we will compare \nour summarization outcomes with:\nI. The best-performing participants in the DUC 2001 and 2002 shared tasks.\nII. The three most successful summarizers identified in a prior evaluation as documented \nin [63].\nIII. Other approaches, both recent and earlier, that utilized the DUC01 and DUC02 data -\nsets, and evaluated their results using ROUGE-1 and ROUGE-2 metrics. The follow -\ning subsections provide a brief overview of these approaches:\n- Parveen and Strube [19] introduced an unsupervised graph-based technique for \nsingle-document summarization, which considers three essential summary features: \nsignificance, non-redundancy, and local coherence.\n- Autosummarizer [64] is a web service that generates summaries by segmenting and \nranking the most crucial sentences. Its single-document summarization method \ninvolves selecting the most pertinent sentences from the source document and has \ndemonstrated superior performance compared to other summarizers in previous \nevaluations [65]. Unfortunately, details regarding the functioning of this system are \nnot available.\n- Classifier4J [66] is a text summarization and classification toolbox. It performs \nextractive single-document summarization based on word frequency and constructs \nthe summary from the initial sentences that include any of the top-100 most frequent \nwords in the document.\n- UnifiedRank [67] is an approach that introduces an innovative unified method for \nsingle-document and multi-document summarization simultaneously. It utilizes a \ngraph-based representation along with a unified ranking technique.Table 6 Example summaries generated by EXABSUMExtractive and EXABSUMAbstractive for \nDocument WSJ891019-0021 (DUC 2002 Corpus, Cluster d062j) with 50% ratio of original text\nEXABSUMExtractive\nThe White House is making sure nobody will accuse it of taking this crisis lightly\nPresident Bush and his aides flew into a whirlwind of earthquake related activity yesterday morning\nMr Bush and his aides were accused of responding too slowly after the Exxon Valdez oil tanker split open in \nAlaskan waters and Hurricane Hugo struck the Carolina coast\nMr. Bush got his first earthquake briefing of the day at 6:30 a.m\nMr Bush said that he hoped there would be less carping about the emergency office performance this time add-\ning that the agency took a hit for its reaction to Hurricane Hugo\nEXABSUMAbstractive\npresident bush visiting the california earthquake site this weekend. president bush and his aides flew into a whirl-\nwind of earthquake related activity yesterday morning to get federal help flowing to victims, designed mostly to \nproject image of white house in action, were trying to head off criticism, were accused of responding too slowly \nafter the exxon valdez oil tanker split open in alaskan waters and hurricane hugo struck the carolina coast visited \nfema headquarters do not want a repeat those charges. the white house is making sure nobody will accuse it of \ntaking crisis lightly\nPage 27 of 34\n Alami\u00a0Merrouni\u00a0et\u00a0al. Journal of Big Data          (2023) 10:163 \n \n- DE [9] is a summarization technique based on sentence clustering. It optimizes the \nobjective function using a discrete Differential Evolution method and similarity, \nthereby selecting representative sentences from each cluster.\n- The Fuzzy Evolutionary Optimization Model (FEOM) [68] categorizes sentences \nbased on document content and selects the most significant sentence from each \ncluster to represent the overall meaning of a document.\n- NetSum [69] is a method that utilizes the RankNet learning algorithm to train a pair-\nbased sentence ranker. It scores each phrase in a document to determine the most \nrelevant sentences.\n- Compendium [38]: a text summarization system used to generate two types of \ngeneric summaries\u2014extractive and abstractive. It includes the variations COM -\nPENDIUME and COMPENDIUME\u2013A, where the former focuses on choosing and \nextracting the most relevant sentences using an extractive approach. The latter, \nCOMPENDIUME\u2013A, combines extractive and abstractive strategies by integrating \nan information compression and fusion stage to generate abstractive-oriented sum -\nmaries.\n- HP-UFPE Functional summarizing (HP-UFPE FS) [70]: A summary system that \ndraws from seventeen extractive summarization methodologies that have garnered \nsubstantial attention in the literature, extensively explored in research papers, blogs, \nand news articles. In this evaluation, the HP-UFPE FS system is utilized, employing \nthe optimal sentence scoring combination for news articles as detailed in [70].\n- Get To The Point [71]: An abstractive summarization approach featuring coverage \nand utilizing a hybrid pointer-generator architecture. This technique addresses the \nchallenge faced by conventional abstractive summarization systems on extensive \ndocuments, mitigating the generation of repeated and redundant words and phrases.\n- Fast Abstractive Summarization [36]: Introduces a precise and efficient summariza -\ntion model that initially selects important sentences and subsequently rewrites them \nin an abstractive manner\u2014compressing and paraphrasing\u2014to generate a concise \nfinal summary. The method employs a novel sentence-level policy gradient technique \nto connect the non-differentiable calculation between these two neural networks \nwhile maintaining linguistic fluency.\nTables\u00a0 7, 8, and 9 provide a comparison between the top-performing configurations \ndetermined during our experiments and the summarizers mentioned earlier, focusing \non the ROUGE-1, ROUGE-2, DUC 2001, DUC 2002, and CNN collections, respec -\ntively. Beginning with the DUC 2001 dataset, our systems  (EXABSUMExtractive  and \n EXABSUMAbstractive ) surpass the DE and FEOM systems in terms of both ROUGE-1 and \nROUGE-2 scores (see Fig.\u00a07).\nUpon analyzing the feature weights derived from DE and FEOM, it becomes evident \nthat both methods employ semantic features to ascertain the significance of sentences. \nThis suggests that semantic techniques play a substantial role in the text summariza -\ntion process. System T, which stands as the top-performing participant in the DUC 2001 \ncompetition, achieved superior ROUGE-2 results. However, it\u2019s worth noting that its \nperformance is statistically similar to the outcomes produced by DE, FEOM, and Clas -\nsifier4J (a supervised approach).\nPage 28 of 34 Alami\u00a0Merrouni\u00a0et\u00a0al. Journal of Big Data          (2023) 10:163 \nTable 7 F-measure comparison: our proposed techniques vs. baselines for single-document \nsummarization on the DUC 2001 collection\nThe bold values emphasize the superior significance of our approach compared to othersSummary type Summary type DUC 2001\nROUGE-1 ROUGE-2\nEXABSUMExtractive Extractive 0.480 0.208\nEXABSUMAbstractive Abstractive 0.319 0.151\nDE Extractive 0.478 0.185\nFEOM Extractive 0.477 0.185\nNetSum Extractive 0.464 0.176\nUnifiedRank Extractive 0.453 0.176\nSystem T (best DUC 2001 partici-\npant)Extractive 0.445 0.202\nClassifier4J Extractive 0.444 0.198\nAutosummarizer Extractive 0.419 0.169\nHP-UFPE FS Extractive 0.359 0.117\nTable 8 Comparison of F-measure results between our proposed techniques and the baseline \nmethods on the DUC 2002 collection for the single-document summarization task\nSystems Summary Type DUC 2002\nROUGE-1 ROUGE-2\nEXABSUMExtractive Extractive 0.493 0.257\nEXABSUMAbstractive Abstractive 0.341 0.104\nParveen and Strube [19] Extractive 0.485 0.230\nUnifiedRank Extractive 0.484 0.214\nSystem 28 (best DUC 2002 participant) Extractive 0.480 0.228\nClassifier4J Extractive 0.470 0.221\nDE Extractive 0.466 0.123\nFEOM Extractive 0.465 0.124\nCOMPENDIUM E Extractive 0.456 0.202\nNetSum Extractive 0.449 0.111\nAutosummarizer Extractive 0.437 0.191\nCOMPENDIUM E\u2013A Abstractive 0.395 \u2013\nFast Abstractive Summarization Abstractive 0.394 0.173\nGet To The Point Abstractive 0.372 0.157\nHP-UFPE FS Extractive 0.359 0.117\nTable 9 F-measure results of our proposed approaches compared to baselines on the CNN dataset \nfor single-document summarization task\nSystems Summary Type CNN\nROUGE-1 ROUGE-2\nEXABSUMExtractive Extractive 0.601 0.451\nEXABSUMAbstractive Abstractive 0.501 0.332\nHP-UFPE FS Extractive 0.507 0.345\nAutosummarizer Extractive 0.488 0.327\nClassifier4J Extractive 0.466 0.321\nPage 29 of 34\n Alami\u00a0Merrouni\u00a0et\u00a0al. Journal of Big Data          (2023) 10:163 \n \nOn the DUC 2002 dataset, the top three performing systems are  EXABSUMExtractive , \nParveen, and Strube [19] (See Fig.\u00a0 8). It is worth noting that the Parveen and Strube \n[19] approach treats summarization as an optimization task, with an optimization \nstep used to verify non-redundancy and local coherence in the resulting summa -\nries. As expected, incorporating coherence and redundancy elimination approaches \nimproves ATS performance. Despite the fact that the DUC2001 and DUC2002 con -\ntests have been running for a decade, the System T and System 28 still produce \ncompetitive results when compared to certain current summarizers. In contrast, \nwhile using deep learning methodologies, the \u2019get to the point\u2019 and \u2019rapid abstractive \nFig. 7 Comparison of ROUGE-1 and ROUGE-2 Results:  EXABSUMExtractive  and  EXABSUMAbstractive  vs. various \nbaseline systems on the DUC 2001 dataset\nFig. 8 ROUGE-1 and ROUGE-2 results of EXABSUMExtractive and EXABSUMAbstractive compared to various \nbaseline systems on the DUC 2002 dataset\n0.0000.1000.2000.3000.4000.5000.6000.700\nHYBRISUM\nExtrac/g415veHYBRISUM\nAbstrac/g415v eHP-UFPE FSA utosummarizer Classi\ufb01er4 JCNN\nROUGE-1 ROUGE-2\nFig. 9 ROUGE-1 and ROUGE-2 results of  EXABSUMExtractive  and  EXABSUMAbstractive  compared to various \nbaseline systems on the large CNN dataset\nPage 30 of 34 Alami\u00a0Merrouni\u00a0et\u00a0al. Journal of Big Data          (2023) 10:163 \nsummarization\u2019 systems (state-of-the-art abstractive methods) produced unimpres -\nsive results.\nRegarding the CNN dataset, once more,  EXABSUMExtractive  emerges as the top per -\nformer in terms of ROUGE-1 and ROUGE-2 scores (see Fig.\u00a0 9). Statistically, it surpasses \nall other systems, showcasing a remarkable 34.12% enhancement over the best-perform -\ning system.\nOverall, our two automatic text summarization (ATS) techniques, namely \n EXABSUMExtractive  and  EXABSUMAbstractive , demonstrate effectiveness in extractive \nand abstractive document summarization, respectively. They stand on par with other \nstate-of-the-art text summarization tools, both extractive and abstractive. However, it\u2019s \nimportant to note that  EXABSUMAbstractive  falls short compared to  EXABSUMExtractive . \nThe employment of  EXABSUMExtractive  results in higher ROUGE-1 scores when com -\npared to other techniques. The performance of  EXABSUMAbstractive  lags behind \n EXABSUMExtractive  across most metrics, as it solely relies on the input content and \nlacks the enhancement provided by the most relevant extractive sentences produced by \n EXABSUMExtractive .\nAs mentioned earlier, the ROUGE evaluation relies on exact matches of text fragments \nwhen comparing system-generated summaries to human-produced ones (extracts). \nConsequently, if abstractive information is integrated with the extractive output sum -\nmary in a hybrid model, it\u2019s possible that the F-measure results could significantly \nimprove compared to the initial extract. This insight suggests that further research could \nbe conducted into these types of summaries, aiming to enhance their quality beyond the \nmere selection of sentences.\nIn our specific approach to creating and testing  EXABSUMAbstractive , we employed \ntwo methods: (1) We initiated the process by crafting abstractive summaries based on \nsentences identified as relevant during the sentence relevance stage. These summa -\nries underwent compression or merging of information, followed by reranking. This \napproach led to resulting summaries that were shorter than the extracts produced by \n EXABSUMExtractive . Since no additional information was introduced, the recall value was \nconsistently lower than that of  EXABSUMExtractive . (2) For the second technique, we uti -\nlized  EXABSUMAbstractive  to generate new sentences from the source document, starting \nwith the first word of each sentence. Ultimately, we opted for this latter technique, as it \nappeared more suitable for producing more accurate summaries. However, it\u2019s impor -\ntant to note that further research efforts are required to enhance  EXABSUMAbstractive , \nincluding exploring techniques such as rephrasing and embedding.\nBased on the ROUGE evaluation results presented in Tables\u00a0 7, 8, and 9, it\u2019s evident that \nthe proposed summarization approach, EXABSUM, demonstrates strong performance \nacross its two variants:  EXABSUMExtractive  and  EXABSUMAbstractive . These findings \nunderscore the significance of both types of summaries, as they collectively contribute \nto the creation of informative summaries, ultimately enhancing the performance of the \ntext summarization task. Additionally, our proposed approach for automatic text sum -\nmarization effectively aids in selecting sentences that are not only informative but also \ngrammatically correct and semantically relevant to the text.\nPage 31 of 34\n Alami\u00a0Merrouni\u00a0et\u00a0al. Journal of Big Data          (2023) 10:163 \n \nSummary and\u00a0conclusions\nIn this paper, we introduced EXABSUM, a novel approach to automatic text summa -\nrization (ATS) specifically designed for single-document summarization. EXABSUM \noffers the generation of two types of summaries: extractive and abstractive, repre -\nsented by the corresponding  EXABSUMExtractive  and  EXABSUMAbstractive  variants. The \nextractive technique integrates statistical and semantic scoring methods, including \nthe innovative \u2019TR-ISF\u2019 approach, to effectively select and extract non-redundant and \nrelevant sentences. On the other hand, the abstractive approach incorporates infor -\nmation compression, fusion, and re-ranking strategies based on keyphrases, produc -\ning abstractive summaries from the source document rather than relying solely on the \nextractive summary.\nThe evaluation results showcased the effectiveness of our two ATS techniques. They \ndemonstrated their ability to capture crucial information across various domains \nthrough benchmark datasets. With the proposed architecture, EXABSUM not only \nretains essential information but also generates coherent and distinct abstractive \nsummaries alongside the extractive ones. Furthermore, the modular structure of \nEXABSUM facilitates easy integration of new phases, allowing for potential improve -\nments and expanded functionalities of the ATS method.\nThis promising result suggests the avenue for future research in abstractive and \nhybrid ATS approaches to enhance their performance beyond mere sentence selec -\ntion. Our work highlights the potential of this novel direction for the NLP community. \nIn the future work, we plan to assess EXABSUM\u2019s performance using hybrid tech -\nniques and explore alternative methods to enhance abstractive summaries, including \nrephrasing techniques and integration of deep learning methodologies.\nAbbreviations\nIR  Information retrieval\nNLP  Natural language processing\nATS  Automatic text summarization\nROUGE  Recall-oriented understudy for gisting evaluation\nHFSM  Hybrid feature selection model\nAcknowledgements\nNot applicable.\nAuthor contributions\nAuthor ZAM is the first author who: conceived and designed the analysis; collected the data; contributed data or analysis \ntools; performed the analysis; wrote the paper. Professors BF and BO also contribute to the paper in conceiving and \ndesigning the analysis, helping the whole methodology findings. All authors reviewed the manuscript.\nFunding\nNot applicable.\nAvailability of data and materials\nThe data was collected from the case company and is not available to the general public. The authors\u2019 data are, however, \navailable upon reasonable request and with the permission of the case study company. The used datasets are available \nin:DUC dataset: https:// duc. nist. gov/ data. html; CNN dataset: https:// sites. google. com/ view/ summa rizat ionco rpus/p% \nC3% A1gina- inici al . Requests for software application or custom code should be made to the corresponding authors \nupon reasonable request.\nDeclarations\nEthics approval and consent to participate\nThis article does not contain any studies with human participants or animals performed by any authors.\nConsent for publication\nNot applicable.\nPage 32 of 34 Alami\u00a0Merrouni\u00a0et\u00a0al. Journal of Big Data          (2023) 10:163 \nCompeting interests\nThe authors declare that they have no competing interests. All authors certify that they have no affiliations with or \ninvolvement in any organization or entity with any financial interest or non-financial interest in the subject matter or \nmaterials discussed in this manuscript.\nReceived: 18 August 2022   Accepted: 3 October 2023\nReferences\n 1. Hovy E, Marcu D. Automated text summarization. The Oxford handbook of computational linguistics. 2005, pp. \n583\u2013598.\n 2. Mani I, Maybury MT. Advances in automatic text summarization. Cambridge: The MIT Press; 1999.\n 3. Huang L, He Y, Wei F, Li W. Modeling document summarization as multi-objective optimization. In: Proceedings \nof the third international symposium on intelligent information technology and security informatics. 2010, pp \n382\u2013386.\n 4. Gupta S, Gupta SK. Abstractive summarization: an overview of the state of the art. Expert Syst Appl. 2019;121:49\u201365.\n 5. Nenkova A, & McKeown K. A survey of text summarization techniques. In Mining text data. Springer; 2012, pp. \n43\u201376.\n 6. Luhn HP . The automatic creation of literature abstracts. IBM J Res Dev. 1958;2(2):159\u201365.\n 7. Barrios F, L\u00f3pez F, Argerich L et al. Variations of the similarity function of textrank for automated summarization. The \nArgentine Symposium on Artificial Intelligence (ASAI) 2015-44 JAIIO; 44 JAIIO-ASAI 2015-ISSN: 2451\u20137585, 2016. pp \n65\u201372.\n 8. Dagan I, Marcus S, Markovitch S. Contextual word similarity and estimation from sparse data. In: Proceedings of the \n31st annual meeting on Association for Computational Linguistics, pp. 164\u2013171. Association for Computational \nLinguistics (1993).\n 9. Aliguliyev RM. A new sentence similarity measure and sentence based extractive technique for automatic text sum-\nmarization. Expert Syst Appl. 2009;36(4):7764\u201372.\n 10. Alc\u00f3n O, Lloret E. SEMPCA-Summarizer: exploiting semantic principal component analysis for automatic summary \ngeneration. Comput Informs. 2018;37:1126\u201348.\n 11. Erkan G, Radev DR. Lexrank: graph-based lexical centrality as salience in text summarization. J Artif Intell Res. \n2004;22:457\u201379.\n 12. Radev D, Allison T, Blair-Goldensohn S, Blitzer J, Celebi A, Drabek E, Lam W, Liu D, Otterbacher J, Qi H, Saggion H, \nTeufel S, Topper M, Winkel A, Zhang Z. MEAD\u2014a platform for multidocument multilingual text summarization, \nProceedings of the 4th International Conference on Language Resources and Evaluation, 2004, pp. 699\u2013702.\n 13. Dunlavy DM, O\u2019Leary DP , Conroy JM, et al. QCS: a system for querying, clustering and summarizing documents. Info \nProcess Manag. 2007;43(6):1588\u2013605.\n 14. Saggion H, Poibeau T. Automatic text summarization: past, present and future. In: Multi-source, multilingual infor -\nmation extraction and summarization. Springer, Berlin, Heidelberg; 2013. p. 3\u201321.\n 15. Liu X, Webster JJ, Kit C. An extractive text summarizer based on significant words. In: Proceedings of the 22nd inter -\nnational conference on computer processing of oriental languages, language technology for the knowledge-based \neconomy, Springer; 2009. pp 168\u2013178.\n 16. Tonelli S, Pianta E. Matching documents and summaries using key concepts. In: Proceedings of the French text min-\ning evaluation workshop. 2011.\n 17. Ko Y, Seo J. An effective sentence-extraction technique using contextual information and statistical approaches for \ntext summarization. Pattern Recognit Lett. 2008;29:1366\u201371. https:// doi. org/ 10. 1016/j. patrec. 2008. 02. 008.\n 18. Baralis E, Cagliero L, Mahoto N, Fiori A. GRAPHSUM: discovering correlations among multiple terms for graph-based \nsummarization. Inf Sci. 2013;249:96\u2013109. https:// doi. org/ 10. 1016/j. ins. 2013. 06. 046.\n 19. Parveen D, Strube M. Integrating importance, non-redundancy and coherence in graph-based extractive summari-\nzation. In: Proceedings of the 24th international conference on artificial intelligence. AAAIPress; 2015. pp 1298\u20131304.\n 20. Durrett G, Berg-Kirkpatrick T, Klein D. Learning-based single-document summarization with compression and \nanaphoricity constraints. In Proceedings of the 54th annual meeting of the association for computational linguistics, \nVolume 1: Long Papers; 2016. pp. 1998\u20132008.\n 21. Alguliev RM, Aliguliyev RM, Hajirahimova MS, Mehdiyev CA. MCMR: maximum coverage and minimum redundant \ntext summarization model. Expert Syst Appl. 2011;38:14514\u201322. https:// doi. org/ 10. 1016/j. eswa. 2011. 05. 033.\n 22. Lin H, Bilmes J. Multi-document summarization via budgeted maximization of submodular functions. In: Human \nlanguage technologies: the 2010 annual conference of the North American chapter of the association for computa-\ntional linguistics, Association for Computational Linguistics, 2010. pp 912\u2013920.\n 23. Yao JG, Wan X, Xiao J. Phrase-based compressive cross-language summarization. In: Proceedings ofthe 2015 confer -\nence on empirical methods in natural language processing; 2015. pp 118\u2013127.\n 24. Plaza L. Uso de Grafos Sem\u00e1nticos en la Generaci\u00f3n Autom\u00e1tica de Res\u00famenes y Estudio de su Aplicaci\u00f3n en Distin-\ntos Dominios: Biomedicina, Periodismo y Turismo, PhD thesis, 2011.\n 25. Belz A. Automatic generation of weather forecast texts using comprehensive probabilistic generation-space mod-\nels. Nat Lang Eng. 2008;14(4):431\u201355.\n 26. Mohammad S, Dorr B, Egan M, Hassan A, Muthukrishan P , Qazvinian V, Radev D, Zajic D. Using citations to generate \nsurveys of scientific paradigms, Proceedings of the North American Chapter of the Association of Computational \nLinguistics, 2009, pp. 584\u2013592.\n 27. Erera S, Shmueli-Scheuer M, Feigenblat G, Nakash OP , Boni O, Roitman H, et al. A summarization system for scientific \ndocuments. In Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the \nPage 33 of 34\n Alami\u00a0Merrouni\u00a0et\u00a0al. Journal of Big Data          (2023) 10:163 \n \n9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP): System Demonstrations, 2019, \npp. 211\u2013216.\n 28. Barzilay R, McKeown KR. Sentence fusion for multidocument news summarization. Comput Linguist. \n2005;31(3):297\u2013328.\n 29. Filippova K, Strube M. Sentence fusion via dependency graph compression. In Proceedings of the 2008 conference \non empirical methods in natural language processing, Honolulu, Hawaii, October; 2008. Association for Computa-\ntional Linguistics. pp 177\u2013185.\n 30. Filippova K. Multi-sentence compression: finding shortest paths in word graphs. In: Proceedings of the 23rd interna-\ntional conference on computational linguistics. Association for Computational Linguistics, 2010. p. 322\u2013330.\n 31. Mahajani A, Pandya V, Maria I, Sharma D. A comprehensive survey on extractive and abstractive techniques for text \nsummarization. Paper presented at the Ambient Communications and Computer Systems, Singapore. 2019.\n 32. Boudin F, Morin E. Keyphrase extraction for n-best reranking in multi-sentence compression. In Proceedings of the \n2013 conference of the North American chapter of the association for computational linguistics: human language \ntechnologies, Atlanta, Georgia, June. Association for Computational Linguistics. 2013. pp 298\u2013305.\n 33. Banerjee S, Mitra P , Sugiyama K. Multi-document abstractive summarization using ilp based multi-sentence com-\npression. In Proceedings of the 24th International Conference on Artificial Intelligence, IJCAI\u201915. 2015. p. 1208\u20131214. \nAAAI Press.\n 34. Nayeem MT, Fuad TA, Chali Y. Abstractive unsupervised multi-document summarization using paraphrastic \nsentence fusion. In: Proceedings of the 27th International Conference on Computational Linguistics. 2018. p. \n1191\u20131204.\n 35. Shang G, Ding W, Zhang Z, Tixier AJP , Meladianos P , Vazirgiannis M, Lorr\u00e9 JP . Unsupervised abstractive meeting sum-\nmarization with multi-sentence compression and budgeted submodular maximization. In ACL (1). 2018.\n 36. Chen YC, Bansal M. Fast abstractive summarization with reinforce-selected sentence rewriting. In Proceedings of the \n56th Annual Meeting of the Association for Computational Linguistics, Vol. 1: Long Papers, 2018. pp. 675\u2013686.\n 37. Di Fabbrizio G, Stent A, Gaizauskas R. A hybrid approach to multi-document summarization of opinions in reviews. \nIn: Proceedings of the 8th International Natural Language Generation Conference (INLG). 2014. p. 54\u201363.\n 38. Lloret E, Rom\u00e1-Ferri MT, Palomar M. COMPENDIUM: a text summarization system for generating abstracts of \nresearch papers. Data Knowl Eng. 2013;88:164\u201375.\n 39. Bhat IK, Mohd M, Hashmy R. SumItUp: a hybrid single-document text summarizer. In Pant M, Ray K, Sharma TK, \nRawat S, Bandyopadhyay A (eds.) Soft computing: theories and applications: proceedings of SoCTA 2016, Vol. 1. \nSingapore: Springer Singapore; 2018. pp. 619\u2013634.\n 40. De Marneffe MC, MacCartney B, Manning CD, et al. Generating typed dependency parses from phrase structure \nparses. In: Lrec, 2006;6:449\u2013454.\n 41. Glickman O. Applied textual entailment challenge. Ph.D. thesis, Bar Ilan University. 2005.\n 42. Tatar D, Mihis AD, Lupsa D. Text entailment for logical segmentation and summarization. Proceedings of the 13th \nInternational Conference on Applications of Natural Language to Information Systems, Lecture Notes in Computer \nScience, vol. 5039, Springer, 2008, pp. 233\u2013244.\n 43. Parikh A, T\u00e4ckstr\u00f6m O, Das D, Uszkoreit J. A decomposable attention model for natural language inference. In Pro -\nceedings of the 2016 conference on empirical methods in natural language processing; 2016. pp. 2249\u20132255.\n 44. Pasunuru R, Bansal M. Multi-reward reinforced summarization with saliency and entailment. In Proceedings of the \n2018 Conference of the North American chapter of the association for computational linguistics: human language \ntechnologies, Vol. 2 (Short Papers); 2018. pp. 646\u2013653.\n 45. Lloret E, Palomar M. A gradual combination of features for building automatic summarization systems. In Proceed-\nings of the 12th international conference on text. Speech and dialogue. Berlin, Heidelberg: Springer-Verlag; 2009. \npp. 16\u201323.\n 46. Ferr\u00e1ndez \u00b4O. Textual entailment recognition and its applicability in NLP tasks. PhD thesis, University of Alicante; \n2009.\n 47. Edmundson HP . New methods in automatic extracting. J ACM. 1969;16(2):264\u201385.\n 48. Ferreira R, de Souza Cabral L, Lins RD, Pereira e Silva G, Freitas F, Cavalcanti GD, et al. Assessing sentence scoring \ntechniques for extractive text summarization. Expert Syst Appl. 2013;40(14):5755\u201364.\n 49. Ouyang Y, Li W, Lu Q, Zhang R. A study on position information in document summarization. In Proceedings of the \n23rd international conference on computational linguistics: Posters. COLING \u201910. Stroudsburg, PA, USA: Association \nfor Computational Linguistics; 2010. pp. 919\u2013927.\n 50. Abuobieda A, Salim N, Albaham AT, Osman AH, Kumar YJ. Text summarization features selection method using \npseudo genetic-based model. In Proceedings of the international conference on information retrieval & knowledge \nmanagement. 2012. pp. 193\u2013197.\n 51. Fattah MA, Ren F. GA, MR, FFNN, PNN and GMM based models for automatic text summarization. Comput Speech \nLang. 2009;23(1):126\u201344.\n 52. Li Y, Luo C, Chung SM. Text clustering with feature selection by using statistical data knowledge and data engineer -\ning. IEEE Trans Knowl Data Eng. 2008;20(5):641\u201351.\n 53. Benghabrit A, Ouhbi B, Frikh B, Behja H. Text clustering using statistical and semantic data. In Proceedings of the \n2013 World Congress on Computer and Information Technologies, 2013, 1\u20136.\n 54. Oliveira H, Ferreira R, Lima R, Lins RD, Freitas F, Riss M, Simske SJ. Assessing shallow sentence scoring techniques and \ncombinations for single and multi-document summarization. Expert Syst Appl. 2016;65:68\u201386.\n 55. Merrouni ZA, Frikh B, Ouhbi B. Automatic keyphrase extraction: a survey and trends. J Intell Inf Syst. 2019; p. 1\u201334. \nSpringer.\n 56. Wan X, Xiao J. Collabrank: towards a collaborative approach to single-document keyphrase extraction. In Proceed-\nings of the 22nd International Conference on Computational Linguistics (Coling 2008), pages 969\u2013976, Manchester, \nUK, August. Coling 2008 Organizing Committee.\n 57. Mihalcea R, Tarau P . Textrank: bringing order into texts. In Dekang Lin and Dekai Wu, editors, Proceedings of EMNLP \n2004, pages 404\u2013411, Barcelona, Spain, July. Association for Computational Linguistics. 2004.\nPage 34 of 34 Alami\u00a0Merrouni\u00a0et\u00a0al. Journal of Big Data          (2023) 10:163 \n 58. Lins RD, Oliveira H, Cabral L, Batista J, Tenorio B, Ferreira R, et al. The cnn-corpus: a large textual corpus for single-\ndocument extractive summarization. In Proceedings of the ACM Symposium on Document Engineering 2019. 2019, \npp. 1\u201310.\n 59. Lins RD, Ferreira R, Simske SJ. DocEng\u201919 Competition on Extractive Text Summarization. In Proceedings of the 2019 \nACM Symposium on Document Engineering (DocEng \u201919). ACM, New York, NY, USA, 2019. pp 216\u2013217. https:// doi. \norg/ 10. 1145/ 33425 58. 33518 74\n 60. Lin CY. Rouge: A package for automatic evaluation of summaries. In Text summarization branches out, 2004. pp. \n74\u201381.\n 61. Lin C-Y, Hovy E. Automatic evaluation of summaries using n-gram co-occurrence statistics. In: Proceedings of the \n2003 Human Language Technology Conference of the North American Chapter of the Association for Computa-\ntional Linguistics. 2003. p. 150\u2013157.\n 62. Ferr\u00e1ndez O, Micol D, Mu\u00f1oz R, Palomar M. A perspective-based approach for solving textual entailment recogni-\ntion. Proceedings of the ACL-PASCAL Workshop on Textual Entailment and Paraphrasing, 2007, pp. 66\u201371.\n 63. Cao Z, Li W, Li S, Wei F. Improving multi-document summarization via text classification. In Thirty-First AAAI Confer -\nence on Artificial Intelligence. 2017.\n 64. Autosummarizer. 2015. Retrieved from http:// autos ummar  izer. com/.\n 65. Batista J, Ferreira R, Tomaz H, Ferreira R, Dueire Lins R, Simske S. A quantitative and qualitative assessment of auto -\nmatic text summarization systems. In Proceedings of the 2015 ACM Symposium on Document Engineering, 2015. \npp. 65\u201368.\n 66. Classifier4J. 2005. Retrieved from http:// class ifier 4j. sourc eforge. net/.\n 67. Wan X. Towards a unified approach to simultaneous single-document and multi-document summarizations. In \nProceedings of the 23rd international conference on computational linguistics (Coling 2010), pp. 1137\u20131145.\n 68. Song W, Choi LC, Park SC, Ding XF. Fuzzy evolutionary optimization modeling and its applications to unsupervised \ncategorization and extractive summarization. Expert Syst Appl. 2011;38(8):9112\u201321.\n 69. Svore K, Vanderwende L, Burges C. Enhancing single-document summarization by combining RankNet and third-\nparty sources. In Proceedings of the 2007 joint conference on empirical methods in natural language processing \nand computational natural language learning (EMNLP-CoNLL), 2007. pp. 448\u2013457.\n 70. Ferreira R, de Freitas FLG, de Souza Cabral L, Lins RD, Lima R, de Fran\u00e7a Pereira e Silva G, et al. A context-based text \nsummarization system. In Proceedings of the 11th international workshop on document analysis systems (das), \n2014. pp. 66\u201370.\n 71. See A, Liu PJ, Manning CD. Get to the point: summarization with pointer-generator networks. In Proceedings of the \n55th Annual Meeting of the Association for Computational Linguistics, Vol. 1: Long Papers; 2017. pp. 1073\u20131083.\nPublisher\u2019s Note\nSpringer Nature remains neutral with regard to jurisdictional claims in published maps and institutional affiliations.",
  "keywords": [
    "summarizers",
    "summarizations",
    "summarizationa",
    "summarization",
    "summarizer",
    "summarizing",
    "summaries",
    "summariesextractive",
    "summariza",
    "textrank"
  ],
  "intent_category": "summarization",
  "named_entities": [
    {
      "text": "2023",
      "label": "DATE"
    },
    {
      "text": "a Creative Commons Attribution 4.0 International License",
      "label": "ORG"
    },
    {
      "text": "Creative Commons",
      "label": "ORG"
    },
    {
      "text": "third",
      "label": "ORDINAL"
    },
    {
      "text": "Creative Commons",
      "label": "ORG"
    },
    {
      "text": "by/4",
      "label": "PRODUCT"
    },
    {
      "text": "Merrouni",
      "label": "PERSON"
    },
    {
      "text": "2023",
      "label": "DATE"
    },
    {
      "text": "10:163",
      "label": "CARDINAL"
    },
    {
      "text": "Big Data\nEXABSUM",
      "label": "ORG"
    },
    {
      "text": "Zakariae Alami",
      "label": "PERSON"
    },
    {
      "text": "Bouchra",
      "label": "GPE"
    },
    {
      "text": "Brahim",
      "label": "ORG"
    },
    {
      "text": "Automatic Text Summarization",
      "label": "ORG"
    },
    {
      "text": "two",
      "label": "CARDINAL"
    },
    {
      "text": "two",
      "label": "CARDINAL"
    },
    {
      "text": "1",
      "label": "CARDINAL"
    },
    {
      "text": "EXABSUMExtractive",
      "label": "NORP"
    },
    {
      "text": "2",
      "label": "CARDINAL"
    },
    {
      "text": "EXABSUM",
      "label": "ORG"
    },
    {
      "text": "Keyphrase",
      "label": "ORG"
    },
    {
      "text": "the 1950s",
      "label": "DATE"
    },
    {
      "text": "NLP",
      "label": "ORG"
    },
    {
      "text": "two",
      "label": "CARDINAL"
    },
    {
      "text": "1",
      "label": "CARDINAL"
    },
    {
      "text": "3",
      "label": "CARDINAL"
    },
    {
      "text": "three",
      "label": "CARDINAL"
    },
    {
      "text": "1",
      "label": "CARDINAL"
    },
    {
      "text": "National School",
      "label": "ORG"
    },
    {
      "text": "Applied Sciences",
      "label": "ORG"
    },
    {
      "text": "Sidi",
      "label": "PERSON"
    },
    {
      "text": "Mohamed Ben Abdellah University",
      "label": "PERSON"
    },
    {
      "text": "B.P",
      "label": "ORG"
    },
    {
      "text": "72",
      "label": "DATE"
    },
    {
      "text": "Route d\u2019imouzer",
      "label": "ORG"
    },
    {
      "text": "Fez",
      "label": "PERSON"
    },
    {
      "text": "Morocco",
      "label": "GPE"
    },
    {
      "text": "2",
      "label": "CARDINAL"
    },
    {
      "text": "Computer Laboratory",
      "label": "ORG"
    },
    {
      "text": "LM2I",
      "label": "ORG"
    },
    {
      "text": "National Higher School of Arts",
      "label": "ORG"
    },
    {
      "text": "Crafts",
      "label": "ORG"
    },
    {
      "text": "ENSAM",
      "label": "ORG"
    },
    {
      "text": "Moulay Ismail \nUniversity",
      "label": "PERSON"
    },
    {
      "text": "UMI",
      "label": "ORG"
    },
    {
      "text": "Marjane II",
      "label": "EVENT"
    },
    {
      "text": "B.P",
      "label": "GPE"
    },
    {
      "text": "4024",
      "label": "DATE"
    },
    {
      "text": "Morocco",
      "label": "GPE"
    },
    {
      "text": "2",
      "label": "CARDINAL"
    },
    {
      "text": "34",
      "label": "CARDINAL"
    },
    {
      "text": "Alami",
      "label": "PERSON"
    },
    {
      "text": "2023",
      "label": "DATE"
    },
    {
      "text": "10:163",
      "label": "CARDINAL"
    },
    {
      "text": "4",
      "label": "CARDINAL"
    },
    {
      "text": "6",
      "label": "CARDINAL"
    },
    {
      "text": "\u2022 Subsequently",
      "label": "ORG"
    },
    {
      "text": "third",
      "label": "ORDINAL"
    },
    {
      "text": "Automatic Text Summarization",
      "label": "ORG"
    },
    {
      "text": "EXABSUM",
      "label": "ORG"
    },
    {
      "text": "two",
      "label": "CARDINAL"
    },
    {
      "text": "Firstly",
      "label": "ORDINAL"
    },
    {
      "text": "EXABSUMExtractive",
      "label": "NORP"
    },
    {
      "text": "\u2022 Unlike",
      "label": "ORG"
    },
    {
      "text": "Semantic",
      "label": "ORG"
    },
    {
      "text": "3",
      "label": "CARDINAL"
    },
    {
      "text": "34",
      "label": "CARDINAL"
    },
    {
      "text": "2023",
      "label": "DATE"
    },
    {
      "text": "10:163",
      "label": "CARDINAL"
    },
    {
      "text": "ATS",
      "label": "ORG"
    },
    {
      "text": "EXABSUM",
      "label": "ORG"
    },
    {
      "text": "EXABSUM",
      "label": "ORG"
    },
    {
      "text": "two",
      "label": "CARDINAL"
    },
    {
      "text": "three",
      "label": "CARDINAL"
    },
    {
      "text": "5",
      "label": "CARDINAL"
    },
    {
      "text": "1",
      "label": "CARDINAL"
    },
    {
      "text": "2",
      "label": "CARDINAL"
    },
    {
      "text": "1",
      "label": "CARDINAL"
    },
    {
      "text": "2",
      "label": "CARDINAL"
    },
    {
      "text": "3",
      "label": "CARDINAL"
    },
    {
      "text": "4",
      "label": "CARDINAL"
    },
    {
      "text": "first",
      "label": "ORDINAL"
    },
    {
      "text": "7\u201310",
      "label": "CARDINAL"
    },
    {
      "text": "One",
      "label": "CARDINAL"
    },
    {
      "text": "11",
      "label": "CARDINAL"
    },
    {
      "text": "12",
      "label": "CARDINAL"
    },
    {
      "text": "English",
      "label": "LANGUAGE"
    },
    {
      "text": "Chinese",
      "label": "NORP"
    },
    {
      "text": "4",
      "label": "CARDINAL"
    },
    {
      "text": "34",
      "label": "CARDINAL"
    },
    {
      "text": "Alami",
      "label": "PERSON"
    },
    {
      "text": "2023",
      "label": "DATE"
    },
    {
      "text": "10:163",
      "label": "CARDINAL"
    },
    {
      "text": "QCS",
      "label": "ORG"
    },
    {
      "text": "13",
      "label": "CARDINAL"
    },
    {
      "text": "Markov",
      "label": "PERSON"
    },
    {
      "text": "14",
      "label": "CARDINAL"
    },
    {
      "text": "TF",
      "label": "ORG"
    },
    {
      "text": "1",
      "label": "CARDINAL"
    },
    {
      "text": "15",
      "label": "DATE"
    },
    {
      "text": "16",
      "label": "CARDINAL"
    },
    {
      "text": "Ko",
      "label": "PERSON"
    },
    {
      "text": "Seo",
      "label": "PERSON"
    },
    {
      "text": "17",
      "label": "CARDINAL"
    },
    {
      "text": "7",
      "label": "CARDINAL"
    },
    {
      "text": "GRAPHSUM",
      "label": "ORG"
    },
    {
      "text": "Baralis",
      "label": "PERSON"
    },
    {
      "text": "al",
      "label": "PERSON"
    },
    {
      "text": "18",
      "label": "CARDINAL"
    },
    {
      "text": "Parveen",
      "label": "DATE"
    },
    {
      "text": "19",
      "label": "CARDINAL"
    },
    {
      "text": "three",
      "label": "CARDINAL"
    },
    {
      "text": "20",
      "label": "CARDINAL"
    },
    {
      "text": "integer linear",
      "label": "ORG"
    },
    {
      "text": "21",
      "label": "CARDINAL"
    },
    {
      "text": "22",
      "label": "CARDINAL"
    },
    {
      "text": "23",
      "label": "CARDINAL"
    },
    {
      "text": "ATS",
      "label": "ORG"
    },
    {
      "text": "SummGraph",
      "label": "ORG"
    },
    {
      "text": "24",
      "label": "CARDINAL"
    },
    {
      "text": "Natural Language Genera",
      "label": "FAC"
    },
    {
      "text": "25",
      "label": "CARDINAL"
    },
    {
      "text": "Mohammad",
      "label": "PERSON"
    },
    {
      "text": "26",
      "label": "CARDINAL"
    },
    {
      "text": "Erera",
      "label": "PERSON"
    },
    {
      "text": "al",
      "label": "PERSON"
    },
    {
      "text": "27",
      "label": "CARDINAL"
    },
    {
      "text": "Science Summarizer",
      "label": "PERSON"
    },
    {
      "text": "Computer Science",
      "label": "ORG"
    },
    {
      "text": "Machine Translation",
      "label": "WORK_OF_ART"
    },
    {
      "text": "ATS",
      "label": "ORG"
    },
    {
      "text": "28",
      "label": "CARDINAL"
    },
    {
      "text": "5",
      "label": "CARDINAL"
    },
    {
      "text": "34",
      "label": "CARDINAL"
    },
    {
      "text": "2023",
      "label": "DATE"
    },
    {
      "text": "10:163",
      "label": "CARDINAL"
    },
    {
      "text": "Filippova",
      "label": "PERSON"
    },
    {
      "text": "Strube",
      "label": "GPE"
    },
    {
      "text": "29",
      "label": "CARDINAL"
    },
    {
      "text": "Filippova",
      "label": "PERSON"
    },
    {
      "text": "30",
      "label": "CARDINAL"
    },
    {
      "text": "4",
      "label": "CARDINAL"
    },
    {
      "text": "31",
      "label": "CARDINAL"
    },
    {
      "text": "Boudin",
      "label": "ORG"
    },
    {
      "text": "32",
      "label": "CARDINAL"
    },
    {
      "text": "Filippova",
      "label": "PERSON"
    },
    {
      "text": "Multi-Sentence Compression",
      "label": "ORG"
    },
    {
      "text": "MSC",
      "label": "ORG"
    },
    {
      "text": "33",
      "label": "CARDINAL"
    },
    {
      "text": "Integer Linear Programming",
      "label": "ORG"
    },
    {
      "text": "ILP",
      "label": "ORG"
    },
    {
      "text": "ILP",
      "label": "ORG"
    },
    {
      "text": "34",
      "label": "CARDINAL"
    },
    {
      "text": "Shang",
      "label": "PERSON"
    },
    {
      "text": "al",
      "label": "PERSON"
    },
    {
      "text": "35",
      "label": "CARDINAL"
    },
    {
      "text": "six",
      "label": "CARDINAL"
    },
    {
      "text": "three",
      "label": "CARDINAL"
    },
    {
      "text": "four",
      "label": "CARDINAL"
    },
    {
      "text": "NLP",
      "label": "ORG"
    },
    {
      "text": "36",
      "label": "CARDINAL"
    },
    {
      "text": "Di Fabbrizio",
      "label": "PERSON"
    },
    {
      "text": "al",
      "label": "PERSON"
    },
    {
      "text": "37",
      "label": "CARDINAL"
    },
    {
      "text": "and/or nega -\n",
      "label": "PERSON"
    },
    {
      "text": "ROM",
      "label": "ORG"
    },
    {
      "text": "38",
      "label": "CARDINAL"
    },
    {
      "text": "PENDIUM",
      "label": "ORG"
    },
    {
      "text": "two",
      "label": "CARDINAL"
    },
    {
      "text": "COMPENDIUM",
      "label": "ORG"
    },
    {
      "text": "6",
      "label": "CARDINAL"
    },
    {
      "text": "34",
      "label": "CARDINAL"
    },
    {
      "text": "Alami",
      "label": "PERSON"
    },
    {
      "text": "2023",
      "label": "DATE"
    },
    {
      "text": "10:163",
      "label": "CARDINAL"
    },
    {
      "text": "39",
      "label": "CARDINAL"
    },
    {
      "text": "two",
      "label": "CARDINAL"
    },
    {
      "text": "1",
      "label": "CARDINAL"
    },
    {
      "text": "Lesk algorithm",
      "label": "PERSON"
    },
    {
      "text": "two",
      "label": "CARDINAL"
    },
    {
      "text": "EXABSUM",
      "label": "ORG"
    },
    {
      "text": "two",
      "label": "CARDINAL"
    },
    {
      "text": "ATS",
      "label": "ORG"
    },
    {
      "text": "two",
      "label": "CARDINAL"
    },
    {
      "text": "first",
      "label": "ORDINAL"
    },
    {
      "text": "EXABSUMExtractive",
      "label": "NORP"
    },
    {
      "text": "EXABSUMExtractive",
      "label": "NORP"
    },
    {
      "text": "second",
      "label": "ORDINAL"
    },
    {
      "text": "EXABSUMExtractive",
      "label": "NORP"
    },
    {
      "text": "Subse -\n",
      "label": "PERSON"
    },
    {
      "text": "four",
      "label": "CARDINAL"
    },
    {
      "text": "Fig",
      "label": "PERSON"
    },
    {
      "text": "1",
      "label": "CARDINAL"
    },
    {
      "text": "First",
      "label": "ORDINAL"
    },
    {
      "text": "Fig",
      "label": "PERSON"
    },
    {
      "text": "1",
      "label": "CARDINAL"
    },
    {
      "text": "EXABSUMExtractive",
      "label": "NORP"
    },
    {
      "text": "34",
      "label": "CARDINAL"
    },
    {
      "text": "2023",
      "label": "DATE"
    },
    {
      "text": "10:163 \n \n",
      "label": "DATE"
    },
    {
      "text": "two",
      "label": "CARDINAL"
    },
    {
      "text": "\u2022 Tokenization",
      "label": "ORG"
    },
    {
      "text": "Bion;,;:,appR;aochAs",
      "label": "PERSON"
    },
    {
      "text": "NL",
      "label": "ORG"
    },
    {
      "text": "P a*nd I2r s",
      "label": "ORG"
    },
    {
      "text": "NLP",
      "label": "ORG"
    },
    {
      "text": "IR",
      "label": "ORG"
    },
    {
      "text": "Stanford",
      "label": "ORG"
    },
    {
      "text": "Stanford Core NLP",
      "label": "ORG"
    },
    {
      "text": "40",
      "label": "CARDINAL"
    },
    {
      "text": "8",
      "label": "CARDINAL"
    },
    {
      "text": "34",
      "label": "CARDINAL"
    },
    {
      "text": "Alami",
      "label": "PERSON"
    },
    {
      "text": "2023",
      "label": "DATE"
    },
    {
      "text": "10:163",
      "label": "CARDINAL"
    },
    {
      "text": "41",
      "label": "CARDINAL"
    },
    {
      "text": "TE",
      "label": "ORG"
    },
    {
      "text": "41",
      "label": "CARDINAL"
    },
    {
      "text": "TE",
      "label": "ORG"
    },
    {
      "text": "first",
      "label": "ORDINAL"
    },
    {
      "text": "second",
      "label": "ORDINAL"
    },
    {
      "text": "NLP",
      "label": "ORG"
    },
    {
      "text": "TE",
      "label": "ORG"
    },
    {
      "text": "42\u201344",
      "label": "CARDINAL"
    },
    {
      "text": "45",
      "label": "CARDINAL"
    },
    {
      "text": "TE",
      "label": "ORG"
    },
    {
      "text": "46",
      "label": "CARDINAL"
    },
    {
      "text": "TE",
      "label": "ORG"
    },
    {
      "text": "WordNet",
      "label": "ORG"
    },
    {
      "text": "10",
      "label": "CARDINAL"
    },
    {
      "text": "doc",
      "label": "ORG"
    },
    {
      "text": "47\u201351",
      "label": "CARDINAL"
    },
    {
      "text": "a. Term Relevance-Inverse",
      "label": "PERSON"
    },
    {
      "text": "TR-ISF",
      "label": "ORG"
    },
    {
      "text": "Informa",
      "label": "NORP"
    },
    {
      "text": "Retrieval IR",
      "label": "PERSON"
    },
    {
      "text": "ISF",
      "label": "ORG"
    },
    {
      "text": "9",
      "label": "CARDINAL"
    },
    {
      "text": "34",
      "label": "CARDINAL"
    },
    {
      "text": "2023",
      "label": "DATE"
    },
    {
      "text": "10:163",
      "label": "CARDINAL"
    },
    {
      "text": "a Hybrid Feature Selection Model",
      "label": "ORG"
    },
    {
      "text": "the TR-ISF Equation",
      "label": "ORG"
    },
    {
      "text": "12",
      "label": "CARDINAL"
    },
    {
      "text": "Eq",
      "label": "PERSON"
    },
    {
      "text": "13",
      "label": "CARDINAL"
    },
    {
      "text": "Li",
      "label": "PERSON"
    },
    {
      "text": "52",
      "label": "CARDINAL"
    },
    {
      "text": "Rw",
      "label": "PERSON"
    },
    {
      "text": "1",
      "label": "CARDINAL"
    },
    {
      "text": "\u03c72\nw",
      "label": "PERSON"
    },
    {
      "text": "Rw",
      "label": "PERSON"
    },
    {
      "text": "larger than 1",
      "label": "CARDINAL"
    },
    {
      "text": "Rw",
      "label": "PERSON"
    },
    {
      "text": "Li",
      "label": "PERSON"
    },
    {
      "text": "52",
      "label": "CARDINAL"
    },
    {
      "text": "Eqs",
      "label": "ORG"
    },
    {
      "text": "1",
      "label": "CARDINAL"
    },
    {
      "text": "2",
      "label": "CARDINAL"
    },
    {
      "text": "CHIR",
      "label": "ORG"
    },
    {
      "text": "\u03c72\nw",
      "label": "PERSON"
    },
    {
      "text": "Rw",
      "label": "PERSON"
    },
    {
      "text": "\u03c72\nw",
      "label": "PERSON"
    },
    {
      "text": "\u03c72\nw",
      "label": "PERSON"
    },
    {
      "text": "the Mutual Information",
      "label": "ORG"
    },
    {
      "text": "SIM",
      "label": "ORG"
    },
    {
      "text": "1",
      "label": "CARDINAL"
    },
    {
      "text": "2",
      "label": "CARDINAL"
    },
    {
      "text": "3",
      "label": "CARDINAL"
    },
    {
      "text": "10",
      "label": "CARDINAL"
    },
    {
      "text": "34",
      "label": "CARDINAL"
    },
    {
      "text": "Alami",
      "label": "PERSON"
    },
    {
      "text": "2023",
      "label": "DATE"
    },
    {
      "text": "10:163",
      "label": "CARDINAL"
    },
    {
      "text": "SIM",
      "label": "ORG"
    },
    {
      "text": "Mutual Information",
      "label": "ORG"
    },
    {
      "text": "8",
      "label": "CARDINAL"
    },
    {
      "text": "two",
      "label": "CARDINAL"
    },
    {
      "text": "8",
      "label": "CARDINAL"
    },
    {
      "text": "two",
      "label": "CARDINAL"
    },
    {
      "text": "P(zi",
      "label": "GPE"
    },
    {
      "text": "53",
      "label": "CARDINAL"
    },
    {
      "text": "doc",
      "label": "ORG"
    },
    {
      "text": "N",
      "label": "ORG"
    },
    {
      "text": "documents.(5",
      "label": "GPE"
    },
    {
      "text": "max",
      "label": "PERSON"
    },
    {
      "text": "I(w1,zi),I(w2,zi",
      "label": "NORP"
    },
    {
      "text": "max",
      "label": "PERSON"
    },
    {
      "text": "I(w1,zi),I(w2,zi",
      "label": "NORP"
    },
    {
      "text": "6) I(zi",
      "label": "DATE"
    },
    {
      "text": "1)/parenrightbigg",
      "label": "DATE"
    },
    {
      "text": "7",
      "label": "CARDINAL"
    },
    {
      "text": "SIM",
      "label": "ORG"
    },
    {
      "text": "d)=/summationtextx\nj=1sim(w",
      "label": "PERSON"
    },
    {
      "text": "8)",
      "label": "CARDINAL"
    },
    {
      "text": "w)=k/summationdisplay\nj=1P",
      "label": "ORG"
    },
    {
      "text": "SIM",
      "label": "ORG"
    },
    {
      "text": "11",
      "label": "CARDINAL"
    },
    {
      "text": "34",
      "label": "CARDINAL"
    },
    {
      "text": "2023",
      "label": "DATE"
    },
    {
      "text": "10:163",
      "label": "CARDINAL"
    },
    {
      "text": "dcen j)\u2248 P(w",
      "label": "PERSON"
    },
    {
      "text": "dcen j)\u2248",
      "label": "PERSON"
    },
    {
      "text": "SIM(w",
      "label": "PRODUCT"
    },
    {
      "text": "three",
      "label": "CARDINAL"
    },
    {
      "text": "1",
      "label": "CARDINAL"
    },
    {
      "text": "2",
      "label": "CARDINAL"
    },
    {
      "text": "3",
      "label": "CARDINAL"
    },
    {
      "text": "0.25",
      "label": "CARDINAL"
    },
    {
      "text": "Eq",
      "label": "GPE"
    },
    {
      "text": "12",
      "label": "CARDINAL"
    },
    {
      "text": "Eq",
      "label": "GPE"
    },
    {
      "text": "13",
      "label": "CARDINAL"
    },
    {
      "text": "term(word",
      "label": "GPE"
    },
    {
      "text": "Eq",
      "label": "PERSON"
    },
    {
      "text": "11",
      "label": "CARDINAL"
    },
    {
      "text": "\u2022 S",
      "label": "ORG"
    },
    {
      "text": "dcen j)=P(w",
      "label": "PERSON"
    },
    {
      "text": "j)log",
      "label": "PERSON"
    },
    {
      "text": "10",
      "label": "CARDINAL"
    },
    {
      "text": "11",
      "label": "CARDINAL"
    },
    {
      "text": "12",
      "label": "CARDINAL"
    },
    {
      "text": "13",
      "label": "CARDINAL"
    },
    {
      "text": "wi\u2208TTR\u2212ISF",
      "label": "PERSON"
    },
    {
      "text": "12",
      "label": "CARDINAL"
    },
    {
      "text": "34",
      "label": "CARDINAL"
    },
    {
      "text": "Alami",
      "label": "PERSON"
    },
    {
      "text": "2023",
      "label": "DATE"
    },
    {
      "text": "10:163",
      "label": "CARDINAL"
    },
    {
      "text": "Sentence",
      "label": "ORG"
    },
    {
      "text": "one",
      "label": "CARDINAL"
    },
    {
      "text": "fewer than ten",
      "label": "CARDINAL"
    },
    {
      "text": "more than 50",
      "label": "CARDINAL"
    },
    {
      "text": "Eq",
      "label": "GPE"
    },
    {
      "text": "15",
      "label": "CARDINAL"
    },
    {
      "text": "\u2022 Li",
      "label": "PERSON"
    },
    {
      "text": "|wt|",
      "label": "NORP"
    },
    {
      "text": "15",
      "label": "CARDINAL"
    },
    {
      "text": "SentenceLen",
      "label": "ORG"
    },
    {
      "text": "16",
      "label": "CARDINAL"
    },
    {
      "text": "13",
      "label": "CARDINAL"
    },
    {
      "text": "34",
      "label": "CARDINAL"
    },
    {
      "text": "2023",
      "label": "DATE"
    },
    {
      "text": "10:163",
      "label": "CARDINAL"
    },
    {
      "text": "zero",
      "label": "CARDINAL"
    },
    {
      "text": "\u2022 S",
      "label": "ORG"
    },
    {
      "text": "48",
      "label": "CARDINAL"
    },
    {
      "text": "54",
      "label": "CARDINAL"
    },
    {
      "text": "N",
      "label": "ORG"
    },
    {
      "text": "17",
      "label": "CARDINAL"
    },
    {
      "text": "SentPosition",
      "label": "ORG"
    },
    {
      "text": "2",
      "label": "CARDINAL"
    },
    {
      "text": "Page 14",
      "label": "ORG"
    },
    {
      "text": "34",
      "label": "CARDINAL"
    },
    {
      "text": "Alami",
      "label": "PERSON"
    },
    {
      "text": "2023",
      "label": "DATE"
    },
    {
      "text": "10:163",
      "label": "CARDINAL"
    },
    {
      "text": "Fig",
      "label": "PERSON"
    },
    {
      "text": "2",
      "label": "CARDINAL"
    },
    {
      "text": "30",
      "label": "CARDINAL"
    },
    {
      "text": "32",
      "label": "CARDINAL"
    },
    {
      "text": "two",
      "label": "CARDINAL"
    },
    {
      "text": "first",
      "label": "ORDINAL"
    },
    {
      "text": "3",
      "label": "CARDINAL"
    },
    {
      "text": "four",
      "label": "CARDINAL"
    },
    {
      "text": "1",
      "label": "CARDINAL"
    },
    {
      "text": "U.S.",
      "label": "GPE"
    },
    {
      "text": "Donald Trump",
      "label": "PERSON"
    },
    {
      "text": "Venezuela",
      "label": "GPE"
    },
    {
      "text": "last Thursday",
      "label": "DATE"
    },
    {
      "text": "2",
      "label": "CARDINAL"
    },
    {
      "text": "Donald Trump",
      "label": "PERSON"
    },
    {
      "text": "the People Republic of Venezuela",
      "label": "GPE"
    },
    {
      "text": "Thursday",
      "label": "DATE"
    },
    {
      "text": "3",
      "label": "CARDINAL"
    },
    {
      "text": "Last week",
      "label": "DATE"
    },
    {
      "text": "State",
      "label": "ORG"
    },
    {
      "text": "M. Trump",
      "label": "PERSON"
    },
    {
      "text": "Venezuela",
      "label": "GPE"
    },
    {
      "text": "4",
      "label": "CARDINAL"
    },
    {
      "text": "Donald Trump",
      "label": "PERSON"
    },
    {
      "text": "Venezuela",
      "label": "GPE"
    },
    {
      "text": "last month",
      "label": "DATE"
    },
    {
      "text": "Thursday",
      "label": "DATE"
    },
    {
      "text": "last week",
      "label": "DATE"
    },
    {
      "text": "Fig",
      "label": "PERSON"
    },
    {
      "text": "3",
      "label": "CARDINAL"
    },
    {
      "text": "1\u20134",
      "label": "CARDINAL"
    },
    {
      "text": "15",
      "label": "CARDINAL"
    },
    {
      "text": "34",
      "label": "CARDINAL"
    },
    {
      "text": "2023",
      "label": "DATE"
    },
    {
      "text": "10:163",
      "label": "CARDINAL"
    },
    {
      "text": "first",
      "label": "ORDINAL"
    },
    {
      "text": "Fig",
      "label": "PERSON"
    },
    {
      "text": "3",
      "label": "CARDINAL"
    },
    {
      "text": "two",
      "label": "CARDINAL"
    },
    {
      "text": "three",
      "label": "CARDINAL"
    },
    {
      "text": "second",
      "label": "ORDINAL"
    },
    {
      "text": "1",
      "label": "CARDINAL"
    },
    {
      "text": "2",
      "label": "CARDINAL"
    },
    {
      "text": "3",
      "label": "CARDINAL"
    },
    {
      "text": "two",
      "label": "CARDINAL"
    },
    {
      "text": "two",
      "label": "CARDINAL"
    },
    {
      "text": "Fig",
      "label": "PERSON"
    },
    {
      "text": "3",
      "label": "CARDINAL"
    },
    {
      "text": "3",
      "label": "CARDINAL"
    },
    {
      "text": "two",
      "label": "CARDINAL"
    },
    {
      "text": "node",
      "label": "GPE"
    },
    {
      "text": "NLTK",
      "label": "ORG"
    },
    {
      "text": "Thursday",
      "label": "DATE"
    },
    {
      "text": "Filippova",
      "label": "PERSON"
    },
    {
      "text": "Boudin and Morin",
      "label": "ORG"
    },
    {
      "text": "32",
      "label": "CARDINAL"
    },
    {
      "text": "fourth",
      "label": "ORDINAL"
    },
    {
      "text": "Eq",
      "label": "GPE"
    },
    {
      "text": "18",
      "label": "CARDINAL"
    },
    {
      "text": "18",
      "label": "CARDINAL"
    },
    {
      "text": "19",
      "label": "CARDINAL"
    },
    {
      "text": "i)+freq",
      "label": "PERSON"
    },
    {
      "text": "16",
      "label": "CARDINAL"
    },
    {
      "text": "34",
      "label": "CARDINAL"
    },
    {
      "text": "Alami",
      "label": "PERSON"
    },
    {
      "text": "2023",
      "label": "DATE"
    },
    {
      "text": "10:163",
      "label": "CARDINAL"
    },
    {
      "text": "d(s",
      "label": "PERSON"
    },
    {
      "text": "two",
      "label": "CARDINAL"
    },
    {
      "text": "1",
      "label": "CARDINAL"
    },
    {
      "text": "Eq",
      "label": "PERSON"
    },
    {
      "text": "19",
      "label": "CARDINAL"
    },
    {
      "text": "2",
      "label": "CARDINAL"
    },
    {
      "text": "Eq",
      "label": "PERSON"
    },
    {
      "text": "20",
      "label": "CARDINAL"
    },
    {
      "text": "less than eight",
      "label": "CARDINAL"
    },
    {
      "text": "first",
      "label": "ORDINAL"
    },
    {
      "text": "at least one",
      "label": "CARDINAL"
    },
    {
      "text": "at least three",
      "label": "CARDINAL"
    },
    {
      "text": "Filippova",
      "label": "ORG"
    },
    {
      "text": "48 to 60%",
      "label": "PERCENT"
    },
    {
      "text": "30",
      "label": "CARDINAL"
    },
    {
      "text": "55",
      "label": "CARDINAL"
    },
    {
      "text": "17",
      "label": "CARDINAL"
    },
    {
      "text": "34",
      "label": "CARDINAL"
    },
    {
      "text": "2023",
      "label": "DATE"
    },
    {
      "text": "10:163",
      "label": "CARDINAL"
    },
    {
      "text": "three",
      "label": "CARDINAL"
    },
    {
      "text": "1",
      "label": "CARDINAL"
    },
    {
      "text": "2",
      "label": "CARDINAL"
    },
    {
      "text": "3",
      "label": "CARDINAL"
    },
    {
      "text": "Wan",
      "label": "PERSON"
    },
    {
      "text": "Xiao",
      "label": "PERSON"
    },
    {
      "text": "56",
      "label": "CARDINAL"
    },
    {
      "text": "two",
      "label": "CARDINAL"
    },
    {
      "text": "TextRank",
      "label": "PRODUCT"
    },
    {
      "text": "57",
      "label": "CARDINAL"
    },
    {
      "text": "Vi",
      "label": "PERSON"
    },
    {
      "text": "0.85",
      "label": "CARDINAL"
    },
    {
      "text": "second",
      "label": "ORDINAL"
    },
    {
      "text": "NNS",
      "label": "ORG"
    },
    {
      "text": "NNP",
      "label": "ORG"
    },
    {
      "text": "NNPS",
      "label": "ORG"
    },
    {
      "text": "VBN",
      "label": "ORG"
    },
    {
      "text": "NNS",
      "label": "ORG"
    },
    {
      "text": "NNP",
      "label": "ORG"
    },
    {
      "text": "NNPS",
      "label": "ORG"
    },
    {
      "text": "VBG",
      "label": "ORG"
    },
    {
      "text": "VBG",
      "label": "ORG"
    },
    {
      "text": "VBG",
      "label": "ORG"
    },
    {
      "text": "informa",
      "label": "NORP"
    },
    {
      "text": "20)(Vi)=1\u2212d",
      "label": "CARDINAL"
    },
    {
      "text": "Vj\u2208adj(Vi)Wji",
      "label": "GPE"
    },
    {
      "text": "18",
      "label": "CARDINAL"
    },
    {
      "text": "34",
      "label": "CARDINAL"
    },
    {
      "text": "Alami",
      "label": "PERSON"
    },
    {
      "text": "2023",
      "label": "DATE"
    },
    {
      "text": "10:163",
      "label": "CARDINAL"
    },
    {
      "text": "keyphrase k",
      "label": "PERSON"
    },
    {
      "text": "1",
      "label": "CARDINAL"
    },
    {
      "text": "Eq",
      "label": "PERSON"
    },
    {
      "text": "21",
      "label": "DATE"
    },
    {
      "text": "Eq",
      "label": "GPE"
    },
    {
      "text": "18",
      "label": "DATE"
    },
    {
      "text": "EXABSUM",
      "label": "ORG"
    },
    {
      "text": "2.0",
      "label": "CARDINAL"
    },
    {
      "text": "21",
      "label": "CARDINAL"
    },
    {
      "text": "k)=/summationtext",
      "label": "PERSON"
    },
    {
      "text": "w\u2208kTextRank",
      "label": "PERSON"
    },
    {
      "text": "23",
      "label": "CARDINAL"
    },
    {
      "text": "19",
      "label": "CARDINAL"
    },
    {
      "text": "34",
      "label": "CARDINAL"
    },
    {
      "text": "2023",
      "label": "DATE"
    },
    {
      "text": "10:163",
      "label": "CARDINAL"
    },
    {
      "text": "EXABSUM",
      "label": "ORG"
    },
    {
      "text": "EXABSUM",
      "label": "ORG"
    },
    {
      "text": "DUC",
      "label": "ORG"
    },
    {
      "text": "2001",
      "label": "DATE"
    },
    {
      "text": "DUC",
      "label": "ORG"
    },
    {
      "text": "2002",
      "label": "DATE"
    },
    {
      "text": "the Document Understanding Collection",
      "label": "ORG"
    },
    {
      "text": "DUC",
      "label": "ORG"
    },
    {
      "text": "Text Analytics \nConferences",
      "label": "ORG"
    },
    {
      "text": "TAC",
      "label": "ORG"
    },
    {
      "text": "DUC",
      "label": "PERSON"
    },
    {
      "text": "2001",
      "label": "DATE"
    },
    {
      "text": "309",
      "label": "CARDINAL"
    },
    {
      "text": "English",
      "label": "NORP"
    },
    {
      "text": "two",
      "label": "CARDINAL"
    },
    {
      "text": "DUC",
      "label": "ORG"
    },
    {
      "text": "2002",
      "label": "DATE"
    },
    {
      "text": "567",
      "label": "CARDINAL"
    },
    {
      "text": "English",
      "label": "LANGUAGE"
    },
    {
      "text": "two",
      "label": "CARDINAL"
    },
    {
      "text": "approximately 100",
      "label": "CARDINAL"
    },
    {
      "text": "DUC",
      "label": "ORG"
    },
    {
      "text": "DUC",
      "label": "ORG"
    },
    {
      "text": "DUC 2002",
      "label": "ORG"
    },
    {
      "text": "about 60%",
      "label": "PERCENT"
    },
    {
      "text": "DUC",
      "label": "ORG"
    },
    {
      "text": "approximately 100",
      "label": "CARDINAL"
    },
    {
      "text": "CNN Corpus",
      "label": "PERSON"
    },
    {
      "text": "58",
      "label": "CARDINAL"
    },
    {
      "text": "CNN",
      "label": "ORG"
    },
    {
      "text": "cnn",
      "label": "ORG"
    },
    {
      "text": "3,000",
      "label": "CARDINAL"
    },
    {
      "text": "English",
      "label": "LANGUAGE"
    },
    {
      "text": "twelve",
      "label": "CARDINAL"
    },
    {
      "text": "CNN",
      "label": "ORG"
    },
    {
      "text": "Business, Opinion, Politics",
      "label": "ORG"
    },
    {
      "text": "Living, Sports",
      "label": "ORG"
    },
    {
      "text": "World News, Technology",
      "label": "ORG"
    },
    {
      "text": "United States",
      "label": "GPE"
    },
    {
      "text": "Travel",
      "label": "ORG"
    },
    {
      "text": "CNN",
      "label": "ORG"
    },
    {
      "text": "90 to 100",
      "label": "CARDINAL"
    },
    {
      "text": "approximately 10,754",
      "label": "CARDINAL"
    },
    {
      "text": "around 10%",
      "label": "PERCENT"
    },
    {
      "text": "3,000",
      "label": "CARDINAL"
    },
    {
      "text": "CNN",
      "label": "ORG"
    },
    {
      "text": "CNN",
      "label": "ORG"
    },
    {
      "text": "CNN",
      "label": "ORG"
    },
    {
      "text": "58",
      "label": "DATE"
    },
    {
      "text": "59",
      "label": "CARDINAL"
    },
    {
      "text": "1",
      "label": "CARDINAL"
    },
    {
      "text": "20",
      "label": "CARDINAL"
    },
    {
      "text": "34",
      "label": "CARDINAL"
    },
    {
      "text": "Alami",
      "label": "PERSON"
    },
    {
      "text": "2023",
      "label": "DATE"
    },
    {
      "text": "10:163",
      "label": "CARDINAL"
    },
    {
      "text": "two",
      "label": "CARDINAL"
    },
    {
      "text": "ROUGE-1",
      "label": "PERSON"
    },
    {
      "text": "ROUGE-2",
      "label": "PERSON"
    },
    {
      "text": "ROUGE",
      "label": "ORG"
    },
    {
      "text": "60",
      "label": "CARDINAL"
    },
    {
      "text": "61",
      "label": "CARDINAL"
    },
    {
      "text": "60",
      "label": "CARDINAL"
    },
    {
      "text": "61",
      "label": "CARDINAL"
    },
    {
      "text": "Lin",
      "label": "PERSON"
    },
    {
      "text": "60",
      "label": "CARDINAL"
    },
    {
      "text": "61",
      "label": "CARDINAL"
    },
    {
      "text": "ROUGE-SU4",
      "label": "ORG"
    },
    {
      "text": "four",
      "label": "CARDINAL"
    },
    {
      "text": "ROUGE",
      "label": "ORG"
    },
    {
      "text": "two",
      "label": "CARDINAL"
    },
    {
      "text": "60",
      "label": "CARDINAL"
    },
    {
      "text": "61].(24",
      "label": "CARDINAL"
    },
    {
      "text": "1",
      "label": "CARDINAL"
    },
    {
      "text": "CNN",
      "label": "ORG"
    },
    {
      "text": "DUC",
      "label": "ORG"
    },
    {
      "text": "Dataset",
      "label": "ORG"
    },
    {
      "text": "30",
      "label": "CARDINAL"
    },
    {
      "text": "309",
      "label": "CARDINAL"
    },
    {
      "text": "100",
      "label": "CARDINAL"
    },
    {
      "text": "59",
      "label": "CARDINAL"
    },
    {
      "text": "567 348,012",
      "label": "CARDINAL"
    },
    {
      "text": "CNN",
      "label": "ORG"
    },
    {
      "text": "0",
      "label": "CARDINAL"
    },
    {
      "text": "Multi-Domain",
      "label": "ORG"
    },
    {
      "text": "2000",
      "label": "DATE"
    },
    {
      "text": "90",
      "label": "CARDINAL"
    },
    {
      "text": "21",
      "label": "CARDINAL"
    },
    {
      "text": "34",
      "label": "CARDINAL"
    },
    {
      "text": "2023",
      "label": "DATE"
    },
    {
      "text": "10:163",
      "label": "CARDINAL"
    },
    {
      "text": "ten",
      "label": "CARDINAL"
    },
    {
      "text": "38",
      "label": "CARDINAL"
    },
    {
      "text": "3",
      "label": "CARDINAL"
    },
    {
      "text": "5",
      "label": "CARDINAL"
    },
    {
      "text": "Likert",
      "label": "PERSON"
    },
    {
      "text": "10",
      "label": "CARDINAL"
    },
    {
      "text": "EXABSUM",
      "label": "ORG"
    },
    {
      "text": "two",
      "label": "CARDINAL"
    },
    {
      "text": "EXABSUM",
      "label": "ORG"
    },
    {
      "text": "EXABSUMExtractive",
      "label": "NORP"
    },
    {
      "text": "EXABSUM",
      "label": "ORG"
    },
    {
      "text": "EXABSUM",
      "label": "ORG"
    },
    {
      "text": "Business, Opinion, Politics",
      "label": "ORG"
    },
    {
      "text": "Living, Sports",
      "label": "ORG"
    },
    {
      "text": "Eq",
      "label": "GPE"
    },
    {
      "text": "13",
      "label": "CARDINAL"
    },
    {
      "text": "SIM",
      "label": "ORG"
    },
    {
      "text": "0",
      "label": "CARDINAL"
    },
    {
      "text": "0.2",
      "label": "DATE"
    },
    {
      "text": "0.5",
      "label": "CARDINAL"
    },
    {
      "text": "0.6",
      "label": "CARDINAL"
    },
    {
      "text": "0.8",
      "label": "CARDINAL"
    },
    {
      "text": "1",
      "label": "CARDINAL"
    },
    {
      "text": "0.6",
      "label": "CARDINAL"
    },
    {
      "text": "0.5",
      "label": "CARDINAL"
    },
    {
      "text": "22",
      "label": "CARDINAL"
    },
    {
      "text": "34",
      "label": "CARDINAL"
    },
    {
      "text": "Alami",
      "label": "PERSON"
    },
    {
      "text": "2023",
      "label": "DATE"
    },
    {
      "text": "10:163",
      "label": "CARDINAL"
    },
    {
      "text": "ISF",
      "label": "ORG"
    },
    {
      "text": "0.6",
      "label": "CARDINAL"
    },
    {
      "text": "three",
      "label": "CARDINAL"
    },
    {
      "text": "1",
      "label": "CARDINAL"
    },
    {
      "text": "ROUGE",
      "label": "ORG"
    },
    {
      "text": "2",
      "label": "CARDINAL"
    },
    {
      "text": "3",
      "label": "CARDINAL"
    },
    {
      "text": "ROUGE-1",
      "label": "NORP"
    },
    {
      "text": "ROUGE-2",
      "label": "PERSON"
    },
    {
      "text": "2",
      "label": "CARDINAL"
    },
    {
      "text": "ROUGE-1",
      "label": "ORG"
    },
    {
      "text": "ROUGE-2",
      "label": "PERSON"
    },
    {
      "text": "ROUGE-SU4",
      "label": "ORG"
    },
    {
      "text": "ROUGE",
      "label": "ORG"
    },
    {
      "text": "DUC02",
      "label": "PERSON"
    },
    {
      "text": "3",
      "label": "CARDINAL"
    },
    {
      "text": "ROUGE-1",
      "label": "ORG"
    },
    {
      "text": "ROUGE-2",
      "label": "PERSON"
    },
    {
      "text": "CNN",
      "label": "ORG"
    },
    {
      "text": "Table",
      "label": "ORG"
    },
    {
      "text": "4",
      "label": "CARDINAL"
    },
    {
      "text": "Figs",
      "label": "PERSON"
    },
    {
      "text": "4",
      "label": "DATE"
    },
    {
      "text": "5",
      "label": "DATE"
    },
    {
      "text": "6",
      "label": "CARDINAL"
    },
    {
      "text": "DUC02",
      "label": "GPE"
    },
    {
      "text": "CNN",
      "label": "ORG"
    },
    {
      "text": "first",
      "label": "ORDINAL"
    },
    {
      "text": "2",
      "label": "CARDINAL"
    },
    {
      "text": "3",
      "label": "CARDINAL"
    },
    {
      "text": "TR",
      "label": "GPE"
    },
    {
      "text": "ISF",
      "label": "ORG"
    },
    {
      "text": "Table 2 ROUGE",
      "label": "ORG"
    },
    {
      "text": "EXABSUMExtractive",
      "label": "NORP"
    },
    {
      "text": "Feature Analysis",
      "label": "ORG"
    },
    {
      "text": "Dataset",
      "label": "ORG"
    },
    {
      "text": "Comb Represents the Combination of Selected Scoring Approaches",
      "label": "ORG"
    },
    {
      "text": "DUC",
      "label": "ORG"
    },
    {
      "text": "2001",
      "label": "DATE"
    },
    {
      "text": "0.402 0.143",
      "label": "CARDINAL"
    },
    {
      "text": "TR\u2212ISF + Sentence Position + Sentence Length",
      "label": "ORG"
    },
    {
      "text": "0.453 0.192",
      "label": "CARDINAL"
    },
    {
      "text": "EXABSUMExtractive",
      "label": "NORP"
    },
    {
      "text": "TR\u2212ISF + Sentence Position + Sentence \nLength + Sentence",
      "label": "ORG"
    },
    {
      "text": "EXABSUMAbstractive Graphs + Reranking",
      "label": "PERSON"
    },
    {
      "text": "ONLY 0.319 0.151\n",
      "label": "CARDINAL"
    },
    {
      "text": "3",
      "label": "CARDINAL"
    },
    {
      "text": "ROUGE",
      "label": "ORG"
    },
    {
      "text": "DUC2002",
      "label": "ORG"
    },
    {
      "text": "Summary Type Scoring Techniques",
      "label": "WORK_OF_ART"
    },
    {
      "text": "2002",
      "label": "DATE"
    },
    {
      "text": "ROUGE\u2011 SU4 ROUGE\u2011L",
      "label": "PERSON"
    },
    {
      "text": "0.189 0.207 0.401",
      "label": "EVENT"
    },
    {
      "text": "0.236",
      "label": "CARDINAL"
    },
    {
      "text": "0.251 0.442",
      "label": "CARDINAL"
    },
    {
      "text": "EXABSUMExtractive",
      "label": "NORP"
    },
    {
      "text": "TR\u2212ISF",
      "label": "GPE"
    },
    {
      "text": "0.288 0.472",
      "label": "CARDINAL"
    },
    {
      "text": "EXABSUMAbstractive Graphs + Reranking",
      "label": "PERSON"
    },
    {
      "text": "0.134",
      "label": "MONEY"
    },
    {
      "text": "0.322",
      "label": "CARDINAL"
    },
    {
      "text": "23",
      "label": "CARDINAL"
    },
    {
      "text": "34",
      "label": "CARDINAL"
    },
    {
      "text": "2023",
      "label": "DATE"
    },
    {
      "text": "10:163",
      "label": "CARDINAL"
    },
    {
      "text": "4",
      "label": "CARDINAL"
    },
    {
      "text": "EXABSUMExtractive",
      "label": "NORP"
    },
    {
      "text": "CNN",
      "label": "ORG"
    },
    {
      "text": "Comb",
      "label": "PERSON"
    },
    {
      "text": "CNN",
      "label": "ORG"
    },
    {
      "text": "TR\u2212ISF + Sentence Position + Sentence Length",
      "label": "ORG"
    },
    {
      "text": "0.592 0.434",
      "label": "CARDINAL"
    },
    {
      "text": "EXABSUMExtractive",
      "label": "NORP"
    },
    {
      "text": "TR\u2212ISF + Sentence Position + Sentence \nLength + Sentence",
      "label": "ORG"
    },
    {
      "text": "EXABSUMAbstractive Graphs + Reranking",
      "label": "PERSON"
    },
    {
      "text": "0.501",
      "label": "CARDINAL"
    },
    {
      "text": "0.332",
      "label": "MONEY"
    },
    {
      "text": "0.0000.1000.2000.3000.4000.5000.600",
      "label": "CARDINAL"
    },
    {
      "text": "Comb 1C",
      "label": "ORG"
    },
    {
      "text": "Graphs +\nRerankingComb 3Results",
      "label": "PERSON"
    },
    {
      "text": "DUC",
      "label": "ORG"
    },
    {
      "text": "2001",
      "label": "DATE"
    },
    {
      "text": "ROUGE-1 ROUGE-2\nFig",
      "label": "PERSON"
    },
    {
      "text": "ROUGE-2 Results",
      "label": "PERSON"
    },
    {
      "text": "EXABSUM",
      "label": "ORG"
    },
    {
      "text": "0.0000.1000.2000.3000.4000.5000.600",
      "label": "CARDINAL"
    },
    {
      "text": "ONLY COMB1C",
      "label": "CARDINAL"
    },
    {
      "text": "DUC",
      "label": "ORG"
    },
    {
      "text": "2002",
      "label": "DATE"
    },
    {
      "text": "ROUGE-1 ROUGE-2 ROUGE-SU4",
      "label": "ORG"
    },
    {
      "text": "ROUGE-2",
      "label": "ORG"
    },
    {
      "text": "ROUGE-SU4",
      "label": "ORG"
    },
    {
      "text": "ROUGE",
      "label": "ORG"
    },
    {
      "text": "DUC",
      "label": "ORG"
    },
    {
      "text": "2002",
      "label": "DATE"
    },
    {
      "text": "24",
      "label": "CARDINAL"
    },
    {
      "text": "34",
      "label": "CARDINAL"
    },
    {
      "text": "Alami",
      "label": "PERSON"
    },
    {
      "text": "2023",
      "label": "DATE"
    },
    {
      "text": "10:163",
      "label": "CARDINAL"
    },
    {
      "text": "Eq",
      "label": "PERSON"
    },
    {
      "text": "13",
      "label": "DATE"
    },
    {
      "text": "second",
      "label": "ORDINAL"
    },
    {
      "text": "2",
      "label": "CARDINAL"
    },
    {
      "text": "3",
      "label": "DATE"
    },
    {
      "text": "4",
      "label": "CARDINAL"
    },
    {
      "text": "EXABSUMExtractive",
      "label": "NORP"
    },
    {
      "text": "comb3",
      "label": "PERSON"
    },
    {
      "text": "ROUGE-1",
      "label": "NORP"
    },
    {
      "text": "3",
      "label": "CARDINAL"
    },
    {
      "text": "13.44%",
      "label": "PERCENT"
    },
    {
      "text": "EXABSUMExtractive",
      "label": "NORP"
    },
    {
      "text": "Combination 2",
      "label": "ORG"
    },
    {
      "text": "11.85%",
      "label": "PERCENT"
    },
    {
      "text": "EXABSUMExtractive",
      "label": "NORP"
    },
    {
      "text": "TR-ISF",
      "label": "ORG"
    },
    {
      "text": "three",
      "label": "CARDINAL"
    },
    {
      "text": "EXABSUMExtractive",
      "label": "NORP"
    },
    {
      "text": "ROUGE",
      "label": "ORG"
    },
    {
      "text": "TR-ISF",
      "label": "ORG"
    },
    {
      "text": "The Textual Entailment (TE",
      "label": "WORK_OF_ART"
    },
    {
      "text": "62",
      "label": "CARDINAL"
    },
    {
      "text": "CNN",
      "label": "ORG"
    },
    {
      "text": "ROUGE-1 ROUGE-2\nFig",
      "label": "PERSON"
    },
    {
      "text": "6",
      "label": "CARDINAL"
    },
    {
      "text": "ROUGE-1",
      "label": "PERSON"
    },
    {
      "text": "ROUGE-2",
      "label": "PERSON"
    },
    {
      "text": "CNN",
      "label": "ORG"
    },
    {
      "text": "25",
      "label": "CARDINAL"
    },
    {
      "text": "34",
      "label": "CARDINAL"
    },
    {
      "text": "2023",
      "label": "DATE"
    },
    {
      "text": "10:163",
      "label": "CARDINAL"
    },
    {
      "text": "ROUGE",
      "label": "ORG"
    },
    {
      "text": "100",
      "label": "CARDINAL"
    },
    {
      "text": "ROUGE",
      "label": "ORG"
    },
    {
      "text": "One",
      "label": "CARDINAL"
    },
    {
      "text": "5",
      "label": "CARDINAL"
    },
    {
      "text": "6 illustrates",
      "label": "QUANTITY"
    },
    {
      "text": "two",
      "label": "CARDINAL"
    },
    {
      "text": "EXABSUMExtractive",
      "label": "NORP"
    },
    {
      "text": "Table 5 Results",
      "label": "WORK_OF_ART"
    },
    {
      "text": "Q1 Q2 Q3\n1",
      "label": "PRODUCT"
    },
    {
      "text": "8.76 17.25",
      "label": "CARDINAL"
    },
    {
      "text": "0 1.21",
      "label": "CARDINAL"
    },
    {
      "text": "2",
      "label": "CARDINAL"
    },
    {
      "text": "19.01 30.1",
      "label": "CARDINAL"
    },
    {
      "text": "18.41 27.61",
      "label": "CARDINAL"
    },
    {
      "text": "3",
      "label": "CARDINAL"
    },
    {
      "text": "21.39",
      "label": "CARDINAL"
    },
    {
      "text": "22.83",
      "label": "CARDINAL"
    },
    {
      "text": "22.83",
      "label": "CARDINAL"
    },
    {
      "text": "4",
      "label": "CARDINAL"
    },
    {
      "text": "48.06 42.1",
      "label": "CARDINAL"
    },
    {
      "text": "5.32",
      "label": "CARDINAL"
    },
    {
      "text": "5",
      "label": "CARDINAL"
    },
    {
      "text": "13.78",
      "label": "MONEY"
    },
    {
      "text": "22.2",
      "label": "CARDINAL"
    },
    {
      "text": "8.55",
      "label": "CARDINAL"
    },
    {
      "text": "26",
      "label": "CARDINAL"
    },
    {
      "text": "34",
      "label": "CARDINAL"
    },
    {
      "text": "Alami",
      "label": "PERSON"
    },
    {
      "text": "2023",
      "label": "DATE"
    },
    {
      "text": "10:163",
      "label": "CARDINAL"
    },
    {
      "text": "Comparison",
      "label": "ORG"
    },
    {
      "text": "EXABSUMExtractive",
      "label": "NORP"
    },
    {
      "text": "DUC",
      "label": "ORG"
    },
    {
      "text": "2001",
      "label": "DATE"
    },
    {
      "text": "2002",
      "label": "DATE"
    },
    {
      "text": "three",
      "label": "CARDINAL"
    },
    {
      "text": "63",
      "label": "CARDINAL"
    },
    {
      "text": "DUC01",
      "label": "GPE"
    },
    {
      "text": "DUC02",
      "label": "ORG"
    },
    {
      "text": "ROUGE-1",
      "label": "ORG"
    },
    {
      "text": "Strube",
      "label": "GPE"
    },
    {
      "text": "19",
      "label": "CARDINAL"
    },
    {
      "text": "three",
      "label": "CARDINAL"
    },
    {
      "text": "64",
      "label": "CARDINAL"
    },
    {
      "text": "65",
      "label": "CARDINAL"
    },
    {
      "text": "66",
      "label": "CARDINAL"
    },
    {
      "text": "67",
      "label": "CARDINAL"
    },
    {
      "text": "6",
      "label": "CARDINAL"
    },
    {
      "text": "EXABSUMExtractive",
      "label": "NORP"
    },
    {
      "text": "DUC 2002 Corpus",
      "label": "ORG"
    },
    {
      "text": "Cluster d062j",
      "label": "PERSON"
    },
    {
      "text": "50%",
      "label": "PERCENT"
    },
    {
      "text": "The White House",
      "label": "ORG"
    },
    {
      "text": "Bush",
      "label": "PERSON"
    },
    {
      "text": "yesterday",
      "label": "DATE"
    },
    {
      "text": "morning",
      "label": "TIME"
    },
    {
      "text": "Bush",
      "label": "PERSON"
    },
    {
      "text": "the Exxon Valdez",
      "label": "EVENT"
    },
    {
      "text": "Alaskan",
      "label": "NORP"
    },
    {
      "text": "Hurricane Hugo",
      "label": "EVENT"
    },
    {
      "text": "Carolina",
      "label": "LOC"
    },
    {
      "text": "Bush",
      "label": "PERSON"
    },
    {
      "text": "first",
      "label": "ORDINAL"
    },
    {
      "text": "the day",
      "label": "DATE"
    },
    {
      "text": "6:30",
      "label": "TIME"
    },
    {
      "text": "Bush",
      "label": "PERSON"
    },
    {
      "text": "Hurricane Hugo",
      "label": "EVENT"
    },
    {
      "text": "bush",
      "label": "PERSON"
    },
    {
      "text": "california",
      "label": "GPE"
    },
    {
      "text": "this weekend",
      "label": "DATE"
    },
    {
      "text": "bush",
      "label": "PERSON"
    },
    {
      "text": "yesterday",
      "label": "DATE"
    },
    {
      "text": "morning",
      "label": "TIME"
    },
    {
      "text": "white house",
      "label": "ORG"
    },
    {
      "text": "the exxon valdez",
      "label": "EVENT"
    },
    {
      "text": "alaskan",
      "label": "NORP"
    },
    {
      "text": "hurricane hugo",
      "label": "EVENT"
    },
    {
      "text": "the carolina coast",
      "label": "GPE"
    },
    {
      "text": "fema",
      "label": "ORG"
    },
    {
      "text": "the white house",
      "label": "ORG"
    },
    {
      "text": "27",
      "label": "CARDINAL"
    },
    {
      "text": "34",
      "label": "CARDINAL"
    },
    {
      "text": "2023",
      "label": "DATE"
    },
    {
      "text": "10:163",
      "label": "CARDINAL"
    },
    {
      "text": "9",
      "label": "CARDINAL"
    },
    {
      "text": "Differential Evolution",
      "label": "PERSON"
    },
    {
      "text": "The Fuzzy Evolutionary Optimization Model (FEOM",
      "label": "ORG"
    },
    {
      "text": "68",
      "label": "CARDINAL"
    },
    {
      "text": "69",
      "label": "CARDINAL"
    },
    {
      "text": "RankNet",
      "label": "ORG"
    },
    {
      "text": "38",
      "label": "CARDINAL"
    },
    {
      "text": "two",
      "label": "CARDINAL"
    },
    {
      "text": "PENDIUME",
      "label": "ORG"
    },
    {
      "text": "COMPENDIUME",
      "label": "ORG"
    },
    {
      "text": "COMPENDIUME",
      "label": "ORG"
    },
    {
      "text": "HP-UFPE FS",
      "label": "ORG"
    },
    {
      "text": "70",
      "label": "CARDINAL"
    },
    {
      "text": "seventeen",
      "label": "CARDINAL"
    },
    {
      "text": "70",
      "label": "CARDINAL"
    },
    {
      "text": "71",
      "label": "CARDINAL"
    },
    {
      "text": "36",
      "label": "CARDINAL"
    },
    {
      "text": "two",
      "label": "CARDINAL"
    },
    {
      "text": "8",
      "label": "DATE"
    },
    {
      "text": "9",
      "label": "CARDINAL"
    },
    {
      "text": "ROUGE-1",
      "label": "NORP"
    },
    {
      "text": "ROUGE-2",
      "label": "PERSON"
    },
    {
      "text": "DUC",
      "label": "PERSON"
    },
    {
      "text": "2001",
      "label": "DATE"
    },
    {
      "text": "DUC 2002",
      "label": "ORG"
    },
    {
      "text": "CNN",
      "label": "ORG"
    },
    {
      "text": "respec",
      "label": "GPE"
    },
    {
      "text": "DUC",
      "label": "PERSON"
    },
    {
      "text": "2001",
      "label": "DATE"
    },
    {
      "text": "DE",
      "label": "ORG"
    },
    {
      "text": "ROUGE-1",
      "label": "PERSON"
    },
    {
      "text": "ROUGE-2",
      "label": "PERSON"
    },
    {
      "text": "Fig",
      "label": "PERSON"
    },
    {
      "text": "7",
      "label": "CARDINAL"
    },
    {
      "text": "DE",
      "label": "ORG"
    },
    {
      "text": "FEOM",
      "label": "ORG"
    },
    {
      "text": "DUC",
      "label": "PERSON"
    },
    {
      "text": "2001",
      "label": "DATE"
    },
    {
      "text": "ROUGE-2",
      "label": "PERSON"
    },
    {
      "text": "DE",
      "label": "ORG"
    },
    {
      "text": "28",
      "label": "CARDINAL"
    },
    {
      "text": "34",
      "label": "CARDINAL"
    },
    {
      "text": "Alami",
      "label": "PERSON"
    },
    {
      "text": "2023",
      "label": "DATE"
    },
    {
      "text": "10:163",
      "label": "CARDINAL"
    },
    {
      "text": "Table 7 F-measure",
      "label": "PRODUCT"
    },
    {
      "text": "DUC",
      "label": "ORG"
    },
    {
      "text": "2001",
      "label": "DATE"
    },
    {
      "text": "DUC",
      "label": "ORG"
    },
    {
      "text": "2001",
      "label": "DATE"
    },
    {
      "text": "ROUGE-1 ROUGE-2",
      "label": "PERSON"
    },
    {
      "text": "EXABSUMExtractive",
      "label": "NORP"
    },
    {
      "text": "0.478 0.185\nFEOM Extractive 0.477 0.185\nNetSum",
      "label": "EVENT"
    },
    {
      "text": "0.176",
      "label": "MONEY"
    },
    {
      "text": "0.453 0.176",
      "label": "CARDINAL"
    },
    {
      "text": "DUC",
      "label": "PERSON"
    },
    {
      "text": "2001",
      "label": "DATE"
    },
    {
      "text": "0.202",
      "label": "CARDINAL"
    },
    {
      "text": "0.444 0.198",
      "label": "CARDINAL"
    },
    {
      "text": "HP-UFPE FS Extractive",
      "label": "ORG"
    },
    {
      "text": "0.359 0.117",
      "label": "CARDINAL"
    },
    {
      "text": "Table 8 Comparison of F-measure",
      "label": "PRODUCT"
    },
    {
      "text": "DUC 2002",
      "label": "ORG"
    },
    {
      "text": "2002",
      "label": "DATE"
    },
    {
      "text": "ROUGE-1 ROUGE-2",
      "label": "PERSON"
    },
    {
      "text": "EXABSUMExtractive",
      "label": "NORP"
    },
    {
      "text": "0.341 0.104",
      "label": "CARDINAL"
    },
    {
      "text": "Parveen",
      "label": "GPE"
    },
    {
      "text": "Strube",
      "label": "GPE"
    },
    {
      "text": "19",
      "label": "CARDINAL"
    },
    {
      "text": "0.485 0.230",
      "label": "CARDINAL"
    },
    {
      "text": "DUC",
      "label": "ORG"
    },
    {
      "text": "2002",
      "label": "DATE"
    },
    {
      "text": "0.228",
      "label": "CARDINAL"
    },
    {
      "text": "0.470 0.221",
      "label": "CARDINAL"
    },
    {
      "text": "0.466 0.123",
      "label": "CARDINAL"
    },
    {
      "text": "0.456 0.202",
      "label": "CARDINAL"
    },
    {
      "text": "NetSum",
      "label": "ORG"
    },
    {
      "text": "0.449 0.111",
      "label": "CARDINAL"
    },
    {
      "text": "Autosummarizer Extractive",
      "label": "PERSON"
    },
    {
      "text": "0.437 0.191",
      "label": "DATE"
    },
    {
      "text": "Fast Abstractive Summarization Abstractive",
      "label": "WORK_OF_ART"
    },
    {
      "text": "0.394 0.173",
      "label": "CARDINAL"
    },
    {
      "text": "0.157",
      "label": "MONEY"
    },
    {
      "text": "HP-UFPE FS Extractive",
      "label": "ORG"
    },
    {
      "text": "0.359 0.117",
      "label": "CARDINAL"
    },
    {
      "text": "Table 9 F-measure",
      "label": "PRODUCT"
    },
    {
      "text": "CNN",
      "label": "ORG"
    },
    {
      "text": "CNN",
      "label": "ORG"
    },
    {
      "text": "ROUGE-1 ROUGE-2",
      "label": "PERSON"
    },
    {
      "text": "0.601 0.451",
      "label": "CARDINAL"
    },
    {
      "text": "0.501",
      "label": "CARDINAL"
    },
    {
      "text": "0.332",
      "label": "CARDINAL"
    },
    {
      "text": "HP-UFPE FS Extractive",
      "label": "ORG"
    },
    {
      "text": "0.507 0.345",
      "label": "CARDINAL"
    },
    {
      "text": "Autosummarizer Extractive",
      "label": "PERSON"
    },
    {
      "text": "0.488 0.327",
      "label": "CARDINAL"
    },
    {
      "text": "0.466 0.321",
      "label": "CARDINAL"
    },
    {
      "text": "29",
      "label": "CARDINAL"
    },
    {
      "text": "34",
      "label": "CARDINAL"
    },
    {
      "text": "2023",
      "label": "DATE"
    },
    {
      "text": "10:163",
      "label": "CARDINAL"
    },
    {
      "text": "DUC 2002",
      "label": "ORG"
    },
    {
      "text": "three",
      "label": "CARDINAL"
    },
    {
      "text": "EXABSUMExtractive",
      "label": "NORP"
    },
    {
      "text": "Parveen",
      "label": "GPE"
    },
    {
      "text": "Strube",
      "label": "GPE"
    },
    {
      "text": "19",
      "label": "CARDINAL"
    },
    {
      "text": "8)",
      "label": "CARDINAL"
    },
    {
      "text": "Parveen",
      "label": "DATE"
    },
    {
      "text": "Strube",
      "label": "GPE"
    },
    {
      "text": "19",
      "label": "CARDINAL"
    },
    {
      "text": "DUC2001",
      "label": "ORG"
    },
    {
      "text": "DUC2002",
      "label": "ORG"
    },
    {
      "text": "a decade",
      "label": "DATE"
    },
    {
      "text": "Fig",
      "label": "PERSON"
    },
    {
      "text": "7",
      "label": "CARDINAL"
    },
    {
      "text": "ROUGE-2 Results",
      "label": "PERSON"
    },
    {
      "text": "EXABSUMExtractive",
      "label": "NORP"
    },
    {
      "text": "DUC",
      "label": "ORG"
    },
    {
      "text": "2001",
      "label": "DATE"
    },
    {
      "text": "Fig",
      "label": "PERSON"
    },
    {
      "text": "8",
      "label": "CARDINAL"
    },
    {
      "text": "ROUGE-2",
      "label": "PERSON"
    },
    {
      "text": "EXABSUMExtractive",
      "label": "NORP"
    },
    {
      "text": "DUC 2002",
      "label": "ORG"
    },
    {
      "text": "0.0000.1000.2000.3000.4000.5000.6000.700",
      "label": "CARDINAL"
    },
    {
      "text": "UFPE FSA",
      "label": "ORG"
    },
    {
      "text": "ROUGE-1 ROUGE-2\nFig",
      "label": "PERSON"
    },
    {
      "text": "9",
      "label": "CARDINAL"
    },
    {
      "text": "ROUGE-2",
      "label": "PERSON"
    },
    {
      "text": "EXABSUMExtractive",
      "label": "NORP"
    },
    {
      "text": "CNN",
      "label": "ORG"
    },
    {
      "text": "30",
      "label": "CARDINAL"
    },
    {
      "text": "34",
      "label": "CARDINAL"
    },
    {
      "text": "Alami",
      "label": "PERSON"
    },
    {
      "text": "2023",
      "label": "DATE"
    },
    {
      "text": "10:163",
      "label": "CARDINAL"
    },
    {
      "text": "CNN",
      "label": "ORG"
    },
    {
      "text": "EXABSUMExtractive",
      "label": "NORP"
    },
    {
      "text": "ROUGE-1",
      "label": "ORG"
    },
    {
      "text": "ROUGE-2",
      "label": "PERSON"
    },
    {
      "text": "Fig",
      "label": "PERSON"
    },
    {
      "text": "9",
      "label": "CARDINAL"
    },
    {
      "text": "34.12%",
      "label": "PERCENT"
    },
    {
      "text": "two",
      "label": "CARDINAL"
    },
    {
      "text": "EXABSUMExtractive",
      "label": "NORP"
    },
    {
      "text": "EXABSUMExtractive",
      "label": "NORP"
    },
    {
      "text": "ROUGE-1",
      "label": "ORG"
    },
    {
      "text": "ROUGE",
      "label": "ORG"
    },
    {
      "text": "F-measure",
      "label": "PRODUCT"
    },
    {
      "text": "two",
      "label": "CARDINAL"
    },
    {
      "text": "1",
      "label": "CARDINAL"
    },
    {
      "text": "EXABSUMExtractive",
      "label": "NORP"
    },
    {
      "text": "2",
      "label": "CARDINAL"
    },
    {
      "text": "second",
      "label": "ORDINAL"
    },
    {
      "text": "first",
      "label": "ORDINAL"
    },
    {
      "text": "ROUGE",
      "label": "ORG"
    },
    {
      "text": "Tables",
      "label": "GPE"
    },
    {
      "text": "8",
      "label": "DATE"
    },
    {
      "text": "9",
      "label": "CARDINAL"
    },
    {
      "text": "EXABSUM",
      "label": "ORG"
    },
    {
      "text": "two",
      "label": "CARDINAL"
    },
    {
      "text": "EXABSUMExtractive",
      "label": "NORP"
    },
    {
      "text": "31",
      "label": "CARDINAL"
    },
    {
      "text": "34",
      "label": "CARDINAL"
    },
    {
      "text": "2023",
      "label": "DATE"
    },
    {
      "text": "10:163",
      "label": "CARDINAL"
    },
    {
      "text": "EXABSUM",
      "label": "ORG"
    },
    {
      "text": "two",
      "label": "CARDINAL"
    },
    {
      "text": "EXABSUMExtractive",
      "label": "NORP"
    },
    {
      "text": "two",
      "label": "CARDINAL"
    },
    {
      "text": "EXABSUM",
      "label": "ORG"
    },
    {
      "text": "EXABSUM",
      "label": "ORG"
    },
    {
      "text": "ATS",
      "label": "FAC"
    },
    {
      "text": "NLP",
      "label": "ORG"
    },
    {
      "text": "EXABSUM",
      "label": "ORG"
    },
    {
      "text": "NLP",
      "label": "ORG"
    },
    {
      "text": "Automatic",
      "label": "GPE"
    },
    {
      "text": "ZAM",
      "label": "PERSON"
    },
    {
      "text": "first",
      "label": "ORDINAL"
    },
    {
      "text": "BO",
      "label": "ORG"
    },
    {
      "text": "DUC",
      "label": "ORG"
    },
    {
      "text": "html",
      "label": "PERSON"
    },
    {
      "text": "CNN",
      "label": "ORG"
    },
    {
      "text": "google",
      "label": "ORG"
    },
    {
      "text": "32",
      "label": "CARDINAL"
    },
    {
      "text": "34",
      "label": "CARDINAL"
    },
    {
      "text": "Alami",
      "label": "PERSON"
    },
    {
      "text": "2023",
      "label": "DATE"
    },
    {
      "text": "10:163",
      "label": "CARDINAL"
    },
    {
      "text": "18",
      "label": "CARDINAL"
    },
    {
      "text": "August 2022",
      "label": "DATE"
    },
    {
      "text": "3",
      "label": "CARDINAL"
    },
    {
      "text": "October 2023",
      "label": "DATE"
    },
    {
      "text": "Marcu D. Automated",
      "label": "PERSON"
    },
    {
      "text": "Oxford",
      "label": "ORG"
    },
    {
      "text": "2005",
      "label": "DATE"
    },
    {
      "text": "pp.",
      "label": "GPE"
    },
    {
      "text": "583\u2013598",
      "label": "CARDINAL"
    },
    {
      "text": "2",
      "label": "CARDINAL"
    },
    {
      "text": "Mani",
      "label": "PERSON"
    },
    {
      "text": "The MIT Press",
      "label": "ORG"
    },
    {
      "text": "1999",
      "label": "DATE"
    },
    {
      "text": "3",
      "label": "CARDINAL"
    },
    {
      "text": "Huang L",
      "label": "PERSON"
    },
    {
      "text": "Wei F",
      "label": "PERSON"
    },
    {
      "text": "Li W. Modeling",
      "label": "PERSON"
    },
    {
      "text": "third",
      "label": "ORDINAL"
    },
    {
      "text": "2010",
      "label": "DATE"
    },
    {
      "text": "382\u2013386",
      "label": "CARDINAL"
    },
    {
      "text": "4",
      "label": "CARDINAL"
    },
    {
      "text": "Gupta S",
      "label": "PERSON"
    },
    {
      "text": "Syst Appl",
      "label": "PERSON"
    },
    {
      "text": "2019;121:49\u201365",
      "label": "CARDINAL"
    },
    {
      "text": "5",
      "label": "CARDINAL"
    },
    {
      "text": "Nenkova A, & McKeown K.",
      "label": "ORG"
    },
    {
      "text": "2012",
      "label": "DATE"
    },
    {
      "text": "pp.",
      "label": "GPE"
    },
    {
      "text": "6",
      "label": "CARDINAL"
    },
    {
      "text": "IBM",
      "label": "ORG"
    },
    {
      "text": "7",
      "label": "CARDINAL"
    },
    {
      "text": "Barrios F,",
      "label": "PRODUCT"
    },
    {
      "text": "Argerich L",
      "label": "PERSON"
    },
    {
      "text": "2015-44",
      "label": "DATE"
    },
    {
      "text": "JAIIO",
      "label": "ORG"
    },
    {
      "text": "44",
      "label": "CARDINAL"
    },
    {
      "text": "JAIIO-ASAI 2015-ISSN",
      "label": "ORG"
    },
    {
      "text": "2451\u20137585, 2016",
      "label": "DATE"
    },
    {
      "text": "65\u201372",
      "label": "CARDINAL"
    },
    {
      "text": "8",
      "label": "CARDINAL"
    },
    {
      "text": "Marcus S",
      "label": "ORG"
    },
    {
      "text": "Markovitch S. Contextual",
      "label": "ORG"
    },
    {
      "text": "31st",
      "label": "ORDINAL"
    },
    {
      "text": "annual",
      "label": "DATE"
    },
    {
      "text": "Association for Computational Linguistics",
      "label": "ORG"
    },
    {
      "text": "pp",
      "label": "GPE"
    },
    {
      "text": "164\u2013171",
      "label": "CARDINAL"
    },
    {
      "text": "1993",
      "label": "DATE"
    },
    {
      "text": "9",
      "label": "CARDINAL"
    },
    {
      "text": "Aliguliyev RM",
      "label": "ORG"
    },
    {
      "text": "Syst Appl",
      "label": "PERSON"
    },
    {
      "text": "2009;36(4):7764\u201372",
      "label": "CARDINAL"
    },
    {
      "text": "10",
      "label": "CARDINAL"
    },
    {
      "text": "Alc\u00f3n O",
      "label": "PERSON"
    },
    {
      "text": "Lloret E. SEMPCA-Summarizer",
      "label": "PERSON"
    },
    {
      "text": "Comput Informs",
      "label": "ORG"
    },
    {
      "text": "2018;37:1126\u201348",
      "label": "CARDINAL"
    },
    {
      "text": "11",
      "label": "CARDINAL"
    },
    {
      "text": "Erkan G",
      "label": "PERSON"
    },
    {
      "text": "Artif Intell Res",
      "label": "PERSON"
    },
    {
      "text": "2004;22:457\u201379",
      "label": "CARDINAL"
    },
    {
      "text": "12",
      "label": "CARDINAL"
    },
    {
      "text": "Allison",
      "label": "PERSON"
    },
    {
      "text": "Blair-Goldensohn S",
      "label": "PERSON"
    },
    {
      "text": "Drabek",
      "label": "PERSON"
    },
    {
      "text": "Liu D",
      "label": "PERSON"
    },
    {
      "text": "Teufel S",
      "label": "ORG"
    },
    {
      "text": "Zhang Z.",
      "label": "PERSON"
    },
    {
      "text": "the 4th International Conference on Language Resources and Evaluation",
      "label": "ORG"
    },
    {
      "text": "2004",
      "label": "DATE"
    },
    {
      "text": "pp",
      "label": "GPE"
    },
    {
      "text": "699\u2013702",
      "label": "CARDINAL"
    },
    {
      "text": "13",
      "label": "CARDINAL"
    },
    {
      "text": "Dunlavy DM",
      "label": "PERSON"
    },
    {
      "text": "QCS",
      "label": "ORG"
    },
    {
      "text": "Info \nProcess Manag",
      "label": "PERSON"
    },
    {
      "text": "2007;43(6):1588\u2013605",
      "label": "CARDINAL"
    },
    {
      "text": "14",
      "label": "CARDINAL"
    },
    {
      "text": "Poibeau T. Automatic",
      "label": "PERSON"
    },
    {
      "text": "Berlin",
      "label": "GPE"
    },
    {
      "text": "Heidelberg",
      "label": "GPE"
    },
    {
      "text": "2013",
      "label": "DATE"
    },
    {
      "text": "3\u201321",
      "label": "CARDINAL"
    },
    {
      "text": "15",
      "label": "CARDINAL"
    },
    {
      "text": "Liu X",
      "label": "PERSON"
    },
    {
      "text": "Webster JJ",
      "label": "PERSON"
    },
    {
      "text": "Kit C.",
      "label": "PERSON"
    },
    {
      "text": "22nd",
      "label": "ORDINAL"
    },
    {
      "text": "2009",
      "label": "DATE"
    },
    {
      "text": "168\u2013178",
      "label": "CARDINAL"
    },
    {
      "text": "16",
      "label": "CARDINAL"
    },
    {
      "text": "Tonelli S",
      "label": "PERSON"
    },
    {
      "text": "Pianta E. Matching",
      "label": "PERSON"
    },
    {
      "text": "French",
      "label": "NORP"
    },
    {
      "text": "2011",
      "label": "DATE"
    },
    {
      "text": "17",
      "label": "CARDINAL"
    },
    {
      "text": "Ko Y",
      "label": "PERSON"
    },
    {
      "text": "Seo J. An",
      "label": "PERSON"
    },
    {
      "text": "2008;29:1366\u201371",
      "label": "CARDINAL"
    },
    {
      "text": "10. 1016",
      "label": "DATE"
    },
    {
      "text": "2008",
      "label": "DATE"
    },
    {
      "text": "02",
      "label": "CARDINAL"
    },
    {
      "text": "008",
      "label": "CARDINAL"
    },
    {
      "text": "18",
      "label": "CARDINAL"
    },
    {
      "text": "Cagliero L",
      "label": "PERSON"
    },
    {
      "text": "Fiori A. GRAPHSUM",
      "label": "PERSON"
    },
    {
      "text": "Inf Sci",
      "label": "PERSON"
    },
    {
      "text": "2013;249:96\u2013109",
      "label": "DATE"
    },
    {
      "text": "10. 1016",
      "label": "DATE"
    },
    {
      "text": "2013",
      "label": "DATE"
    },
    {
      "text": "06",
      "label": "CARDINAL"
    },
    {
      "text": "046",
      "label": "CARDINAL"
    },
    {
      "text": "19",
      "label": "CARDINAL"
    },
    {
      "text": "24th",
      "label": "ORDINAL"
    },
    {
      "text": "AAAIPress",
      "label": "ORG"
    },
    {
      "text": "2015",
      "label": "DATE"
    },
    {
      "text": "1298\u20131304",
      "label": "CARDINAL"
    },
    {
      "text": "20",
      "label": "CARDINAL"
    },
    {
      "text": "Durrett G",
      "label": "PERSON"
    },
    {
      "text": "Berg",
      "label": "PERSON"
    },
    {
      "text": "Klein D. Learning",
      "label": "ORG"
    },
    {
      "text": "54th",
      "label": "ORDINAL"
    },
    {
      "text": "annual",
      "label": "DATE"
    },
    {
      "text": "1",
      "label": "CARDINAL"
    },
    {
      "text": "2016",
      "label": "DATE"
    },
    {
      "text": "21",
      "label": "DATE"
    },
    {
      "text": "Alguliev RM",
      "label": "PERSON"
    },
    {
      "text": "Aliguliyev RM",
      "label": "ORG"
    },
    {
      "text": "Hajirahimova MS",
      "label": "PERSON"
    },
    {
      "text": "Mehdiyev CA",
      "label": "PERSON"
    },
    {
      "text": "Syst Appl",
      "label": "PERSON"
    },
    {
      "text": "2011;38:14514\u201322",
      "label": "DATE"
    },
    {
      "text": "10. 1016",
      "label": "DATE"
    },
    {
      "text": "2011",
      "label": "DATE"
    },
    {
      "text": "05",
      "label": "CARDINAL"
    },
    {
      "text": "033",
      "label": "CARDINAL"
    },
    {
      "text": "22",
      "label": "CARDINAL"
    },
    {
      "text": "Lin H",
      "label": "PERSON"
    },
    {
      "text": "Bilmes J. Multi-document",
      "label": "PERSON"
    },
    {
      "text": "2010",
      "label": "DATE"
    },
    {
      "text": "annual",
      "label": "DATE"
    },
    {
      "text": "North American",
      "label": "NORP"
    },
    {
      "text": "Association for Computational Linguistics",
      "label": "ORG"
    },
    {
      "text": "2010",
      "label": "DATE"
    },
    {
      "text": "912\u2013920",
      "label": "CARDINAL"
    },
    {
      "text": "23",
      "label": "CARDINAL"
    },
    {
      "text": "Wan X",
      "label": "PERSON"
    },
    {
      "text": "Xiao J. Phrase",
      "label": "PERSON"
    },
    {
      "text": "compressive cross-language",
      "label": "ORG"
    },
    {
      "text": "2015",
      "label": "DATE"
    },
    {
      "text": "2015",
      "label": "DATE"
    },
    {
      "text": "118\u2013127",
      "label": "CARDINAL"
    },
    {
      "text": "24",
      "label": "CARDINAL"
    },
    {
      "text": "Plaza L. Uso de Grafos Sem\u00e1nticos",
      "label": "PERSON"
    },
    {
      "text": "Generaci\u00f3n Autom\u00e1tica de Res\u00famenes",
      "label": "PERSON"
    },
    {
      "text": "Estudio de su Aplicaci\u00f3n",
      "label": "ORG"
    },
    {
      "text": "PhD",
      "label": "WORK_OF_ART"
    },
    {
      "text": "2011",
      "label": "DATE"
    },
    {
      "text": "25",
      "label": "CARDINAL"
    },
    {
      "text": "Belz A. Automatic",
      "label": "PERSON"
    },
    {
      "text": "Nat Lang Eng",
      "label": "PERSON"
    },
    {
      "text": "2008;14(4):431\u201355",
      "label": "CARDINAL"
    },
    {
      "text": "26",
      "label": "CARDINAL"
    },
    {
      "text": "Mohammad S",
      "label": "PERSON"
    },
    {
      "text": "Dorr B",
      "label": "PERSON"
    },
    {
      "text": "Egan M",
      "label": "PERSON"
    },
    {
      "text": "Hassan A",
      "label": "PERSON"
    },
    {
      "text": "Muthukrishan P",
      "label": "PERSON"
    },
    {
      "text": "Qazvinian V",
      "label": "PERSON"
    },
    {
      "text": "Zajic D. Using",
      "label": "PERSON"
    },
    {
      "text": "North American",
      "label": "NORP"
    },
    {
      "text": "the Association of Computational \nLinguistics",
      "label": "ORG"
    },
    {
      "text": "2009",
      "label": "DATE"
    },
    {
      "text": "pp",
      "label": "GPE"
    },
    {
      "text": "584\u2013592",
      "label": "CARDINAL"
    },
    {
      "text": "27",
      "label": "CARDINAL"
    },
    {
      "text": "Erera S",
      "label": "ORG"
    },
    {
      "text": "Shmueli-Scheuer M",
      "label": "ORG"
    },
    {
      "text": "Roitman H",
      "label": "PERSON"
    },
    {
      "text": "al",
      "label": "PERSON"
    },
    {
      "text": "the 2019 Conference on Empirical Methods in Natural Language Processing",
      "label": "EVENT"
    },
    {
      "text": "Page 33",
      "label": "LAW"
    },
    {
      "text": "34",
      "label": "CARDINAL"
    },
    {
      "text": "2023",
      "label": "DATE"
    },
    {
      "text": "10:163",
      "label": "CARDINAL"
    },
    {
      "text": "9th",
      "label": "ORDINAL"
    },
    {
      "text": "System Demonstrations",
      "label": "ORG"
    },
    {
      "text": "2019",
      "label": "DATE"
    },
    {
      "text": "211\u2013216",
      "label": "CARDINAL"
    },
    {
      "text": "28",
      "label": "CARDINAL"
    },
    {
      "text": "2005;31(3):297\u2013328",
      "label": "CARDINAL"
    },
    {
      "text": "29",
      "label": "CARDINAL"
    },
    {
      "text": "Filippova K",
      "label": "PERSON"
    },
    {
      "text": "Strube M. Sentence",
      "label": "PERSON"
    },
    {
      "text": "2008",
      "label": "DATE"
    },
    {
      "text": "Honolulu",
      "label": "GPE"
    },
    {
      "text": "Hawaii",
      "label": "GPE"
    },
    {
      "text": "October",
      "label": "DATE"
    },
    {
      "text": "2008",
      "label": "DATE"
    },
    {
      "text": "Computa-",
      "label": "PERSON"
    },
    {
      "text": "Linguistics",
      "label": "GPE"
    },
    {
      "text": "177\u2013185",
      "label": "CARDINAL"
    },
    {
      "text": "30",
      "label": "CARDINAL"
    },
    {
      "text": "Filippova K. Multi-sentence",
      "label": "PERSON"
    },
    {
      "text": "2010",
      "label": "DATE"
    },
    {
      "text": "322\u2013330",
      "label": "CARDINAL"
    },
    {
      "text": "31",
      "label": "CARDINAL"
    },
    {
      "text": "Mahajani A",
      "label": "ORG"
    },
    {
      "text": "Maria I",
      "label": "PERSON"
    },
    {
      "text": "Sharma D.",
      "label": "PERSON"
    },
    {
      "text": "the Ambient Communications and Computer Systems",
      "label": "ORG"
    },
    {
      "text": "Singapore",
      "label": "GPE"
    },
    {
      "text": "2019",
      "label": "DATE"
    },
    {
      "text": "32",
      "label": "DATE"
    },
    {
      "text": "Boudin F",
      "label": "PERSON"
    },
    {
      "text": "Morin E. Keyphrase",
      "label": "PERSON"
    },
    {
      "text": "2013",
      "label": "DATE"
    },
    {
      "text": "North American",
      "label": "NORP"
    },
    {
      "text": "Atlanta",
      "label": "GPE"
    },
    {
      "text": "Georgia",
      "label": "GPE"
    },
    {
      "text": "June",
      "label": "DATE"
    },
    {
      "text": "2013",
      "label": "DATE"
    },
    {
      "text": "298\u2013305",
      "label": "CARDINAL"
    },
    {
      "text": "33",
      "label": "CARDINAL"
    },
    {
      "text": "Banerjee S",
      "label": "ORG"
    },
    {
      "text": "Mitra P",
      "label": "ORG"
    },
    {
      "text": "Sugiyama K. Multi-document",
      "label": "PERSON"
    },
    {
      "text": "24th",
      "label": "ORDINAL"
    },
    {
      "text": "2015",
      "label": "DATE"
    },
    {
      "text": "1208\u20131214",
      "label": "CARDINAL"
    },
    {
      "text": "AAAI Press",
      "label": "ORG"
    },
    {
      "text": "34",
      "label": "DATE"
    },
    {
      "text": "Nayeem MT",
      "label": "PERSON"
    },
    {
      "text": "Fuad TA",
      "label": "PERSON"
    },
    {
      "text": "Chali Y. Abstractive",
      "label": "PERSON"
    },
    {
      "text": "2018",
      "label": "DATE"
    },
    {
      "text": "1191\u20131204",
      "label": "CARDINAL"
    },
    {
      "text": "35",
      "label": "DATE"
    },
    {
      "text": "Shang G",
      "label": "PERSON"
    },
    {
      "text": "Ding W",
      "label": "PERSON"
    },
    {
      "text": "Zhang Z",
      "label": "PERSON"
    },
    {
      "text": "Tixier AJP",
      "label": "PERSON"
    },
    {
      "text": "Vazirgiannis M",
      "label": "PERSON"
    },
    {
      "text": "Lorr\u00e9 JP",
      "label": "PERSON"
    },
    {
      "text": "ACL",
      "label": "ORG"
    },
    {
      "text": "1",
      "label": "CARDINAL"
    },
    {
      "text": "2018",
      "label": "DATE"
    },
    {
      "text": "36",
      "label": "CARDINAL"
    },
    {
      "text": "Chen YC",
      "label": "PERSON"
    },
    {
      "text": "Bansal M. Fast",
      "label": "PERSON"
    },
    {
      "text": "56th",
      "label": "ORDINAL"
    },
    {
      "text": "the Association for Computational Linguistics",
      "label": "ORG"
    },
    {
      "text": "Vol",
      "label": "PERSON"
    },
    {
      "text": "1",
      "label": "CARDINAL"
    },
    {
      "text": "2018",
      "label": "DATE"
    },
    {
      "text": "675\u2013686",
      "label": "CARDINAL"
    },
    {
      "text": "37",
      "label": "DATE"
    },
    {
      "text": "Di Fabbrizio G",
      "label": "PERSON"
    },
    {
      "text": "Stent A",
      "label": "PERSON"
    },
    {
      "text": "Gaizauskas R.",
      "label": "PERSON"
    },
    {
      "text": "8th",
      "label": "ORDINAL"
    },
    {
      "text": "International Natural Language Generation Conference (INLG",
      "label": "EVENT"
    },
    {
      "text": "2014",
      "label": "DATE"
    },
    {
      "text": "54\u201363",
      "label": "CARDINAL"
    },
    {
      "text": "38",
      "label": "DATE"
    },
    {
      "text": "Lloret E",
      "label": "PERSON"
    },
    {
      "text": "Rom\u00e1-Ferri MT",
      "label": "PERSON"
    },
    {
      "text": "Palomar M. COMPENDIUM",
      "label": "PERSON"
    },
    {
      "text": "2013;88:164\u201375",
      "label": "CARDINAL"
    },
    {
      "text": "39",
      "label": "CARDINAL"
    },
    {
      "text": "Hashmy R. SumItUp",
      "label": "PERSON"
    },
    {
      "text": "Pant M",
      "label": "PERSON"
    },
    {
      "text": "Ray K",
      "label": "PERSON"
    },
    {
      "text": "Rawat S",
      "label": "ORG"
    },
    {
      "text": "SoCTA 2016",
      "label": "DATE"
    },
    {
      "text": "1.",
      "label": "CARDINAL"
    },
    {
      "text": "Singapore",
      "label": "GPE"
    },
    {
      "text": "2018",
      "label": "DATE"
    },
    {
      "text": "619\u2013634",
      "label": "CARDINAL"
    },
    {
      "text": "40",
      "label": "CARDINAL"
    },
    {
      "text": "De Marneffe MC",
      "label": "ORG"
    },
    {
      "text": "MacCartney",
      "label": "ORG"
    },
    {
      "text": "al",
      "label": "PERSON"
    },
    {
      "text": "Lrec",
      "label": "PERSON"
    },
    {
      "text": "41",
      "label": "CARDINAL"
    },
    {
      "text": "Glickman O. Applied",
      "label": "PERSON"
    },
    {
      "text": "Bar Ilan University",
      "label": "ORG"
    },
    {
      "text": "2005",
      "label": "DATE"
    },
    {
      "text": "42",
      "label": "DATE"
    },
    {
      "text": "Mihis AD",
      "label": "DATE"
    },
    {
      "text": "Lupsa D. Text",
      "label": "PERSON"
    },
    {
      "text": "Computer \nScience",
      "label": "ORG"
    },
    {
      "text": "5039",
      "label": "DATE"
    },
    {
      "text": "2008",
      "label": "DATE"
    },
    {
      "text": "pp",
      "label": "GPE"
    },
    {
      "text": "233\u2013244",
      "label": "CARDINAL"
    },
    {
      "text": "43",
      "label": "CARDINAL"
    },
    {
      "text": "2016",
      "label": "DATE"
    },
    {
      "text": "2016",
      "label": "DATE"
    },
    {
      "text": "2249\u20132255",
      "label": "CARDINAL"
    },
    {
      "text": "44",
      "label": "DATE"
    },
    {
      "text": "Pasunuru",
      "label": "ORG"
    },
    {
      "text": "Bansal M. Multi-reward",
      "label": "PERSON"
    },
    {
      "text": "2018",
      "label": "DATE"
    },
    {
      "text": "North American",
      "label": "NORP"
    },
    {
      "text": "Vol",
      "label": "PERSON"
    },
    {
      "text": "2",
      "label": "CARDINAL"
    },
    {
      "text": "2018",
      "label": "DATE"
    },
    {
      "text": "646\u2013653",
      "label": "CARDINAL"
    },
    {
      "text": "45",
      "label": "CARDINAL"
    },
    {
      "text": "Palomar M.",
      "label": "PERSON"
    },
    {
      "text": "12th",
      "label": "ORDINAL"
    },
    {
      "text": "Speech",
      "label": "ORG"
    },
    {
      "text": "Berlin",
      "label": "GPE"
    },
    {
      "text": "2009",
      "label": "DATE"
    },
    {
      "text": "16\u201323",
      "label": "CARDINAL"
    },
    {
      "text": "46",
      "label": "DATE"
    },
    {
      "text": "Ferr\u00e1ndez \u00b4O. Textual",
      "label": "PERSON"
    },
    {
      "text": "NLP",
      "label": "ORG"
    },
    {
      "text": "University of Alicante",
      "label": "ORG"
    },
    {
      "text": "2009",
      "label": "DATE"
    },
    {
      "text": "47",
      "label": "DATE"
    },
    {
      "text": "Edmundson HP",
      "label": "PERSON"
    },
    {
      "text": "ACM",
      "label": "ORG"
    },
    {
      "text": "1969;16(2):264\u201385",
      "label": "CARDINAL"
    },
    {
      "text": "48",
      "label": "DATE"
    },
    {
      "text": "Ferreira R, de Souza Cabral L",
      "label": "PERSON"
    },
    {
      "text": "Pereira",
      "label": "GPE"
    },
    {
      "text": "Cavalcanti GD",
      "label": "PERSON"
    },
    {
      "text": "al",
      "label": "PERSON"
    },
    {
      "text": "Syst Appl",
      "label": "PERSON"
    },
    {
      "text": "2013;40(14):5755\u201364",
      "label": "CARDINAL"
    },
    {
      "text": "49",
      "label": "DATE"
    },
    {
      "text": "Ouyang Y",
      "label": "PERSON"
    },
    {
      "text": "Li W",
      "label": "PERSON"
    },
    {
      "text": "Lu Q",
      "label": "PERSON"
    },
    {
      "text": "Zhang R.",
      "label": "PERSON"
    },
    {
      "text": "10",
      "label": "CARDINAL"
    },
    {
      "text": "Stroudsburg",
      "label": "GPE"
    },
    {
      "text": "PA",
      "label": "GPE"
    },
    {
      "text": "2010",
      "label": "DATE"
    },
    {
      "text": "919\u2013927",
      "label": "CARDINAL"
    },
    {
      "text": "50",
      "label": "CARDINAL"
    },
    {
      "text": "Osman AH",
      "label": "LAW"
    },
    {
      "text": "Kumar YJ",
      "label": "PERSON"
    },
    {
      "text": "2012",
      "label": "DATE"
    },
    {
      "text": "pp",
      "label": "PERSON"
    },
    {
      "text": "193\u2013197",
      "label": "CARDINAL"
    },
    {
      "text": "51",
      "label": "CARDINAL"
    },
    {
      "text": "Fattah MA",
      "label": "PERSON"
    },
    {
      "text": "MR",
      "label": "GPE"
    },
    {
      "text": "FFNN",
      "label": "ORG"
    },
    {
      "text": "PNN",
      "label": "ORG"
    },
    {
      "text": "GMM",
      "label": "ORG"
    },
    {
      "text": "Comput Speech \nLang",
      "label": "PERSON"
    },
    {
      "text": "2009;23(1):126\u201344",
      "label": "CARDINAL"
    },
    {
      "text": "52",
      "label": "CARDINAL"
    },
    {
      "text": "Li Y",
      "label": "PERSON"
    },
    {
      "text": "Luo C",
      "label": "PERSON"
    },
    {
      "text": "IEEE Trans Knowl Data Eng",
      "label": "ORG"
    },
    {
      "text": "2008;20(5):641\u201351",
      "label": "DATE"
    },
    {
      "text": "53",
      "label": "CARDINAL"
    },
    {
      "text": "Benghabrit A",
      "label": "ORG"
    },
    {
      "text": "Ouhbi B",
      "label": "PERSON"
    },
    {
      "text": "Behja H. Text",
      "label": "PERSON"
    },
    {
      "text": "2013",
      "label": "DATE"
    },
    {
      "text": "World Congress on Computer and Information Technologies",
      "label": "ORG"
    },
    {
      "text": "2013",
      "label": "DATE"
    },
    {
      "text": "1\u20136",
      "label": "CARDINAL"
    },
    {
      "text": "54",
      "label": "DATE"
    },
    {
      "text": "Oliveira H",
      "label": "PERSON"
    },
    {
      "text": "Ferreira",
      "label": "GPE"
    },
    {
      "text": "Lima",
      "label": "GPE"
    },
    {
      "text": "Lins RD",
      "label": "ORG"
    },
    {
      "text": "Freitas",
      "label": "ORG"
    },
    {
      "text": "Simske SJ",
      "label": "WORK_OF_ART"
    },
    {
      "text": "Syst Appl",
      "label": "PERSON"
    },
    {
      "text": "2016;65:68\u201386",
      "label": "CARDINAL"
    },
    {
      "text": "55",
      "label": "DATE"
    },
    {
      "text": "Ouhbi B. Automatic",
      "label": "PERSON"
    },
    {
      "text": "Intell Inf Syst",
      "label": "PERSON"
    },
    {
      "text": "2019",
      "label": "DATE"
    },
    {
      "text": "1\u201334",
      "label": "CARDINAL"
    },
    {
      "text": "56",
      "label": "CARDINAL"
    },
    {
      "text": "Wan X",
      "label": "PERSON"
    },
    {
      "text": "Xiao J. Collabrank",
      "label": "PERSON"
    },
    {
      "text": "969\u2013976",
      "label": "CARDINAL"
    },
    {
      "text": "Manchester",
      "label": "PERSON"
    },
    {
      "text": "UK",
      "label": "GPE"
    },
    {
      "text": "August",
      "label": "DATE"
    },
    {
      "text": "2008",
      "label": "DATE"
    },
    {
      "text": "Organizing Committee",
      "label": "ORG"
    },
    {
      "text": "57",
      "label": "CARDINAL"
    },
    {
      "text": "Tarau P",
      "label": "ORG"
    },
    {
      "text": "Dekang Lin",
      "label": "PERSON"
    },
    {
      "text": "Wu",
      "label": "PERSON"
    },
    {
      "text": "Proceedings of EMNLP \n",
      "label": "ORG"
    },
    {
      "text": "2004",
      "label": "DATE"
    },
    {
      "text": "404\u2013411",
      "label": "CARDINAL"
    },
    {
      "text": "Barcelona",
      "label": "GPE"
    },
    {
      "text": "Spain",
      "label": "GPE"
    },
    {
      "text": "July",
      "label": "DATE"
    },
    {
      "text": "2004",
      "label": "DATE"
    },
    {
      "text": "34",
      "label": "CARDINAL"
    },
    {
      "text": "34",
      "label": "CARDINAL"
    },
    {
      "text": "Alami",
      "label": "PERSON"
    },
    {
      "text": "2023",
      "label": "DATE"
    },
    {
      "text": "10:163",
      "label": "CARDINAL"
    },
    {
      "text": "58",
      "label": "DATE"
    },
    {
      "text": "Lins RD",
      "label": "ORG"
    },
    {
      "text": "Oliveira H",
      "label": "PERSON"
    },
    {
      "text": "Cabral L",
      "label": "ORG"
    },
    {
      "text": "al",
      "label": "PERSON"
    },
    {
      "text": "cnn",
      "label": "ORG"
    },
    {
      "text": "2019",
      "label": "DATE"
    },
    {
      "text": "59",
      "label": "CARDINAL"
    },
    {
      "text": "Lins RD",
      "label": "GPE"
    },
    {
      "text": "Ferreira",
      "label": "GPE"
    },
    {
      "text": "Simske SJ",
      "label": "WORK_OF_ART"
    },
    {
      "text": "2019",
      "label": "DATE"
    },
    {
      "text": "DocEng",
      "label": "ORG"
    },
    {
      "text": "19",
      "label": "CARDINAL"
    },
    {
      "text": "ACM",
      "label": "ORG"
    },
    {
      "text": "New York",
      "label": "GPE"
    },
    {
      "text": "NY",
      "label": "GPE"
    },
    {
      "text": "USA",
      "label": "GPE"
    },
    {
      "text": "2019",
      "label": "DATE"
    },
    {
      "text": "216\u2013217",
      "label": "CARDINAL"
    },
    {
      "text": "10",
      "label": "CARDINAL"
    },
    {
      "text": "1145/",
      "label": "CARDINAL"
    },
    {
      "text": "33518",
      "label": "DATE"
    },
    {
      "text": "60",
      "label": "CARDINAL"
    },
    {
      "text": "Lin CY",
      "label": "PERSON"
    },
    {
      "text": "2004",
      "label": "DATE"
    },
    {
      "text": "61",
      "label": "CARDINAL"
    },
    {
      "text": "Lin C-Y",
      "label": "PERSON"
    },
    {
      "text": "Hovy E. Automatic",
      "label": "PERSON"
    },
    {
      "text": "n-gram",
      "label": "PRODUCT"
    },
    {
      "text": "2003",
      "label": "DATE"
    },
    {
      "text": "Human Language Technology Conference of",
      "label": "ORG"
    },
    {
      "text": "North American",
      "label": "NORP"
    },
    {
      "text": "Linguistics",
      "label": "PERSON"
    },
    {
      "text": "2003",
      "label": "DATE"
    },
    {
      "text": "150\u2013157",
      "label": "CARDINAL"
    },
    {
      "text": "62",
      "label": "CARDINAL"
    },
    {
      "text": "Ferr\u00e1ndez O,",
      "label": "PERSON"
    },
    {
      "text": "Mu\u00f1oz",
      "label": "PERSON"
    },
    {
      "text": "Palomar M. A",
      "label": "PERSON"
    },
    {
      "text": "Textual Entailment and Paraphrasing",
      "label": "ORG"
    },
    {
      "text": "2007",
      "label": "DATE"
    },
    {
      "text": "pp",
      "label": "GPE"
    },
    {
      "text": "66\u201371",
      "label": "CARDINAL"
    },
    {
      "text": "63",
      "label": "CARDINAL"
    },
    {
      "text": "Cao Z",
      "label": "ORG"
    },
    {
      "text": "Li W",
      "label": "PERSON"
    },
    {
      "text": "Wei F. Improving multi-document",
      "label": "PERSON"
    },
    {
      "text": "Thirty-First",
      "label": "CARDINAL"
    },
    {
      "text": "Artificial Intelligence",
      "label": "ORG"
    },
    {
      "text": "2017",
      "label": "DATE"
    },
    {
      "text": "64",
      "label": "DATE"
    },
    {
      "text": "Autosummarizer",
      "label": "PERSON"
    },
    {
      "text": "2015",
      "label": "DATE"
    },
    {
      "text": "65",
      "label": "CARDINAL"
    },
    {
      "text": "Batista",
      "label": "PERSON"
    },
    {
      "text": "Tomaz H",
      "label": "ORG"
    },
    {
      "text": "Ferreira",
      "label": "GPE"
    },
    {
      "text": "Dueire Lins",
      "label": "PERSON"
    },
    {
      "text": "Simske S.",
      "label": "PERSON"
    },
    {
      "text": "2015",
      "label": "DATE"
    },
    {
      "text": "2015",
      "label": "DATE"
    },
    {
      "text": "66",
      "label": "CARDINAL"
    },
    {
      "text": "Classifier4J. 2005",
      "label": "DATE"
    },
    {
      "text": "4j",
      "label": "CARDINAL"
    },
    {
      "text": "sourc",
      "label": "PERSON"
    },
    {
      "text": "67",
      "label": "CARDINAL"
    },
    {
      "text": "Wan X. Towards",
      "label": "PERSON"
    },
    {
      "text": "2010",
      "label": "DATE"
    },
    {
      "text": "pp",
      "label": "GPE"
    },
    {
      "text": "1137\u20131145",
      "label": "CARDINAL"
    },
    {
      "text": "Song W",
      "label": "PERSON"
    },
    {
      "text": "Choi LC",
      "label": "ORG"
    },
    {
      "text": "Park SC",
      "label": "ORG"
    },
    {
      "text": "Ding XF",
      "label": "PERSON"
    },
    {
      "text": "Syst Appl",
      "label": "PERSON"
    },
    {
      "text": "2011;38(8):9112\u201321",
      "label": "CARDINAL"
    },
    {
      "text": "69",
      "label": "CARDINAL"
    },
    {
      "text": "Svore K",
      "label": "PERSON"
    },
    {
      "text": "Vanderwende L",
      "label": "ORG"
    },
    {
      "text": "Burges C. Enhancing",
      "label": "ORG"
    },
    {
      "text": "RankNet",
      "label": "ORG"
    },
    {
      "text": "2007",
      "label": "DATE"
    },
    {
      "text": "EMNLP-CoNLL",
      "label": "ORG"
    },
    {
      "text": "2007",
      "label": "DATE"
    },
    {
      "text": "448\u2013457",
      "label": "CARDINAL"
    },
    {
      "text": "70",
      "label": "DATE"
    },
    {
      "text": "Ferreira R, de Freitas FLG",
      "label": "PERSON"
    },
    {
      "text": "Lins RD",
      "label": "GPE"
    },
    {
      "text": "Lima",
      "label": "GPE"
    },
    {
      "text": "de Fran\u00e7a Pereira",
      "label": "PERSON"
    },
    {
      "text": "al",
      "label": "PERSON"
    },
    {
      "text": "11th",
      "label": "ORDINAL"
    },
    {
      "text": "2014",
      "label": "DATE"
    },
    {
      "text": "66\u201370",
      "label": "CARDINAL"
    },
    {
      "text": "71",
      "label": "DATE"
    },
    {
      "text": "Liu PJ",
      "label": "PERSON"
    },
    {
      "text": "55th",
      "label": "ORDINAL"
    },
    {
      "text": "the Association for Computational Linguistics",
      "label": "ORG"
    },
    {
      "text": "Vol",
      "label": "PERSON"
    },
    {
      "text": "1",
      "label": "CARDINAL"
    },
    {
      "text": "2017",
      "label": "DATE"
    },
    {
      "text": "pp",
      "label": "PERSON"
    },
    {
      "text": "1073\u20131083",
      "label": "DATE"
    }
  ],
  "summary": "The paper introduces EXABSUM, a novel text summarization approach capable of generating both extractive and abstractive summaries. Combining statistical, semantic scoring, and graph-based methods, EXABSUM outperforms existing techniques in summarizing multi-domain textual content efficiently, addressing the growing need for accessible information in the era of expanding online data.",
  "embedding": [
    0.06634442508220673,
    0.0027447640895843506,
    -0.03234487026929855,
    -0.00796198844909668,
    -0.054876070469617844,
    0.03515354171395302,
    -0.040926095098257065,
    -0.022093195468187332,
    0.0015501579036936164,
    -0.027393024414777756,
    0.04235602915287018,
    -0.02841954678297043,
    0.03618776053190231,
    0.04470288008451462,
    0.010821813717484474,
    -0.09021692723035812,
    0.012924820184707642,
    0.016308804973959923,
    0.018110079690814018,
    0.005157438572496176,
    0.06113821640610695,
    0.02266983687877655,
    0.010039621964097023,
    0.005367415491491556,
    0.06036371737718582,
    0.024405330419540405,
    0.010491996072232723,
    -0.05010035261511803,
    0.05581068992614746,
    0.0017822467489168048,
    0.007362329866737127,
    -0.025405278429389,
    -0.008766385726630688,
    -0.016177909448742867,
    2.115634970323299e-06,
    -0.07609423249959946,
    -0.05981193855404854,
    -0.02218175120651722,
    0.036611150950193405,
    0.0018468505004420877,
    0.03956152871251106,
    -0.02389627881348133,
    -0.0022100687492638826,
    0.028572257608175278,
    -0.0002796958724502474,
    0.02109949104487896,
    0.006856390740722418,
    0.023586535826325417,
    0.06711561232805252,
    0.049381740391254425,
    -0.025057008489966393,
    -0.06501452624797821,
    0.026211077347397804,
    0.029390636831521988,
    -0.03420684114098549,
    0.039509501308202744,
    -0.009548448026180267,
    0.007144107483327389,
    -0.0021767679136246443,
    -0.0055120657198131084,
    -0.004887652117758989,
    0.04088256508111954,
    -0.00923197716474533,
    0.0046811639331281185,
    0.0026896344497799873,
    0.05459337681531906,
    -0.05219753086566925,
    -0.025581004098057747,
    -0.005813735071569681,
    0.053335484117269516,
    0.03104974702000618,
    -0.01473873108625412,
    0.06513500213623047,
    0.007366684265434742,
    -0.01160483993589878,
    0.04375598579645157,
    -0.07084543257951736,
    0.06563791632652283,
    -0.0415273979306221,
    0.036650367081165314,
    0.027548570185899734,
    0.06908367574214935,
    -0.04825572296977043,
    0.06051952391862869,
    -0.05241911858320236,
    -0.008511322550475597,
    -0.014186471700668335,
    -0.013610545545816422,
    -0.011883614584803581,
    -0.027676332741975784,
    -0.021833594888448715,
    -0.06324295699596405,
    0.02405783161520958,
    0.07552126795053482,
    0.042577698826789856,
    -0.04992811754345894,
    -0.005530887749046087,
    -0.10232352465391159,
    0.058282528072595596,
    -0.05247145891189575,
    0.0023095544893294573,
    -0.01881101168692112,
    0.049235835671424866,
    0.07488472014665604,
    0.016417009755969048,
    -0.043900735676288605,
    0.029128018766641617,
    -0.017661279067397118,
    -0.016929907724261284,
    0.010638976469635963,
    -0.007305210921913385,
    0.0036025072913616896,
    -0.017716897651553154,
    0.06139210984110832,
    -0.0710444524884224,
    -0.0023237161803990602,
    -0.04770582541823387,
    0.017829881981015205,
    0.019219938665628433,
    -0.027840107679367065,
    -0.028979137539863586,
    -0.0019010617397725582,
    0.029166800901293755,
    0.010408814996480942,
    -0.007421883288770914,
    -0.02895539626479149,
    -0.04893244802951813,
    -0.0023433335591107607,
    0.00650666793808341,
    -0.0016575570916756988,
    0.0319623239338398,
    0.02994939312338829,
    0.08118178695440292,
    0.05313238874077797,
    0.00777771882712841,
    0.03414809703826904,
    0.000721304037142545,
    -0.04248717054724693,
    -0.0018440412823110819,
    -0.03652046620845795,
    0.0005758331972174346,
    -0.035597063601017,
    -0.021266577765345573,
    -0.04977155849337578,
    0.017531175166368484,
    0.0012589271645992994,
    -0.029819119721651077,
    0.042703498154878616,
    -0.006594522390514612,
    0.033057719469070435,
    -0.023591702803969383,
    0.004086560104042292,
    -0.06141984090209007,
    0.0037750464398413897,
    0.07084927707910538,
    0.014856998808681965,
    0.04743388667702675,
    0.012608538381755352,
    0.04399079456925392,
    0.05935685336589813,
    0.04230146110057831,
    0.0066041965037584305,
    0.044352732598781586,
    0.04209354519844055,
    0.009123554453253746,
    0.023209745064377785,
    0.018631702288985252,
    0.01789582520723343,
    -0.053641319274902344,
    -0.07000171393156052,
    -0.023551031947135925,
    0.04821375012397766,
    -0.03494343161582947,
    0.08213289082050323,
    0.060348402708768845,
    0.05564506724476814,
    -0.02292398177087307,
    0.05450325459241867,
    -0.026598213240504265,
    0.03403719514608383,
    0.05369415506720543,
    0.021450292319059372,
    0.052990447729825974,
    0.021222177892923355,
    0.00012819185212720186,
    0.03864039108157158,
    0.09865569323301315,
    0.03085017204284668,
    0.004268890246748924,
    -0.05154786631464958,
    0.045971181243658066,
    0.022334575653076172,
    0.03176134079694748,
    0.004062323831021786,
    0.037230707705020905,
    -0.010205306112766266,
    -0.00933197233825922,
    -0.01728397235274315,
    0.02027713693678379,
    -0.05398046597838402,
    0.03261261805891991,
    -0.008816676214337349,
    0.020984426140785217,
    -0.019671514630317688,
    0.023257922381162643,
    -0.03604761138558388,
    0.02296587824821472,
    -0.014935080893337727,
    -0.0065512568689882755,
    0.0002878382510971278,
    0.013406607322394848,
    -0.017384612932801247,
    -0.06367822736501694,
    -0.06373206526041031,
    -0.027206461876630783,
    0.04646717384457588,
    -0.03254430741071701,
    -0.043938759714365005,
    -0.03162157163023949,
    0.004141715355217457,
    0.040382303297519684,
    0.026137925684452057,
    -0.055934760719537735,
    0.011491422541439533,
    0.0011870622402057052,
    0.010305684059858322,
    0.008182884193956852,
    -0.010580020025372505,
    0.019880417734384537,
    0.03831193223595619,
    -0.004942264407873154,
    0.03681454807519913,
    0.030262213200330734,
    -0.010705006308853626,
    -0.033659692853689194,
    0.025541013106703758,
    0.02868095599114895,
    0.035026442259550095,
    0.005065309815108776,
    -0.04349902272224426,
    0.02177911438047886,
    -0.003469605464488268,
    0.012345638126134872,
    -0.0564383901655674,
    0.02791597880423069,
    -0.06276379525661469,
    0.047445401549339294,
    -0.04235519468784332,
    0.03784387186169624,
    -0.00549900671467185,
    0.01745171844959259,
    -0.04088865965604782,
    0.08818677812814713,
    0.0006524897762574255,
    -0.017765173688530922,
    -0.005864804610610008,
    -0.07684950530529022,
    0.01623384654521942,
    0.0012921602465212345,
    0.03397227078676224,
    -0.036506958305835724,
    0.0004641554842237383,
    0.014907135628163815,
    0.06509064882993698,
    -0.02062220126390457,
    -0.08395536243915558,
    -0.019034016877412796,
    -0.05376214161515236,
    0.024782638996839523,
    0.02556265890598297,
    0.043016791343688965,
    0.039815645664930344,
    0.04412073642015457,
    -0.021866168826818466,
    0.009797913953661919,
    -0.0226704441010952,
    -0.015140528790652752,
    0.016370439901947975,
    -0.006024900358170271,
    0.04491789638996124,
    0.025404611602425575,
    0.01734624058008194,
    -0.014883756637573242,
    -0.0016755165997892618,
    -0.01488061435520649,
    0.022810645401477814,
    0.05110064893960953,
    -0.05422467738389969,
    0.0208789873868227,
    -0.004604806192219257,
    -0.020260067656636238,
    -0.02581796608865261,
    0.01898522861301899,
    -0.010705074295401573,
    -0.039533745497465134,
    -0.023515500128269196,
    0.011017514392733574,
    -0.04034089669585228,
    0.06387878209352493,
    -0.02096598967909813,
    0.002406022511422634,
    -0.045749690383672714,
    -0.005642101634293795,
    -0.002596053294837475,
    -0.06438694149255753,
    0.04916064068675041,
    0.03492883965373039,
    -0.02858162112534046,
    0.05364513024687767,
    -0.02849137783050537,
    0.037972256541252136,
    -0.010970668867230415,
    -0.008171668276190758,
    0.010656598955392838,
    -0.018163708969950676,
    0.01585978828370571,
    -0.05444847792387009,
    -0.0068682595156133175,
    -0.005659650545567274,
    0.06230352818965912,
    -0.009553602896630764,
    -0.02804144285619259,
    -0.01175953634083271,
    0.024426745250821114,
    0.05523655563592911,
    -0.09501391649246216,
    -0.004310379270464182,
    -0.033481840044260025,
    0.02781020849943161,
    -0.005280437879264355,
    0.055249668657779694,
    -0.006412793882191181,
    -0.010162829421460629,
    0.009662744589149952,
    -0.03850855305790901,
    0.018122632056474686,
    -0.02960212342441082,
    0.044552966952323914,
    0.006197644863277674,
    0.0001631477935006842,
    -0.016453184187412262,
    0.0100216930732131,
    0.02772798389196396,
    -0.05410207062959671,
    0.020395886152982712,
    -0.017645953223109245,
    0.04703795537352562,
    0.004036942031234503,
    -0.05921192467212677,
    0.0030748615972697735,
    0.06292533874511719,
    0.008528138510882854,
    -0.024835677817463875,
    -0.03907742351293564,
    0.018560051918029785,
    0.07271095365285873,
    0.057128358632326126,
    -0.04285305738449097,
    0.040636301040649414,
    -0.006351981777697802,
    -0.0014389301650226116,
    0.08547908812761307,
    -0.026921799406409264,
    -0.021199679002165794,
    0.02192307822406292,
    -0.030606575310230255,
    -0.009186764247715473,
    -0.08786001056432724,
    0.030863136053085327,
    -0.02813340537250042,
    0.026058483868837357,
    -0.018341774120926857,
    0.011395151726901531,
    0.07423093169927597,
    0.03985106199979782,
    -0.048612046986818314,
    -0.01263877097517252,
    0.010918215848505497,
    -0.019690927118062973,
    -0.019176818430423737,
    -0.005571660120040178,
    -0.07195397466421127,
    0.03651529550552368,
    -0.002502385526895523,
    0.016717959195375443,
    -0.05102856084704399,
    -0.03482470661401749,
    0.007343775127083063,
    -0.08017384260892868,
    0.025440581142902374,
    -0.0024305793922394514,
    -0.0938187912106514,
    -0.02671831101179123,
    -0.03844721242785454,
    0.013998736627399921,
    0.0021084260661154985,
    -0.07693440467119217,
    0.010869297198951244,
    -0.03339951112866402,
    0.03845176845788956,
    0.0226487647742033,
    -0.06508281826972961,
    0.04276823252439499,
    -0.041024066507816315,
    -0.01794617436826229,
    -0.06126336008310318,
    0.02762731723487377,
    0.06624123454093933,
    -0.04865919426083565,
    0.03177635744214058,
    0.03256896510720253,
    -0.0840495154261589,
    -0.05478975176811218,
    -0.005183226894587278,
    0.07935626059770584,
    0.028941892087459564,
    -0.004291696939617395,
    -0.08128657937049866,
    0.04973859339952469,
    0.028280671685934067,
    -0.008805696852505207,
    0.03338109329342842,
    0.050467927008867264,
    0.016797324642539024,
    -0.014242514036595821,
    -0.09252138435840607,
    0.02065526880323887,
    -0.00013787577336188406,
    0.007126190233975649,
    0.010547935962677002,
    -0.0011933916248381138,
    -0.013309466652572155,
    -0.01841110736131668,
    -0.007998266257345676,
    -0.048703450709581375,
    -0.03893575072288513,
    -0.019910532981157303,
    -0.024677017703652382,
    -0.03429007902741432,
    -0.06998292356729507,
    -0.05655627325177193,
    0.0168642345815897,
    0.008765138685703278,
    0.014928345568478107,
    0.017500976100564003,
    0.009374015964567661,
    0.0037443225737661123,
    -0.03617841377854347,
    -0.036297183483839035,
    0.007178974337875843,
    -0.0006933107506483793,
    0.014528332278132439,
    -0.031155014410614967,
    0.05520980805158615,
    -0.02225605957210064,
    -0.032805185765028,
    0.021718081086874008,
    -0.017879657447338104,
    -0.053256236016750336,
    -0.025702867656946182,
    -0.00516224792227149,
    0.015081075951457024,
    -0.012266901321709156,
    0.01583710126578808,
    -0.010036470368504524,
    0.10818204283714294,
    0.03614495322108269,
    0.006958253215998411,
    -0.0073461453430354595,
    -0.012550728395581245,
    0.03893941640853882,
    -0.03300199657678604,
    0.010864467360079288,
    -0.04353315383195877,
    0.05022187530994415,
    -0.029272548854351044,
    -0.004316613543778658,
    -0.043851789087057114,
    0.008446856401860714,
    0.006416915450245142,
    0.03331219032406807,
    -0.022858649492263794,
    -0.042404141277074814,
    -0.07201741635799408,
    0.002954987110570073,
    -0.03900950402021408,
    0.004964569117873907,
    -0.03816016763448715,
    -0.01393673662096262,
    0.012291999533772469,
    -0.012511189095675945,
    0.034779470413923264,
    -0.013512617908418179,
    0.04871942475438118,
    0.03282878175377846,
    -0.011446725577116013,
    -0.03666079416871071,
    0.03109366074204445,
    -0.009711994789540768,
    -0.005886653903871775,
    -0.060282330960035324,
    -0.007129743695259094,
    -0.023762274533510208,
    -0.06169281154870987,
    -0.04932376369833946,
    0.019658289849758148,
    -0.013070440851151943,
    -0.01653299666941166,
    0.034098733216524124,
    0.008064351975917816,
    -0.019171331077814102,
    0.05765772610902786,
    -0.04798780009150505,
    0.038020916283130646,
    -0.03655015677213669,
    0.005916142370551825,
    0.02301490493118763,
    -0.060631830245256424,
    0.028089432045817375,
    0.028473196551203728,
    -0.016649041324853897,
    -0.000673627364449203,
    0.03968990221619606,
    0.012286502867937088,
    0.0011808555573225021,
    -0.06445957720279694,
    -0.010434851981699467,
    0.003641267539933324,
    -0.003964010160416365,
    0.045113932341337204,
    -0.07244116067886353,
    0.0060333372093737125,
    0.034416232258081436,
    -0.04032085835933685,
    -0.035769373178482056,
    -0.0011514779180288315,
    -0.025813886895775795,
    0.020529277622699738,
    0.03279280662536621,
    -0.02131357416510582,
    -0.03647356852889061,
    -0.01925334893167019,
    0.02876841276884079,
    0.019088206812739372,
    0.03139927238225937,
    0.010710391215980053,
    0.002232993021607399,
    0.019902793690562248,
    0.026002489030361176,
    -0.009942770004272461,
    -0.0682661235332489,
    0.002429739572107792,
    -0.049500081688165665,
    0.012895596213638783,
    -0.006836008280515671,
    -6.182309030690335e-33,
    0.008182649500668049,
    -0.002351667732000351,
    -0.04689321666955948,
    0.03589368984103203,
    -0.03429024666547775,
    0.01183729711920023,
    -0.04104969650506973,
    -0.05286850780248642,
    0.03474486991763115,
    -0.015109065920114517,
    -0.016740551218390465,
    0.0009551895782351494,
    0.01424473151564598,
    0.017989519983530045,
    0.03209665045142174,
    0.04982522875070572,
    -0.020440174266695976,
    0.004609569441527128,
    -0.03273892030119896,
    0.04998425021767616,
    0.05771815404295921,
    -0.014485240913927555,
    0.03591195121407509,
    -0.05970160663127899,
    0.03114483691751957,
    -0.027681885287165642,
    -0.07268448919057846,
    -0.02715418115258217,
    0.05299259349703789,
    0.02104232832789421,
    -0.01134167518466711,
    -0.013735082000494003,
    0.03675844520330429,
    0.014877242967486382,
    -0.024416692554950714,
    0.027340687811374664,
    -0.06797472387552261,
    -0.03926251083612442,
    0.005011569708585739,
    -0.057060666382312775,
    -0.0339508093893528,
    -0.03850240632891655,
    0.0539325550198555,
    -0.029757803305983543,
    -0.01929750107228756,
    -0.025375355035066605,
    0.04937456548213959,
    -0.05796145647764206,
    -0.022513307631015778,
    -0.07021351158618927,
    -0.010546484030783176,
    0.043619152158498764,
    -0.048360370099544525,
    0.04623531177639961,
    0.007651042193174362,
    0.03301871195435524,
    0.0038279853761196136,
    0.005792186129838228,
    -0.028128860518336296,
    0.08572761714458466,
    0.07667754590511322,
    0.015353280119597912,
    0.0221864003688097,
    0.01849084161221981,
    0.03719404339790344,
    0.033598341047763824,
    -0.04707785323262215,
    -0.039770785719156265,
    -0.009649848565459251,
    0.016747809946537018,
    -0.020443640649318695,
    -0.01621820405125618,
    -0.006894457619637251,
    0.03980603069067001,
    0.03869456425309181,
    6.938240858289646e-06,
    -0.07396556437015533,
    0.11580876260995865,
    -0.013061204925179482,
    0.006239859387278557,
    0.031744424253702164,
    -0.021912703290581703,
    -0.03567524999380112,
    -0.019438404589891434,
    0.013275270350277424,
    -0.00782701838761568,
    0.007022498175501823,
    0.006139075383543968,
    -0.02735896222293377,
    0.019192708656191826,
    -0.06852704286575317,
    0.04641878232359886,
    -0.03832065686583519,
    -0.03248073533177376,
    0.006927973590791225,
    -0.00590134784579277,
    -0.004166401457041502,
    0.040510255843400955,
    -5.315991074894555e-06,
    -0.06712666898965836,
    -0.047270674258470535,
    -0.01664123870432377,
    -0.023556379601359367,
    0.01251162588596344,
    -0.016725711524486542,
    0.026231231167912483,
    0.02804546058177948,
    0.017122359946370125,
    -0.05135459452867508,
    -0.01212395541369915,
    0.05005835369229317,
    0.03590167313814163,
    -0.02687947079539299,
    0.01662863790988922,
    -0.03269047290086746,
    -0.0072029647417366505,
    0.01963488943874836,
    -0.004174640867859125,
    0.037334684282541275,
    0.030974263325333595,
    -0.010466339066624641,
    0.009765597991645336,
    0.008607986383140087,
    0.002822782378643751,
    0.007147108670324087,
    -0.0030912847723811865,
    -0.004535311367362738,
    -0.023366253823041916,
    0.026049455627799034,
    -0.03623929247260094,
    -0.00362780992873013,
    -0.016080863773822784,
    2.7599878649198217e-07,
    0.050772957503795624,
    0.010896878316998482,
    0.028431911021471024,
    -0.014358414337038994,
    -0.03668760880827904,
    0.006103352643549442,
    0.006327229551970959,
    0.0279709305614233,
    0.017565295100212097,
    0.03359122946858406,
    0.045841898769140244,
    0.02959434501826763,
    -0.0030871250201016665,
    0.03829214721918106,
    -0.07136863470077515,
    -0.019031601026654243,
    -0.04206100106239319,
    -0.0681326612830162,
    -0.03872876241803169,
    0.029114078730344772,
    0.046713389456272125,
    0.04146607220172882,
    0.009853101335465908,
    0.001381180016323924,
    -0.031821299344301224,
    -0.019013892859220505,
    -0.00783354602754116,
    -0.02430083602666855,
    -0.0344671867787838,
    0.039966657757759094,
    0.026138262823224068,
    0.007009091321378946,
    -0.017481056973338127,
    -0.02702936716377735,
    -0.02035476639866829,
    0.012823384255170822,
    0.04645887389779091,
    0.03328828141093254,
    0.006016624625772238,
    0.03522055968642235,
    0.050700750201940536,
    -0.03711659833788872,
    0.05933185666799545,
    0.0016596470959484577,
    0.06027157977223396,
    -0.018627755343914032,
    -0.03921594098210335,
    -0.019987091422080994,
    -0.04714850336313248,
    0.014587825164198875,
    -0.03406362980604172,
    0.001920168288052082,
    -0.04948757588863373,
    0.04569172114133835,
    -0.030423933640122414,
    -0.012966777198016644,
    0.005059451796114445,
    -0.056960269808769226,
    0.014127477072179317,
    0.008762935176491737,
    -0.0008233345579355955,
    -0.03955555707216263,
    0.01975616253912449,
    0.03583591431379318,
    0.006272254511713982,
    -0.051711469888687134,
    0.026650937274098396,
    2.7242145865153824e-34,
    0.07551905512809753,
    0.006460604257881641,
    -0.062498725950717926,
    0.0032335342839360237,
    0.02233954519033432,
    -0.026558218523859978,
    -0.005947706755250692,
    0.012379016727209091,
    0.018311476334929466,
    -0.08621303737163544,
    -0.00019040267216041684
  ]
}